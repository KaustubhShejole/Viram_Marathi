{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8969430b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.50.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2ffd9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 25 17:41:13 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.5     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          Off | 00000000:17:00.0 Off |                    0 |\n",
      "| N/A   58C    P0              72W / 300W |  30216MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80GB PCIe          Off | 00000000:31:00.0 Off |                    0 |\n",
      "| N/A   72C    P0             303W / 300W |  80011MiB / 81920MiB |     92%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100 80GB PCIe          Off | 00000000:4B:00.0 Off |                    0 |\n",
      "| N/A   56C    P0              74W / 300W |  74909MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100 80GB PCIe          Off | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   63C    P0             298W / 300W |  74979MiB / 81920MiB |    100%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "497ae3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/Approach0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "278bf807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5eb4a9",
   "metadata": {},
   "source": [
    "## Dataset Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d41239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"thenlpresearcher/in22_conv_eng_mar_hin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d21714fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "raw_datasets = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adb6ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- LOAD DATA --------------------\n",
    "src_sentences = raw_datasets['test'][\"src\"]\n",
    "gt_mar     = raw_datasets['test'][\"mar_Deva\"]\n",
    "gt_hin    = raw_datasets['test'][\"hin_Deva\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777aedff",
   "metadata": {},
   "source": [
    "## Model Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38b6729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model_name = \"ai4bharat/indictrans2-en-indic-dist-200M\"\n",
    "without_punct_model_name = \"thenlpresearcher/iitb-en-indic-without-punct\"\n",
    "with_punct_model_name = \"thenlpresearcher/iitb-en-indic-only-punct\"\n",
    "combined_x_punct_model_name = \"thenlpresearcher/shalaka_fd_indictrans2-en-indic-dist-200M_finetuned_eng_Latn_to_mar_Deva\"\n",
    "combined_2x_punct_model_name = \"thenlpresearcher/shalaka_indictrans2-en-indic-dist-200M_finetuned_eng_Latn_to_mar_Deva\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13cd3ad",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be82f2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"original\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be8de642",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = original_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c136114c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 17:41:20.500438: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-25 17:41:20.562261: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-25 17:41:22.780769: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "100%|███████████████████████████████████████| 47/47 [03:07<00:00,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng_Latn: Mom, let's go for a movie tomorrow.\n",
      "mar_Deva: आई, उद्या चित्रपटाला जाऊया.\n",
      "eng_Latn: I don't have to go to school.\n",
      "mar_Deva: मला शाळेत जाण्याची गरज नाही.\n",
      "eng_Latn: It is a holiday.\n",
      "mar_Deva: ती सुट्टी असते.\n",
      "eng_Latn: Oh, tomorrow is the 14th of April right?\n",
      "mar_Deva: अरे, उद्या 14 एप्रिल आहे ना?\n",
      "eng_Latn: Your dad will also have the day off from work.\n",
      "mar_Deva: तुमच्या वडिलांनाही कामावरून सुट्टी मिळेल.\n",
      "eng_Latn: We can make a movie plan!\n",
      "mar_Deva: आम्ही चित्रपटाची योजना बनवू शकतो!\n",
      "eng_Latn: That's a good news!\n",
      "mar_Deva: ही एक चांगली बातमी आहे!\n",
      "eng_Latn: Why is it a holiday though?\n",
      "mar_Deva: मात्र, ही सुट्टी का आहे?\n",
      "eng_Latn: Are all schools, colleges and offices closed tomorrow?\n",
      "mar_Deva: सर्व शाळा, महाविद्यालये आणि कार्यालये उद्या बंद आहेत का?\n",
      "eng_Latn: It is Ambedkar Jayanti tomorrow!\n",
      "mar_Deva: उद्या आंबेडकर जयंती आहे!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from IndicTransToolkit.processor import IndicProcessor\n",
    "from tqdm import tqdm\n",
    "# recommended to run this on a gpu with flash_attn installed\n",
    "# don't set attn_implemetation if you don't have flash_attn\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "src_lang, tgt_lang = \"eng_Latn\", \"mar_Deva\"\n",
    "tokenizer_name =  \"ai4bharat/indictrans2-en-indic-dist-200M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name, \n",
    "    trust_remote_code=True, \n",
    "    torch_dtype=torch.float16, # performance might slightly vary for bfloat16\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ").to(DEVICE)\n",
    "\n",
    "ip = IndicProcessor(inference=True)\n",
    "\n",
    "input_sentences = src_sentences\n",
    "\n",
    "import torch\n",
    "\n",
    "def batch_translate(\n",
    "    input_sentences,\n",
    "    src_lang,\n",
    "    tgt_lang,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    ip,\n",
    "    device=\"cuda\",\n",
    "    batch_size=16,\n",
    "):\n",
    "    all_translations = []\n",
    "\n",
    "    for i in tqdm(range(0, len(input_sentences), batch_size)):\n",
    "        batch = input_sentences[i : i + batch_size]\n",
    "\n",
    "        # Preprocess (handles entity mapping etc.)\n",
    "        batch = ip.preprocess_batch(\n",
    "            batch,\n",
    "            src_lang=src_lang,\n",
    "            tgt_lang=tgt_lang\n",
    "        )\n",
    "\n",
    "        # Tokenize on device\n",
    "        inputs = tokenizer(\n",
    "            batch,\n",
    "            truncation=True,\n",
    "            padding=\"longest\",\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=True,\n",
    "        ).to(device)\n",
    "\n",
    "        # Generate translations\n",
    "        with torch.no_grad():\n",
    "            generated = model.generate(\n",
    "                **inputs,\n",
    "                use_cache=True,\n",
    "                min_length=0,\n",
    "                max_length=256,\n",
    "                num_beams=5,\n",
    "                num_return_sequences=1,\n",
    "            )\n",
    "\n",
    "        # Decode\n",
    "        decoded = tokenizer.batch_decode(\n",
    "            generated,\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=True,\n",
    "        )\n",
    "\n",
    "        # Postprocess (restore entities)\n",
    "        decoded = ip.postprocess_batch(decoded, lang=tgt_lang)\n",
    "\n",
    "        all_translations.extend(decoded)\n",
    "\n",
    "    return all_translations\n",
    "\n",
    "translations = batch_translate(\n",
    "    input_sentences,\n",
    "    src_lang=\"eng_Latn\",\n",
    "    tgt_lang=\"mar_Deva\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    ip=ip,\n",
    "    device=DEVICE,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "for input_sentence, translation in zip(input_sentences[:10], translations[:10]):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce586dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "आई, उद्या चित्रपटाला जाऊया.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def remove_prefix(translations, prefix):\n",
    "    ans = []\n",
    "    for t in translations:\n",
    "        t = t.strip()\n",
    "        if t.startswith(prefix):\n",
    "            t = t[len(prefix):]\n",
    "        t = re.sub(r'\\.+', '.', t)\n",
    "        ans.append(t)\n",
    "    return ans\n",
    "\n",
    "translations_mar = remove_prefix(translations, \"mar_Deva eng_Latn \")\n",
    "print(translations_mar[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07841519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 47/47 [03:22<00:00,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng_Latn: Mom, let's go for a movie tomorrow.\n",
      "mar_Deva: माँ, चलो कल एक फ़िल्म देखने चलते हैं।\n",
      "eng_Latn: I don't have to go to school.\n",
      "mar_Deva: मुझे स्कूल जाने की ज़रूरत नहीं है।\n",
      "eng_Latn: It is a holiday.\n",
      "mar_Deva: यह छुट्टी है।\n",
      "eng_Latn: Oh, tomorrow is the 14th of April right?\n",
      "mar_Deva: ओह, कल 14 अप्रैल है ना?\n",
      "eng_Latn: Your dad will also have the day off from work.\n",
      "mar_Deva: आपके पिता को भी काम से छुट्टी मिलेगी।\n",
      "eng_Latn: We can make a movie plan!\n",
      "mar_Deva: हम एक फिल्म की योजना बना सकते हैं!\n",
      "eng_Latn: That's a good news!\n",
      "mar_Deva: यह एक अच्छी खबर है!\n",
      "eng_Latn: Why is it a holiday though?\n",
      "mar_Deva: लेकिन यह छुट्टी क्यों है?\n",
      "eng_Latn: Are all schools, colleges and offices closed tomorrow?\n",
      "mar_Deva: क्या सभी स्कूल, कॉलेज और कार्यालय कल बंद हैं?\n",
      "eng_Latn: It is Ambedkar Jayanti tomorrow!\n",
      "mar_Deva: कल अम्बेडकर जयंती है!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from IndicTransToolkit.processor import IndicProcessor\n",
    "from tqdm import tqdm\n",
    "# recommended to run this on a gpu with flash_attn installed\n",
    "# don't set attn_implemetation if you don't have flash_attn\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "translations = batch_translate(\n",
    "    input_sentences,\n",
    "    src_lang=\"eng_Latn\",\n",
    "    tgt_lang=\"hin_Deva\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    ip=ip,\n",
    "    device=DEVICE,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "for input_sentence, translation in zip(input_sentences[:10], translations[:10]):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eb48190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "माँ, चलो कल एक फ़िल्म देखने चलते हैं।\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def remove_prefix(translations, prefix):\n",
    "    ans = []\n",
    "    for t in translations:\n",
    "        t = t.strip()\n",
    "        if t.startswith(prefix):\n",
    "            t = t[len(prefix):]\n",
    "        t = re.sub(r'\\.+', '.', t)\n",
    "        ans.append(t)\n",
    "    return ans\n",
    "\n",
    "translations_hin = remove_prefix(translations, \"hin_Deva eng_Latn \")\n",
    "print(translations_hin[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "726e33f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved predictions to thenlpresearcher/in22_conv_eng_mar_hin/original_outputs.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "\n",
    "# -------------------- SAVE OUTPUTS --------------------\n",
    "results_df = pd.DataFrame({\n",
    "    \"src\": src_sentences,\n",
    "    \"prediction_mar\": translations_mar,\n",
    "    \"prediction_hin\": translations_hin,\n",
    "    \"gt_mar\": gt_mar,\n",
    "    \"gt_hin\": gt_hin\n",
    "})\n",
    "\n",
    "import os\n",
    "os.makedirs(dataset_name, exist_ok=True)\n",
    "results_df.to_csv(f\"{dataset_name}/{mode}_outputs.csv\", index=False)\n",
    "print(f\"✔ Saved predictions to {dataset_name}/{mode}_outputs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bd693c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- METRICS --------------------\n",
    "bleu = load(\"sacrebleu\")\n",
    "chrf = load(\"chrf\")\n",
    "\n",
    "def compute_scores(preds, ref1):\n",
    "    \"\"\"\n",
    "    Compute BLEU and chrF++ scores using all three references for each sentence.\n",
    "    \"\"\"\n",
    "    references = [[r1] for r1 in ref1]  # sacrebleu format\n",
    "    bleu_score = bleu.compute(predictions=preds, references=references)[\"score\"]\n",
    "    chrf_score = chrf.compute(predictions=preds, references=references)[\"score\"]\n",
    "    return bleu_score, chrf_score\n",
    "\n",
    "bleu_score_mar, chrf_score_mar = compute_scores(translations_mar, gt_mar)\n",
    "bleu_score_hin, chrf_score_hin = compute_scores(translations_hin, gt_hin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66dee636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics -- Marathi\n",
      "BLEU: 18.94741520242327, CHRF++: 51.04813164303506\n",
      "Metrics -- Hindi\n",
      "BLEU: 26.3837176743007 CHRF++: 48.309698872187774\n"
     ]
    }
   ],
   "source": [
    "print('Metrics -- Marathi')\n",
    "print(f\"BLEU: {bleu_score_mar}, CHRF++: {chrf_score_mar}\")\n",
    "\n",
    "print('Metrics -- Hindi')\n",
    "print(f\"BLEU: {bleu_score_hin} CHRF++: {chrf_score_hin}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73659125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "765c8914",
   "metadata": {},
   "source": [
    "### Without Punctuation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd60be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"without\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de25d667",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = without_punct_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a58c7014",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name, \n",
    "    trust_remote_code=True, \n",
    "    torch_dtype=torch.float16, # performance might slightly vary for bfloat16\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1457ee1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 47/47 [01:13<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng_Latn: Mom, let's go for a movie tomorrow.\n",
      "mar_Deva: mar_Deva eng_Latn आई, उद्या चित्रपट बघायला जाऊ.\n",
      "eng_Latn: I don't have to go to school.\n",
      "mar_Deva: mar_Deva eng_Latn मला शाळेत जायची गरज नाही.\n",
      "eng_Latn: It is a holiday.\n",
      "mar_Deva: mar_Deva eng_Latn ती सुट्टी असते.\n",
      "eng_Latn: Oh, tomorrow is the 14th of April right?\n",
      "mar_Deva: mar_Deva eng_Latn अरे, उद्या 14 एप्रिल आहे ना?\n",
      "eng_Latn: Your dad will also have the day off from work.\n",
      "mar_Deva: mar_Deva eng_Latn तुमच्या वडिलांनाही कामावरून सुट्टी मिळेल.\n",
      "eng_Latn: We can make a movie plan!\n",
      "mar_Deva: mar_Deva eng_Latn आपण चित्रपटाची योजना बनवू शकतो!\n",
      "eng_Latn: That's a good news!\n",
      "mar_Deva: mar_Deva eng_Latn ही चांगली बातमी आहे!\n",
      "eng_Latn: Why is it a holiday though?\n",
      "mar_Deva: mar_Deva eng_Latn पण ही सुट्टी का आहे?\n",
      "eng_Latn: Are all schools, colleges and offices closed tomorrow?\n",
      "mar_Deva: mar_Deva eng_Latn सर्व शाळा, महाविद्यालये आणि कार्यालये उद्या बंद आहेत का?\n",
      "eng_Latn: It is Ambedkar Jayanti tomorrow!\n",
      "mar_Deva: mar_Deva eng_Latn उद्या आंबेडकर जयंती आहे!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "translations = batch_translate(\n",
    "    input_sentences,\n",
    "    src_lang=\"eng_Latn\",\n",
    "    tgt_lang=\"mar_Deva\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    ip=ip,\n",
    "    device=DEVICE,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "for input_sentence, translation in zip(input_sentences[:10], translations[:10]):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a7590e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "आई, उद्या चित्रपट बघायला जाऊ.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def remove_prefix(translations, prefix):\n",
    "    ans = []\n",
    "    for t in translations:\n",
    "        t = t.strip()\n",
    "        if t.startswith(prefix):\n",
    "            t = t[len(prefix):]\n",
    "        t = re.sub(r'\\.+', '.', t)\n",
    "        ans.append(t)\n",
    "    return ans\n",
    "\n",
    "translations_mar = remove_prefix(translations, \"mar_Deva eng_Latn \")\n",
    "print(translations_mar[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "558c6e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 47/47 [05:19<00:00,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng_Latn: Mom, let's go for a movie tomorrow.\n",
      "mar_Deva: mar_Deva eng_Latn माँ, चल कल सिनेमा में जाते हैं..........,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "eng_Latn: I don't have to go to school.\n",
      "mar_Deva: mar_Deva eng_Latn स्कूल जाने की आवश्यकता ही नहीं है..............................................................................................................................................................................................................................................\n",
      "eng_Latn: It is a holiday.\n",
      "mar_Deva: वो एक अवकाश है...........................................................................................................................................................................................................................................................\n",
      "eng_Latn: Oh, tomorrow is the 14th of April right?\n",
      "mar_Deva: mar_Deva eng_Latn ओह, कल 14अप्रैल है, है ना?.......,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "eng_Latn: Your dad will also have the day off from work.\n",
      "mar_Deva: mar_Deva eng_Latn आपके पिता को भी काम से एक दिन की अवकाश मिल रहा है........................................................................................................................................................................................................................................\n",
      "eng_Latn: We can make a movie plan!\n",
      "mar_Deva: mar_Deva eng_Latn हम एक फिल्म की योजना बना सकते हैं!\n",
      "eng_Latn: That's a good news!\n",
      "mar_Deva: ये तो एक खुश खबरी है...!....................................................................................................................................................................................................................................................\n",
      "eng_Latn: Why is it a holiday though?\n",
      "mar_Deva: फिर भी, वह एक अवकाश क्यों है?,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "eng_Latn: Are all schools, colleges and offices closed tomorrow?\n",
      "mar_Deva: mar_Deva eng_Latn सब स्कूल, कॉलेज और ऑफिस कल बंद होते हैं?\n",
      "eng_Latn: It is Ambedkar Jayanti tomorrow!\n",
      "mar_Deva: mar_Deva eng_Latn कल आंबेडकर जयंती है!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "translations = batch_translate(\n",
    "    input_sentences,\n",
    "    src_lang=\"eng_Latn\",\n",
    "    tgt_lang=\"hin_Deva\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    ip=ip,\n",
    "    device=DEVICE,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "for input_sentence, translation in zip(input_sentences[:10], translations[:10]):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0857328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved predictions to thenlpresearcher/in22_conv_eng_mar_hin/without_outputs.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "\n",
    "# -------------------- SAVE OUTPUTS --------------------\n",
    "results_df = pd.DataFrame({\n",
    "    \"src\": src_sentences,\n",
    "    \"prediction_mar\": translations_mar,\n",
    "    \"prediction_hin\": translations_hin,\n",
    "    \"gt_mar\": gt_mar,\n",
    "    \"gt_hin\": gt_hin\n",
    "})\n",
    "\n",
    "import os\n",
    "os.makedirs(dataset_name, exist_ok=True)\n",
    "results_df.to_csv(f\"{dataset_name}/{mode}_outputs.csv\", index=False)\n",
    "print(f\"✔ Saved predictions to {dataset_name}/{mode}_outputs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ce59341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- METRICS --------------------\n",
    "bleu = load(\"sacrebleu\")\n",
    "chrf = load(\"chrf\")\n",
    "\n",
    "def compute_scores(preds, ref1):\n",
    "    \"\"\"\n",
    "    Compute BLEU and chrF++ scores using all three references for each sentence.\n",
    "    \"\"\"\n",
    "    references = [[r1] for r1 in ref1]  # sacrebleu format\n",
    "    bleu_score = bleu.compute(predictions=preds, references=references)[\"score\"]\n",
    "    chrf_score = chrf.compute(predictions=preds, references=references)[\"score\"]\n",
    "    return bleu_score, chrf_score\n",
    "\n",
    "bleu_score_mar, chrf_score_mar = compute_scores(translations_mar, gt_mar)\n",
    "bleu_score_hin, chrf_score_hin = compute_scores(translations_hin, gt_hin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e9c2e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics -- Marathi\n",
      "BLEU: 16.674078534665142, CHRF++: 49.68337569456086\n",
      "Metrics -- Hindi\n",
      "BLEU: 26.3837176743007 CHRF++: 48.309698872187774\n"
     ]
    }
   ],
   "source": [
    "print('Metrics -- Marathi')\n",
    "print(f\"BLEU: {bleu_score_mar}, CHRF++: {chrf_score_mar}\")\n",
    "\n",
    "print('Metrics -- Hindi')\n",
    "print(f\"BLEU: {bleu_score_hin} CHRF++: {chrf_score_hin}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c96b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37c2a440",
   "metadata": {},
   "source": [
    "### With Punctuation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8961c9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"with\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9894ca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = with_punct_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48bc691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name, \n",
    "    trust_remote_code=True, \n",
    "    torch_dtype=torch.float16, # performance might slightly vary for bfloat16\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36894a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 47/47 [01:54<00:00,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng_Latn: Mom, let's go for a movie tomorrow.\n",
      "mar_Deva: mar_Deva eng_Latn आई, उद्या चित्रपट बघायला जाऊ.\n",
      "eng_Latn: I don't have to go to school.\n",
      "mar_Deva: mar_Deva eng_Latn मला शाळेत जाण्याची गरज नाही.\n",
      "eng_Latn: It is a holiday.\n",
      "mar_Deva: mar_Deva eng_Latn ती सुट्टी असते.\n",
      "eng_Latn: Oh, tomorrow is the 14th of April right?\n",
      "mar_Deva: mar_Deva eng_Latn अरे, उद्या 14 एप्रिल आहे ना?\n",
      "eng_Latn: Your dad will also have the day off from work.\n",
      "mar_Deva: mar_Deva eng_Latn तुमच्या वडिलांनाही कामावरून सुट्टी मिळेल.\n",
      "eng_Latn: We can make a movie plan!\n",
      "mar_Deva: mar_Deva eng_Latn आपण चित्रपटाची योजना बनवू शकतो!\n",
      "eng_Latn: That's a good news!\n",
      "mar_Deva: mar_Deva eng_Latn ही चांगली बातमी आहे!\n",
      "eng_Latn: Why is it a holiday though?\n",
      "mar_Deva: mar_Deva eng_Latn पण ही सुट्टी का आहे?\n",
      "eng_Latn: Are all schools, colleges and offices closed tomorrow?\n",
      "mar_Deva: mar_Deva eng_Latn सर्व शाळा, महाविद्यालये आणि कार्यालये उद्या बंद आहेत का?\n",
      "eng_Latn: It is Ambedkar Jayanti tomorrow!\n",
      "mar_Deva: mar_Deva eng_Latn उद्या आंबेडकर जयंती आहे!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "translations = batch_translate(\n",
    "    input_sentences,\n",
    "    src_lang=\"eng_Latn\",\n",
    "    tgt_lang=\"mar_Deva\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    ip=ip,\n",
    "    device=DEVICE,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "for input_sentence, translation in zip(input_sentences[:10], translations[:10]):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "537665a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "आई, उद्या चित्रपट बघायला जाऊ.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def remove_prefix(translations, prefix):\n",
    "    ans = []\n",
    "    for t in translations:\n",
    "        t = t.strip()\n",
    "        if t.startswith(prefix):\n",
    "            t = t[len(prefix):]\n",
    "        t = re.sub(r'\\.+', '.', t)\n",
    "        ans.append(t)\n",
    "    return ans\n",
    "\n",
    "translations_mar = remove_prefix(translations, \"mar_Deva eng_Latn \")\n",
    "print(translations_mar[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5a403ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 47/47 [04:05<00:00,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng_Latn: Mom, let's go for a movie tomorrow.\n",
      "mar_Deva: mar_Deva eng_Latn माँ, चलो कल सिनेमा के लिए जाते हैं.\n",
      "eng_Latn: I don't have to go to school.\n",
      "mar_Deva: mar_Deva eng_Latn मुझे स्कूल नहीं जाना है.\n",
      "eng_Latn: It is a holiday.\n",
      "mar_Deva: mar_Deva eng_Latn वह एक अवकाश है।\n",
      "eng_Latn: Oh, tomorrow is the 14th of April right?\n",
      "mar_Deva: mar_Deva eng_Latn ओह, कल 14 एप्रिल है ना?\n",
      "eng_Latn: Your dad will also have the day off from work.\n",
      "mar_Deva: mar_Deva eng_Latn आपके पिता को भी काम से एक दिन की अवकाश मिल रहा है.\n",
      "eng_Latn: We can make a movie plan!\n",
      "mar_Deva: mar_Deva eng_Latn हम एक फिल्म की योजना बना सकते हैं!\n",
      "eng_Latn: That's a good news!\n",
      "mar_Deva: mar_Deva eng_Latn ये एक खुश खबर है!\n",
      "eng_Latn: Why is it a holiday though?\n",
      "mar_Deva: mar_Deva eng_Latn फिर भी ये अवकाश क्यों है?\n",
      "eng_Latn: Are all schools, colleges and offices closed tomorrow?\n",
      "mar_Deva: mar_Deva eng_Latn सब स्कूल, कॉलेज और ऑफिस कल बंद होते हैं?\n",
      "eng_Latn: It is Ambedkar Jayanti tomorrow!\n",
      "mar_Deva: mar_Deva eng_Latn कल आंबेडकर जयंती है!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "translations = batch_translate(\n",
    "    input_sentences,\n",
    "    src_lang=\"eng_Latn\",\n",
    "    tgt_lang=\"hin_Deva\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    ip=ip,\n",
    "    device=DEVICE,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "for input_sentence, translation in zip(input_sentences[:10], translations[:10]):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5c7037a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved predictions to thenlpresearcher/in22_conv_eng_mar_hin/with_outputs.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "\n",
    "# -------------------- SAVE OUTPUTS --------------------\n",
    "results_df = pd.DataFrame({\n",
    "    \"src\": src_sentences,\n",
    "    \"prediction_mar\": translations_mar,\n",
    "    \"prediction_hin\": translations_hin,\n",
    "    \"gt_mar\": gt_mar,\n",
    "    \"gt_hin\": gt_hin\n",
    "})\n",
    "\n",
    "\n",
    "import os\n",
    "os.makedirs(dataset_name, exist_ok=True)\n",
    "results_df.to_csv(f\"{dataset_name}/{mode}_outputs.csv\", index=False)\n",
    "print(f\"✔ Saved predictions to {dataset_name}/{mode}_outputs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8980eb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- METRICS --------------------\n",
    "bleu = load(\"sacrebleu\")\n",
    "chrf = load(\"chrf\")\n",
    "\n",
    "def compute_scores(preds, ref1):\n",
    "    \"\"\"\n",
    "    Compute BLEU and chrF++ scores using all three references for each sentence.\n",
    "    \"\"\"\n",
    "    references = [[r1] for r1 in ref1]  # sacrebleu format\n",
    "    bleu_score = bleu.compute(predictions=preds, references=references)[\"score\"]\n",
    "    chrf_score = chrf.compute(predictions=preds, references=references)[\"score\"]\n",
    "    return bleu_score, chrf_score\n",
    "\n",
    "bleu_score_mar, chrf_score_mar = compute_scores(translations_mar, gt_mar)\n",
    "bleu_score_hin, chrf_score_hin = compute_scores(translations_hin, gt_hin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4df7305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics -- Marathi\n",
      "BLEU: 16.078959081533664, CHRF++: 49.770554463446146\n",
      "Metrics -- Hindi\n",
      "BLEU: 26.3837176743007 CHRF++: 48.309698872187774\n"
     ]
    }
   ],
   "source": [
    "print('Metrics -- Marathi')\n",
    "print(f\"BLEU: {bleu_score_mar}, CHRF++: {chrf_score_mar}\")\n",
    "\n",
    "print('Metrics -- Hindi')\n",
    "print(f\"BLEU: {bleu_score_hin} CHRF++: {chrf_score_hin}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dae3a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e29b2546",
   "metadata": {},
   "source": [
    "### Combined Punctuation Model (2x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a77b174",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"combined_2x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53d4ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = combined_2x_punct_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9800538",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name, \n",
    "    trust_remote_code=True, \n",
    "    torch_dtype=torch.float16, # performance might slightly vary for bfloat16\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c94a145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 47/47 [02:06<00:00,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng_Latn: Mom, let's go for a movie tomorrow.\n",
      "mar_Deva: mar_Deva eng_Latn आई, उद्या एखाद्या चित्रपटाला जाऊ.\n",
      "eng_Latn: I don't have to go to school.\n",
      "mar_Deva: mar_Deva eng_Latn मला शाळेत जाण्याची गरज नाही.\n",
      "eng_Latn: It is a holiday.\n",
      "mar_Deva: mar_Deva eng_Latn ती सुट्टी असते.\n",
      "eng_Latn: Oh, tomorrow is the 14th of April right?\n",
      "mar_Deva: mar_Deva eng_Latn अरे, उद्या 14 एप्रिल आहे ना?\n",
      "eng_Latn: Your dad will also have the day off from work.\n",
      "mar_Deva: mar_Deva eng_Latn तुमच्या वडिलांनाही कामावरून सुट्टी मिळेल.\n",
      "eng_Latn: We can make a movie plan!\n",
      "mar_Deva: mar_Deva eng_Latn आपण चित्रपटाची योजना बनवू शकतो!\n",
      "eng_Latn: That's a good news!\n",
      "mar_Deva: mar_Deva eng_Latn ही चांगली बातमी आहे!\n",
      "eng_Latn: Why is it a holiday though?\n",
      "mar_Deva: mar_Deva eng_Latn पण ती सुट्टी का असते?\n",
      "eng_Latn: Are all schools, colleges and offices closed tomorrow?\n",
      "mar_Deva: mar_Deva eng_Latn सर्व शाळा, महाविद्यालये आणि कार्यालये उद्या बंद आहेत का?\n",
      "eng_Latn: It is Ambedkar Jayanti tomorrow!\n",
      "mar_Deva: mar_Deva eng_Latn उद्या आंबेडकर जयंती आहे!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "translations = batch_translate(\n",
    "    input_sentences,\n",
    "    src_lang=\"eng_Latn\",\n",
    "    tgt_lang=\"mar_Deva\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    ip=ip,\n",
    "    device=DEVICE,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "for input_sentence, translation in zip(input_sentences[:10], translations[:10]):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a28cae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "आई, उद्या एखाद्या चित्रपटाला जाऊ.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def remove_prefix(translations, prefix):\n",
    "    ans = []\n",
    "    for t in translations:\n",
    "        t = t.strip()\n",
    "        if t.startswith(prefix):\n",
    "            t = t[len(prefix):]\n",
    "        t = re.sub(r'\\.+', '.', t)\n",
    "        ans.append(t)\n",
    "    return ans\n",
    "\n",
    "translations_mar = remove_prefix(translations, \"mar_Deva eng_Latn \")\n",
    "print(translations_mar[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2929be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 47/47 [06:00<00:00,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng_Latn: Mom, let's go for a movie tomorrow.\n",
      "mar_Deva: mar_Deva eng_Latn माँ, कल फिल्म देखने चलते हैं हम.............................................................................................................................................................................................................................................\n",
      "eng_Latn: I don't have to go to school.\n",
      "mar_Deva: mar_Deva eng_Latn मुझे स्कूल जाने की कोई आवश्यकता नहीं है.............................................................................................................................................................................................................................................\n",
      "eng_Latn: It is a holiday.\n",
      "mar_Deva: यह एक अवकाश है।\n",
      "eng_Latn: Oh, tomorrow is the 14th of April right?\n",
      "mar_Deva: mar_Deva eng_Latn ओह, कल 14अप्रिल है, है ना?.........................................................................................................................................................................................................................................\n",
      "eng_Latn: Your dad will also have the day off from work.\n",
      "mar_Deva: mar_Deva eng_Latn आपके पिता को भी काम से एक दिन की छुट्टी मिलनी चाहिए थी।\n",
      "eng_Latn: We can make a movie plan!\n",
      "mar_Deva: हम एक फिल्म की योजना बना सकते हैं!\n",
      "eng_Latn: That's a good news!\n",
      "mar_Deva: ये तो एक खुश खबरी है........................................................................................................................................................................................................................................................\n",
      "eng_Latn: Why is it a holiday though?\n",
      "mar_Deva: फिर भी, यह एक अवकाश क्यों है?\n",
      "eng_Latn: Are all schools, colleges and offices closed tomorrow?\n",
      "mar_Deva: mar_Deva eng_Latn क्या कल सब स्कूल, कॉलेज और ऑफिस बंद हो जाते हैं?\n",
      "eng_Latn: It is Ambedkar Jayanti tomorrow!\n",
      "mar_Deva: कल आम्बेदकर जयंती है!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "translations = batch_translate(\n",
    "    input_sentences,\n",
    "    src_lang=\"eng_Latn\",\n",
    "    tgt_lang=\"hin_Deva\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    ip=ip,\n",
    "    device=DEVICE,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "for input_sentence, translation in zip(input_sentences[:10], translations[:10]):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4530c915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved predictions to thenlpresearcher/in22_conv_eng_mar_hin/combined_2x_outputs.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "\n",
    "# -------------------- SAVE OUTPUTS --------------------\n",
    "results_df = pd.DataFrame({\n",
    "    \"src\": src_sentences,\n",
    "    \"prediction_mar\": translations_mar,\n",
    "    \"prediction_hin\": translations_hin,\n",
    "    \"gt_mar\": gt_mar,\n",
    "    \"gt_hin\": gt_hin\n",
    "})\n",
    "\n",
    "import os\n",
    "os.makedirs(dataset_name, exist_ok=True)\n",
    "results_df.to_csv(f\"{dataset_name}/{mode}_outputs.csv\", index=False)\n",
    "print(f\"✔ Saved predictions to {dataset_name}/{mode}_outputs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0937ed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- METRICS --------------------\n",
    "bleu = load(\"sacrebleu\")\n",
    "chrf = load(\"chrf\")\n",
    "\n",
    "def compute_scores(preds, ref1):\n",
    "    \"\"\"\n",
    "    Compute BLEU and chrF++ scores using all three references for each sentence.\n",
    "    \"\"\"\n",
    "    references = [[r1] for r1 in ref1]  # sacrebleu format\n",
    "    bleu_score = bleu.compute(predictions=preds, references=references)[\"score\"]\n",
    "    chrf_score = chrf.compute(predictions=preds, references=references)[\"score\"]\n",
    "    return bleu_score, chrf_score\n",
    "\n",
    "bleu_score_mar, chrf_score_mar = compute_scores(translations_mar, gt_mar)\n",
    "bleu_score_hin, chrf_score_hin = compute_scores(translations_hin, gt_hin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40790dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics -- Marathi\n",
      "BLEU: 17.930452115794093, CHRF++: 50.44942453145798\n",
      "Metrics -- Hindi\n",
      "BLEU: 26.3837176743007 CHRF++: 48.309698872187774\n"
     ]
    }
   ],
   "source": [
    "print('Metrics -- Marathi')\n",
    "print(f\"BLEU: {bleu_score_mar}, CHRF++: {chrf_score_mar}\")\n",
    "\n",
    "print('Metrics -- Hindi')\n",
    "print(f\"BLEU: {bleu_score_hin} CHRF++: {chrf_score_hin}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901eb1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48215a33",
   "metadata": {},
   "source": [
    "### Combined Punctuation Model (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e6747135",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"combined_x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f28f36f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = combined_x_punct_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6543fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name, \n",
    "    trust_remote_code=True, \n",
    "    torch_dtype=torch.float16, # performance might slightly vary for bfloat16\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7ca720ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 47/47 [02:57<00:00,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng_Latn: Mom, let's go for a movie tomorrow.\n",
      "mar_Deva: mar_Deva eng_Latn आई, उद्या एखाद्या चित्रपटाला जाऊ.\n",
      "eng_Latn: I don't have to go to school.\n",
      "mar_Deva: mar_Deva eng_Latn मला शाळेत जाण्याची गरज नाही.\n",
      "eng_Latn: It is a holiday.\n",
      "mar_Deva: mar_Deva eng_Latn ती सुट्टी असते.\n",
      "eng_Latn: Oh, tomorrow is the 14th of April right?\n",
      "mar_Deva: mar_Deva eng_Latn अरे, उद्या 14 एप्रिल आहे ना?\n",
      "eng_Latn: Your dad will also have the day off from work.\n",
      "mar_Deva: mar_Deva eng_Latn तुमच्या वडिलांनाही कामावरून सुट्टी मिळेल.\n",
      "eng_Latn: We can make a movie plan!\n",
      "mar_Deva: mar_Deva eng_Latn आपण चित्रपटाची योजना बनवू शकतो!\n",
      "eng_Latn: That's a good news!\n",
      "mar_Deva: mar_Deva eng_Latn ही चांगली बातमी आहे!\n",
      "eng_Latn: Why is it a holiday though?\n",
      "mar_Deva: मात्र, ती सुट्टी का असते?\n",
      "eng_Latn: Are all schools, colleges and offices closed tomorrow?\n",
      "mar_Deva: mar_Deva eng_Latn सर्व शाळा, महाविद्यालये आणि कार्यालये उद्या बंद आहेत का?\n",
      "eng_Latn: It is Ambedkar Jayanti tomorrow!\n",
      "mar_Deva: mar_Deva eng_Latn उद्या आंबेडकर जयंती आहे!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "translations = batch_translate(\n",
    "    input_sentences,\n",
    "    src_lang=\"eng_Latn\",\n",
    "    tgt_lang=\"mar_Deva\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    ip=ip,\n",
    "    device=DEVICE,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "for input_sentence, translation in zip(input_sentences[:10], translations[:10]):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "44561edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "आई, उद्या एखाद्या चित्रपटाला जाऊ.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def remove_prefix(translations, prefix):\n",
    "    ans = []\n",
    "    for t in translations:\n",
    "        t = t.strip()\n",
    "        if t.startswith(prefix):\n",
    "            t = t[len(prefix):]\n",
    "        t = re.sub(r'\\.+', '.', t)\n",
    "        ans.append(t)\n",
    "    return ans\n",
    "\n",
    "translations_mar = remove_prefix(translations, \"mar_Deva eng_Latn \")\n",
    "print(translations_mar[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "781d5246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 47/47 [06:22<00:00,  8.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng_Latn: Mom, let's go for a movie tomorrow.\n",
      "mar_Deva: mar_Deva eng_Latn माँ, चलो कल एक फिल्म देखने जाते हैं। \"\n",
      "eng_Latn: I don't have to go to school.\n",
      "mar_Deva: mar_Deva eng_Latn मुझे स्कूल जाने की कोई आवश्यकता नहीं है।\n",
      "eng_Latn: It is a holiday.\n",
      "mar_Deva: यह छुट्टी का दिन होता है।\n",
      "eng_Latn: Oh, tomorrow is the 14th of April right?\n",
      "mar_Deva: mar_Deva eng_Latn ओह, कल 14 अप्रैल की तारीख है, है ना?\n",
      "eng_Latn: Your dad will also have the day off from work.\n",
      "mar_Deva: mar_Deva eng_Latn आपके पिता को भी काम से एक दिन की छुट्टी मिलनी तय है।\n",
      "eng_Latn: We can make a movie plan!\n",
      "mar_Deva: हम एक फिल्म की योजना बना सकते हैं!\n",
      "eng_Latn: That's a good news!\n",
      "mar_Deva: ये तो एक अच्छी खबर है.........................................................................................................................................................................................................................................................\n",
      "eng_Latn: Why is it a holiday though?\n",
      "mar_Deva: फिर भी, यह छुट्टी क्यों है?\n",
      "eng_Latn: Are all schools, colleges and offices closed tomorrow?\n",
      "mar_Deva: mar_Deva eng_Latn क्या कल सब स्कूल, कॉलेज और ऑफिस बंद हो जाते हैं?\n",
      "eng_Latn: It is Ambedkar Jayanti tomorrow!\n",
      "mar_Deva: कल आम्बेदकर जयंती है!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "translations = batch_translate(\n",
    "    input_sentences,\n",
    "    src_lang=\"eng_Latn\",\n",
    "    tgt_lang=\"hin_Deva\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    ip=ip,\n",
    "    device=DEVICE,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "for input_sentence, translation in zip(input_sentences[:10], translations[:10]):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d15dd037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved predictions to thenlpresearcher/in22_conv_eng_mar_hin/combined_x_outputs.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "\n",
    "# -------------------- SAVE OUTPUTS --------------------\n",
    "results_df = pd.DataFrame({\n",
    "    \"src\": src_sentences,\n",
    "    \"prediction_mar\": translations_mar,\n",
    "    \"prediction_hin\": translations_hin,\n",
    "    \"gt_mar\": gt_mar,\n",
    "    \"gt_hin\": gt_hin\n",
    "})\n",
    "\n",
    "import os\n",
    "os.makedirs(dataset_name, exist_ok=True)\n",
    "results_df.to_csv(f\"{dataset_name}/{mode}_outputs.csv\", index=False)\n",
    "print(f\"✔ Saved predictions to {dataset_name}/{mode}_outputs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "802993f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- METRICS --------------------\n",
    "bleu = load(\"sacrebleu\")\n",
    "chrf = load(\"chrf\")\n",
    "\n",
    "def compute_scores(preds, ref1):\n",
    "    \"\"\"\n",
    "    Compute BLEU and chrF++ scores using all three references for each sentence.\n",
    "    \"\"\"\n",
    "    references = [[r1] for r1 in ref1]  # sacrebleu format\n",
    "    bleu_score = bleu.compute(predictions=preds, references=references)[\"score\"]\n",
    "    chrf_score = chrf.compute(predictions=preds, references=references)[\"score\"]\n",
    "    return bleu_score, chrf_score\n",
    "\n",
    "bleu_score_mar, chrf_score_mar = compute_scores(translations_mar, gt_mar)\n",
    "bleu_score_hin, chrf_score_hin = compute_scores(translations_hin, gt_hin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cad2809e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics -- Marathi\n",
      "BLEU: 17.874171775737672, CHRF++: 50.339241451649706\n",
      "Metrics -- Hindi\n",
      "BLEU: 26.3837176743007 CHRF++: 48.309698872187774\n"
     ]
    }
   ],
   "source": [
    "print('Metrics -- Marathi')\n",
    "print(f\"BLEU: {bleu_score_mar}, CHRF++: {chrf_score_mar}\")\n",
    "\n",
    "print('Metrics -- Hindi')\n",
    "print(f\"BLEU: {bleu_score_hin} CHRF++: {chrf_score_hin}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5dab40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73ef0377",
   "metadata": {},
   "source": [
    "## T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2202958",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = original_model_name\n",
    "mode = \"t5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e4685108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Use batching + GPU (if available)\n",
    "punctuator_pipeline = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"thenlpresearcher/iitb-t5-finetuned-punctuation\",\n",
    "    device=device,            # GPU; use device=-1 for CPU\n",
    "    batch_size=64        # adjust based on GPU RAM\n",
    ")\n",
    "\n",
    "def restore_punctuation_t5_batch(text_list):\n",
    "    # The pipeline automatically batches under the hood\n",
    "    outputs = punctuator_pipeline(\n",
    "        text_list,\n",
    "        max_length=128\n",
    "    )\n",
    "    # Pipeline returns list of dicts\n",
    "    return [o[\"generated_text\"] for o in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fed51b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1503\n"
     ]
    }
   ],
   "source": [
    "# Run the whole batch in parallel\n",
    "predicted_sentences = restore_punctuation_t5_batch(src_sentences)\n",
    "print(len(predicted_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a4f93173",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentences = predicted_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c06443a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 47/47 [03:05<00:00,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng_Latn: Mom, let's go for a movie tomorrow.\n",
      "mar_Deva: mar_Deva eng_Latn आई, उद्या एखाद्या चित्रपटाला जाऊ.\n",
      "eng_Latn: I don't have to go to school.\n",
      "mar_Deva: mar_Deva eng_Latn मला शाळेत जाण्याची गरज नाही.\n",
      "eng_Latn: It is a holiday.\n",
      "mar_Deva: mar_Deva eng_Latn ती सुट्टी असते.\n",
      "eng_Latn: Oh, tomorrow is the 14th of April, right?\n",
      "mar_Deva: mar_Deva eng_Latn अरे, उद्या 14 एप्रिल आहे ना?\n",
      "eng_Latn: Your dad will also have the day off from work.\n",
      "mar_Deva: mar_Deva eng_Latn तुमच्या वडिलांनाही कामावरून सुट्टी मिळेल.\n",
      "eng_Latn: We can make a movie plan!\n",
      "mar_Deva: mar_Deva eng_Latn आपण चित्रपटाची योजना बनवू शकतो!\n",
      "eng_Latn: That's a good news!\n",
      "mar_Deva: mar_Deva eng_Latn ही चांगली बातमी आहे!\n",
      "eng_Latn: Why is it a holiday though?\n",
      "mar_Deva: मात्र, ती सुट्टी का असते?\n",
      "eng_Latn: Are all schools, colleges and offices closed tomorrow?\n",
      "mar_Deva: mar_Deva eng_Latn सर्व शाळा, महाविद्यालये आणि कार्यालये उद्या बंद आहेत का?\n",
      "eng_Latn: It is Ambedkar Jayanti tomorrow!\n",
      "mar_Deva: mar_Deva eng_Latn उद्या आंबेडकर जयंती आहे!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "translations = batch_translate(\n",
    "    input_sentences,\n",
    "    src_lang=\"eng_Latn\",\n",
    "    tgt_lang=\"mar_Deva\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    ip=ip,\n",
    "    device=DEVICE,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "for input_sentence, translation in zip(input_sentences[:10], translations[:10]):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "19f9c3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "आई, उद्या एखाद्या चित्रपटाला जाऊ.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def remove_prefix(translations, prefix):\n",
    "    ans = []\n",
    "    for t in translations:\n",
    "        t = t.strip()\n",
    "        if t.startswith(prefix):\n",
    "            t = t[len(prefix):]\n",
    "        t = re.sub(r'\\.+', '.', t)\n",
    "        ans.append(t)\n",
    "    return ans\n",
    "\n",
    "translations_mar = remove_prefix(translations, \"mar_Deva eng_Latn \")\n",
    "print(translations_mar[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c1f05662",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 47/47 [06:17<00:00,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng_Latn: Mom, let's go for a movie tomorrow.\n",
      "mar_Deva: mar_Deva eng_Latn माँ, चलो कल एक फिल्म देखने जाते हैं। \"\n",
      "eng_Latn: I don't have to go to school.\n",
      "mar_Deva: mar_Deva eng_Latn मुझे स्कूल जाने की कोई आवश्यकता नहीं है।\n",
      "eng_Latn: It is a holiday.\n",
      "mar_Deva: यह छुट्टी का दिन होता है।\n",
      "eng_Latn: Oh, tomorrow is the 14th of April, right?\n",
      "mar_Deva: mar_Deva eng_Latn ओह, कल 14 अप्रैल की तारीख है, है ना?\n",
      "eng_Latn: Your dad will also have the day off from work.\n",
      "mar_Deva: mar_Deva eng_Latn आपके पिता को भी काम से एक दिन की छुट्टी मिलनी तय है।\n",
      "eng_Latn: We can make a movie plan!\n",
      "mar_Deva: हम एक फिल्म की योजना बना सकते हैं!\n",
      "eng_Latn: That's a good news!\n",
      "mar_Deva: ये तो एक अच्छी खबर है.........................................................................................................................................................................................................................................................\n",
      "eng_Latn: Why is it a holiday though?\n",
      "mar_Deva: फिर भी, यह छुट्टी क्यों है?\n",
      "eng_Latn: Are all schools, colleges and offices closed tomorrow?\n",
      "mar_Deva: mar_Deva eng_Latn क्या कल सब स्कूल, कॉलेज और ऑफिस बंद हो जाते हैं?\n",
      "eng_Latn: It is Ambedkar Jayanti tomorrow!\n",
      "mar_Deva: कल आम्बेदकर जयंती है!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "translations = batch_translate(\n",
    "    input_sentences,\n",
    "    src_lang=\"eng_Latn\",\n",
    "    tgt_lang=\"hin_Deva\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    ip=ip,\n",
    "    device=DEVICE,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "for input_sentence, translation in zip(input_sentences[:10], translations[:10]):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3e0eff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved predictions to thenlpresearcher/in22_conv_eng_mar_hin/t5_outputs.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "\n",
    "# -------------------- SAVE OUTPUTS --------------------\n",
    "results_df = pd.DataFrame({\n",
    "    \"src\": src_sentences,\n",
    "    \"prediction_mar\": translations_mar,\n",
    "    \"prediction_hin\": translations_hin,\n",
    "    \"gt_mar\": gt_mar,\n",
    "    \"gt_hin\": gt_hin\n",
    "})\n",
    "\n",
    "import os\n",
    "os.makedirs(dataset_name, exist_ok=True)\n",
    "results_df.to_csv(f\"{dataset_name}/{mode}_outputs.csv\", index=False)\n",
    "print(f\"✔ Saved predictions to {dataset_name}/{mode}_outputs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3cfdafc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- METRICS --------------------\n",
    "bleu = load(\"sacrebleu\")\n",
    "chrf = load(\"chrf\")\n",
    "\n",
    "def compute_scores(preds, ref1):\n",
    "    \"\"\"\n",
    "    Compute BLEU and chrF++ scores using all three references for each sentence.\n",
    "    \"\"\"\n",
    "    references = [[r1] for r1 in ref1]  # sacrebleu format\n",
    "    bleu_score = bleu.compute(predictions=preds, references=references)[\"score\"]\n",
    "    chrf_score = chrf.compute(predictions=preds, references=references)[\"score\"]\n",
    "    return bleu_score, chrf_score\n",
    "\n",
    "bleu_score_mar, chrf_score_mar = compute_scores(translations_mar, gt_mar)\n",
    "bleu_score_hin, chrf_score_hin = compute_scores(translations_hin, gt_hin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "86a5476b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics -- Marathi\n",
      "BLEU: 17.822822344140665, CHRF++: 50.23633412097026\n",
      "Metrics -- Hindi\n",
      "BLEU: 26.3837176743007 CHRF++: 48.309698872187774\n"
     ]
    }
   ],
   "source": [
    "print('Metrics -- Marathi')\n",
    "print(f\"BLEU: {bleu_score_mar}, CHRF++: {chrf_score_mar}\")\n",
    "\n",
    "print('Metrics -- Hindi')\n",
    "print(f\"BLEU: {bleu_score_hin} CHRF++: {chrf_score_hin}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61159da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7a9cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
