{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0bcbf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34c6174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfcd26d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a69eea7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec 26 12:26:29 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.163.01             Driver Version: 550.163.01     CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          Off |   00000000:17:00.0 Off |                    0 |\n",
      "| N/A   60C    P0             75W /  300W |    3713MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA A100 80GB PCIe          Off |   00000000:31:00.0 Off |                    0 |\n",
      "| N/A   46C    P0             75W /  300W |    7067MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA A100 80GB PCIe          Off |   00000000:4B:00.0 Off |                    0 |\n",
      "| N/A   61C    P0            114W /  300W |   40380MiB /  81920MiB |     23%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA A100 80GB PCIe          Off |   00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   53C    P0            114W /  300W |   37276MiB /  81920MiB |     12%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "426a093b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/Prompting/responses/ready_for_metrics\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80aa827b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(197285, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labse_tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/LaBSE\")\n",
    "labse_model = AutoModel.from_pretrained(\"sentence-transformers/LaBSE\")\n",
    "\n",
    "muril_tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\n",
    "muril_model = AutoModel.from_pretrained(\"google/muril-base-cased\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "labse_model.to(device)\n",
    "muril_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "625a265e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.10/dist-packages (4.57.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2024.5.15)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (4.66.4)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.2.1)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (4.24.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers[sentencepiece]) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers[sentencepiece]) (4.12.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers[sentencepiece]) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2024.6.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.6)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.4.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.24.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.4.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.18)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.14.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (22.0.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.9.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.12.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.2.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.9.1+cpu)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.2.1)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.57.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert-score) (1.24.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.66.4)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score) (24.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (4.12.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.1.4)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2024.5.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.36.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.7.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2024.6.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=3.0.0->bert-score) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.13.3->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.5)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bert-score\n",
      "Successfully installed bert-score-0.3.13\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: unbabel-comet in /usr/local/lib/python3.10/dist-packages (2.2.7)\n",
      "Requirement already satisfied: entmax<2.0,>=1.1 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (1.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (0.36.0)\n",
      "Requirement already satisfied: jsonargparse==3.13.1 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (3.13.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (1.24.4)\n",
      "Requirement already satisfied: pandas>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (2.2.1)\n",
      "Requirement already satisfied: protobuf<5.0.0,>=4.24.4 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (4.24.4)\n",
      "Requirement already satisfied: pytorch-lightning<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (2.6.0)\n",
      "Requirement already satisfied: sacrebleu<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (2.5.1)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (1.13.1)\n",
      "Requirement already satisfied: sentencepiece<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (0.2.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (2.9.1+cpu)\n",
      "Requirement already satisfied: torchmetrics<0.11.0,>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (0.10.3)\n",
      "Requirement already satisfied: transformers<5.0,>=4.17 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (4.57.3)\n",
      "Requirement already satisfied: PyYAML>=3.13 in /usr/local/lib/python3.10/dist-packages (from jsonargparse==3.13.1->unbabel-comet) (6.0.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2024.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (24.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (4.12.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.1->unbabel-comet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.1->unbabel-comet) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.1->unbabel-comet) (2024.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.10/dist-packages/lightning_utilities-0.11.2-py3.10.egg (from pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (0.11.2)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (3.2.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (2024.5.15)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (0.9.0)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (0.4.6)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (6.0.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet) (3.1.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.7.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (3.9.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (68.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.1->unbabel-comet) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.13.3->torch>=1.6.0->unbabel-comet) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->unbabel-comet) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2024.6.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (4.0.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.9.1+cpu)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.12.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (1.24.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.6.2)\n",
      "Downloading sentence_transformers-5.2.0-py3-none-any.whl (493 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-5.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[sentencepiece]\n",
    "!pip install evaluate\n",
    "!pip install bert-score\n",
    "!pip install unbabel-comet\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38c88edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from evaluate import load\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "def compute_translation_scores(predictions, references, lang='en'):\n",
    "    \"\"\"\n",
    "    Compute reference-based translation evaluation scores using:\n",
    "    1. BERTScore (MuRIL)\n",
    "    2. LaBSE cosine similarity\n",
    "    \n",
    "    Args:\n",
    "        predictions (list of str): Model outputs\n",
    "        references (list of str): Reference translations\n",
    "        lang (str): Language code for BERTScore ('en', 'hi', etc.)\n",
    "    \n",
    "    Returns:\n",
    "        dict: {'muril_f1': float, 'labse_cosine': float}\n",
    "    \"\"\"\n",
    "    assert len(predictions) == len(references), \"Predictions and references must have the same length\"\n",
    "\n",
    "    # ---------- BERTScore (MuRIL) ----------\n",
    "    bertscore = load(\"bertscore\")\n",
    "    bert_results = bertscore.compute(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "        model_type='google/muril-base-cased',\n",
    "        num_layers=4,\n",
    "        lang=lang\n",
    "    )\n",
    "    muril_f1_mean = float(np.mean(bert_results['f1']))\n",
    "\n",
    "    # ---------- LaBSE Cosine Similarity ----------\n",
    "    model = SentenceTransformer('sentence-transformers/LaBSE')\n",
    "    pred_emb = model.encode(predictions, convert_to_tensor=True)\n",
    "    ref_emb = model.encode(references, convert_to_tensor=True)\n",
    "    cosine_sim_matrix = util.cos_sim(pred_emb, ref_emb)\n",
    "    # Take diagonal (each prediction with its reference)\n",
    "    labse_cosine_mean = float(cosine_sim_matrix.diag().mean())\n",
    "\n",
    "    return {'muril_score': muril_f1_mean, 'labse_cosine': labse_cosine_mean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83177adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_ref_based_scores(mt_texts, ref_texts, method=\"max\"):\n",
    "#     results = []\n",
    "    \n",
    "#     for i, mt in enumerate(mt_texts):\n",
    "#         ref = ref_texts[i]\n",
    "        \n",
    "#         # Skip if empty or NaN\n",
    "#         if not mt or not ref or pd.isna(mt) or pd.isna(ref):\n",
    "#             continue\n",
    "        \n",
    "#         # --- LaBSE ---\n",
    "#         try:\n",
    "#             inputs = labse_tokenizer(ref, mt, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "#             with torch.no_grad():\n",
    "#                 embeddings = labse_model(**inputs).pooler_output\n",
    "#             if embeddings.shape[0] >= 2:\n",
    "#                 labse_ref_mt =  F.cosine_similarity(embeddings[0].unsqueeze(0), embeddings[1].unsqueeze(0)).item()\n",
    "#             else:\n",
    "#                 labse_ref_mt = 0.0\n",
    "#         except Exception as e:\n",
    "#             print(f\"Skipping LaBSE pair due to error: {e}\")\n",
    "#             labse_ref_mt = 0.0\n",
    "\n",
    "#         # --- MuRIL ---\n",
    "#         try:\n",
    "#             inputs = muril_tokenizer(ref, mt, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "#             with torch.no_grad():\n",
    "#                 outputs = muril_model(**inputs)\n",
    "#                 embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "#             if embeddings.shape[0] >= 2:\n",
    "#                 muril_ref_mt =  F.cosine_similarity(embeddings[0].unsqueeze(0), embeddings[1].unsqueeze(0)).item()\n",
    "#             else:\n",
    "#                 muril_ref_mt = 0.0\n",
    "#         except Exception as e:\n",
    "#             print(f\"Skipping MuRIL pair due to error: {e}\")\n",
    "#             muril_ref_mt = 0.0\n",
    "\n",
    "#         results.append({\n",
    "#             \"mt\": mt,\n",
    "#             \"labse_ref_mt\": labse_ref_mt,\n",
    "#             \"muril_ref_mt\": muril_ref_mt\n",
    "#         })\n",
    "    \n",
    "#     df_scores = pd.DataFrame(results)\n",
    "    \n",
    "#     # System-level averages\n",
    "#     system_scores = {\n",
    "#         \"labse_ref_mt\": df_scores[\"labse_ref_mt\"].mean() if not df_scores.empty else 0.0,\n",
    "#         \"muril_ref_mt\": df_scores[\"muril_ref_mt\"].mean() if not df_scores.empty else 0.0\n",
    "#     }\n",
    "    \n",
    "#     return system_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17218109",
   "metadata": {},
   "outputs": [],
   "source": [
    "labse = {}\n",
    "muril = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8668a414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7577f20",
   "metadata": {},
   "source": [
    "## Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebd43f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"llama_original.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fa51232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Response</th>\n",
       "      <th>sent_meant</th>\n",
       "      <th>gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chanting, the choir raised the volume as the c...</td>\n",
       "      <td>श्रद्धांजली घेतल्यानंतर, गायिका घोषवाण्याने प्...</td>\n",
       "      <td>Chanting, the choir raised the volume as the c...</td>\n",
       "      <td>धर्मगुरू प्रार्थना म्हणत असताना, घोष करणाऱ्या ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A six-month-old calf was submitted for examina...</td>\n",
       "      <td>एकूण सहा महिन्यांचा वाढतोळा ज्याला परीक्षेसाठी...</td>\n",
       "      <td>A six-month-old calf was submitted for examina...</td>\n",
       "      <td>तपासणीसाठी आणलेल्या सहा महिन्यांच्या एका वासरा...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Planning authorities should provide alternativ...</td>\n",
       "      <td>व्यवस्थापन अधिकारी लहान व्यवसायासाठी घरगुती क्...</td>\n",
       "      <td>Planning authorities should provide alternativ...</td>\n",
       "      <td>नियोजन प्राधिकरणांनी लहान व्यवसायांसाठी पर्याय...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As the machine develops, the forms we use to r...</td>\n",
       "      <td>येत्या वेळी मशीन विकसित होत असताना, आम्ही पूर्...</td>\n",
       "      <td>As the machine develops, the forms we use to r...</td>\n",
       "      <td>जसजशी यंत्रणा विकसित होईल, तसतसे मागील प्रकल्प...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As mentioned first, impressions can be mislead...</td>\n",
       "      <td>पहिल्या वेळी सांगितल्याप्रमाणे भावना वाईट वाटू...</td>\n",
       "      <td>As mentioned first, impressions can be mislead...</td>\n",
       "      <td>आधी सांगितल्याप्रमाणे, पहिली छाप फसवी असू शकते.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  Chanting, the choir raised the volume as the c...   \n",
       "1  A six-month-old calf was submitted for examina...   \n",
       "2  Planning authorities should provide alternativ...   \n",
       "3  As the machine develops, the forms we use to r...   \n",
       "4  As mentioned first, impressions can be mislead...   \n",
       "\n",
       "                                            Response  \\\n",
       "0  श्रद्धांजली घेतल्यानंतर, गायिका घोषवाण्याने प्...   \n",
       "1  एकूण सहा महिन्यांचा वाढतोळा ज्याला परीक्षेसाठी...   \n",
       "2  व्यवस्थापन अधिकारी लहान व्यवसायासाठी घरगुती क्...   \n",
       "3  येत्या वेळी मशीन विकसित होत असताना, आम्ही पूर्...   \n",
       "4  पहिल्या वेळी सांगितल्याप्रमाणे भावना वाईट वाटू...   \n",
       "\n",
       "                                          sent_meant  \\\n",
       "0  Chanting, the choir raised the volume as the c...   \n",
       "1  A six-month-old calf was submitted for examina...   \n",
       "2  Planning authorities should provide alternativ...   \n",
       "3  As the machine develops, the forms we use to r...   \n",
       "4  As mentioned first, impressions can be mislead...   \n",
       "\n",
       "                                                  gt  \n",
       "0  धर्मगुरू प्रार्थना म्हणत असताना, घोष करणाऱ्या ...  \n",
       "1  तपासणीसाठी आणलेल्या सहा महिन्यांच्या एका वासरा...  \n",
       "2  नियोजन प्राधिकरणांनी लहान व्यवसायांसाठी पर्याय...  \n",
       "3  जसजशी यंत्रणा विकसित होईल, तसतसे मागील प्रकल्प...  \n",
       "4    आधी सांगितल्याप्रमाणे, पहिली छाप फसवी असू शकते.  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66a59d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 7.95kB [00:00, 5.17MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: {'muril_score': 0.6535316021354111, 'labse_cosine': 0.8404159545898438}\n"
     ]
    }
   ],
   "source": [
    "predictions = df['Response'].tolist()\n",
    "references = df['gt'].tolist()\n",
    "\n",
    "    \n",
    "scores = compute_translation_scores(predictions, references, lang='en')\n",
    "print(\"Scores:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce22ccb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84dc06eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: sarvam_few_cot.csv, Strategy: few, Scores: {'muril_score': 0.6709941561315574, 'labse_cosine': 0.8508744239807129}\n",
      "File: llama_few_cot.csv, Strategy: few, Scores: {'muril_score': 0.6120327737401513, 'labse_cosine': 0.8194451332092285}\n",
      "File: llama_few_zero.csv, Strategy: few, Scores: {'muril_score': 0.619218980272611, 'labse_cosine': 0.8216394186019897}\n",
      "File: gemma_few_cot.csv, Strategy: few, Scores: {'muril_score': 0.7056032255584118, 'labse_cosine': 0.8925914168357849}\n",
      "File: gemma_few_zero.csv, Strategy: few, Scores: {'muril_score': 0.7013319251584071, 'labse_cosine': 0.8882648944854736}\n",
      "File: sarvam_few_zero.csv, Strategy: few, Scores: {'muril_score': 0.70191195899365, 'labse_cosine': 0.8803153038024902}\n",
      "File: llama_original.csv, Strategy: original.csv, Scores: {'muril_score': 0.6535316021354111, 'labse_cosine': 0.8404159545898438}\n",
      "File: sarvam_original.csv, Strategy: original.csv, Scores: {'muril_score': 0.655046463796967, 'labse_cosine': 0.8422093391418457}\n",
      "File: gemma_original.csv, Strategy: original.csv, Scores: {'muril_score': 0.689612994591395, 'labse_cosine': 0.8829489350318909}\n",
      "File: llama_zero_zero.csv, Strategy: zero, Scores: {'muril_score': 0.6313577675157123, 'labse_cosine': 0.8230174779891968}\n",
      "File: gemma_zero_zero.csv, Strategy: zero, Scores: {'muril_score': 0.6711749463445611, 'labse_cosine': 0.855908215045929}\n",
      "File: gemma_zero_cot.csv, Strategy: zero, Scores: {'muril_score': 0.6952221779911606, 'labse_cosine': 0.878286600112915}\n",
      "File: llama_zero_cot.csv, Strategy: zero, Scores: {'muril_score': 0.6093104489975505, 'labse_cosine': 0.8029788136482239}\n",
      "File: sarvam_zero_cot.csv, Strategy: zero, Scores: {'muril_score': 0.6468266438481942, 'labse_cosine': 0.8227871656417847}\n",
      "File: sarvam_zero_zero.csv, Strategy: zero, Scores: {'muril_score': 0.6148778684437275, 'labse_cosine': 0.8102161884307861}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# CSV folder is current directory\n",
    "csv_folder = \".\"\n",
    "\n",
    "# Collect results\n",
    "results = []\n",
    "\n",
    "for file_name in os.listdir(csv_folder):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        file_path = os.path.join(csv_folder, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        predictions = df['Response'].tolist()\n",
    "        references = df['gt'].tolist()\n",
    "\n",
    "        # Compute translation scores\n",
    "        scores = compute_translation_scores(predictions, references, lang='en')\n",
    "\n",
    "        # Append results with file info\n",
    "        results.append({\n",
    "            \"file\": file_name,\n",
    "            \"strategy\": file_name.split('_')[1],  # part after first '_'\n",
    "            \"scores\": scores\n",
    "        })\n",
    "\n",
    "# Sort results by strategy (the word after the first '_')\n",
    "results_sorted = sorted(results, key=lambda x: x['strategy'])\n",
    "\n",
    "# Print sorted results\n",
    "for r in results_sorted:\n",
    "    print(f\"File: {r['file']}, Strategy: {r['strategy']}, Scores: {r['scores']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6725d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = df['Response'].tolist()\n",
    "# references = df['gt'].tolist()\n",
    "\n",
    "# print(predictions[:5])\n",
    "# print(references[:5])\n",
    "\n",
    "# scores = compute_ref_based_scores(predictions, references)\n",
    "# labse = scores['labse_ref_mt']\n",
    "# muril= scores['muril_ref_mt']\n",
    "\n",
    "# print(f\"LaBSE and MuRIL Scores for {file_name}:\")\n",
    "# print(labse, muril)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc8c160",
   "metadata": {},
   "source": [
    "## Only Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aca6ac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"with_outputs.csv\"\n",
    "mode = \"with\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2898b7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaBSE and MuRIL Scores for with:\n",
      "{'labse_ref_mt': 0.9197827294812637, 'muril_ref_mt': 0.9981659788903645}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file_name)\n",
    "\n",
    "predictions = df['prediction_mar'].tolist()\n",
    "references = df['gt_mar'].tolist()\n",
    "\n",
    "scores = compute_ref_based_scores(predictions, references)\n",
    "labse[mode] = scores['labse_ref_mt']\n",
    "muril[mode] = scores['muril_ref_mt']\n",
    "\n",
    "print(f\"LaBSE and MuRIL Scores for {mode}:\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408c8715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "728ae494",
   "metadata": {},
   "source": [
    "## Without Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c15cc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"without_outputs.csv\"\n",
    "mode = \"without\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3230e1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaBSE and MuRIL Scores for without:\n",
      "{'labse_ref_mt': 0.9201303059861079, 'muril_ref_mt': 0.9981740449472081}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file_name)\n",
    "\n",
    "predictions = df['prediction_mar'].tolist()\n",
    "references = df['gt_mar'].tolist()\n",
    "\n",
    "scores = compute_ref_based_scores(predictions, references)\n",
    "labse[mode] = scores['labse_ref_mt']\n",
    "muril[mode] = scores['muril_ref_mt']\n",
    "\n",
    "print(f\"LaBSE and MuRIL Scores for {mode}:\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852aec4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed71243c",
   "metadata": {},
   "source": [
    "## Combined - LR & Epochs Changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e0c6941",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"combined_2x_outputs.csv\"\n",
    "mode = \"combined_2x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6fde1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaBSE and MuRIL Scores for combined_2x:\n",
      "{'labse_ref_mt': 0.9204223514679323, 'muril_ref_mt': 0.9981520064735604}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file_name)\n",
    "\n",
    "predictions = df['prediction_mar'].tolist()\n",
    "references = df['gt_mar'].tolist()\n",
    "\n",
    "scores = compute_ref_based_scores(predictions, references)\n",
    "labse[mode] = scores['labse_ref_mt']\n",
    "muril[mode] = scores['muril_ref_mt']\n",
    "\n",
    "print(f\"LaBSE and MuRIL Scores for {mode}:\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbb5041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe308bf4",
   "metadata": {},
   "source": [
    "## Combined - LR & Epochs & Dataset Changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df5636fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"combined_x_outputs.csv\"\n",
    "mode = \"combined_x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b385bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaBSE and MuRIL Scores for combined_x:\n",
      "{'labse_ref_mt': 0.9217669360018302, 'muril_ref_mt': 0.9981642475458181}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file_name)\n",
    "\n",
    "predictions = df['prediction_mar'].tolist()\n",
    "references = df['gt_mar'].tolist()\n",
    "\n",
    "scores = compute_ref_based_scores(predictions, references)\n",
    "labse[mode] = scores['labse_ref_mt']\n",
    "muril[mode] = scores['muril_ref_mt']\n",
    "\n",
    "print(f\"LaBSE and MuRIL Scores for {mode}:\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecaee27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76fe3cda",
   "metadata": {},
   "source": [
    "## T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a89245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"t5_outputs.csv\"\n",
    "mode = \"t5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffb42cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaBSE and MuRIL Scores for t5:\n",
      "{'labse_ref_mt': 0.9212691990159818, 'muril_ref_mt': 0.9981615691031951}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file_name)\n",
    "\n",
    "predictions = df['prediction_mar'].tolist()\n",
    "references = df['gt_mar'].tolist()\n",
    "\n",
    "scores = compute_ref_based_scores(predictions, references)\n",
    "labse[mode] = scores['labse_ref_mt']\n",
    "muril[mode] = scores['muril_ref_mt']\n",
    "\n",
    "print(f\"LaBSE and MuRIL Scores for {mode}:\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d7749b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c177334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original : 0.9226\n",
      "with : 0.9198\n",
      "without : 0.9201\n",
      "combined_2x : 0.9204\n",
      "combined_x : 0.9218\n",
      "t5 : 0.9213\n"
     ]
    }
   ],
   "source": [
    "for key, val in labse.items():\n",
    "    print(f\"{key} : {val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f805b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original : 0.998117\n",
      "with : 0.998166\n",
      "without : 0.998174\n",
      "combined_2x : 0.998152\n",
      "combined_x : 0.998164\n",
      "t5 : 0.998162\n"
     ]
    }
   ],
   "source": [
    "for key, val in muril.items():\n",
    "    print(f\"{key} : {val:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
