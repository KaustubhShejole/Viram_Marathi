{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd63a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label list: ['O', 'COMMA', 'PERIOD', 'QUESTION', 'EXCLAMATION', 'SEMICOLON', 'COLON', 'HYPHEN', 'EN_DASH', 'EM_DASH', 'LEFT_PAREN', 'RIGHT_PAREN', 'LEFT_BRACKET', 'RIGHT_BRACKET', 'LEFT_BRACE', 'RIGHT_BRACE', 'DOUBLE_QUOTE', 'SINGLE_QUOTE', 'ELLIPSIS', 'SLASH', 'BACKSLASH', 'AT_SYMBOL', 'HASH', 'DOLLAR', 'PERCENT', 'AMPERSAND', 'ASTERISK', 'PLUS', 'EQUALS', 'LESS_THAN', 'GREATER_THAN', 'PIPE', 'CARET', 'BACKTICK', 'TILDE']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import BertTokenizerFast\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. define punctuation map\n",
    "punctuation_map = {\n",
    "    ',': 'COMMA',\n",
    "    '.': 'PERIOD',\n",
    "    '?': 'QUESTION',\n",
    "    '!': 'EXCLAMATION',\n",
    "    ';': 'SEMICOLON',\n",
    "    ':': 'COLON',\n",
    "    '-': 'HYPHEN',\n",
    "    '–': 'EN_DASH',\n",
    "    '—': 'EM_DASH',\n",
    "    '(': 'LEFT_PAREN',\n",
    "    ')': 'RIGHT_PAREN',\n",
    "    '[': 'LEFT_BRACKET',\n",
    "    ']': 'RIGHT_BRACKET',\n",
    "    '{': 'LEFT_BRACE',\n",
    "    '}': 'RIGHT_BRACE',\n",
    "    '\"': 'DOUBLE_QUOTE',\n",
    "    \"'\": 'SINGLE_QUOTE',\n",
    "    '…': 'ELLIPSIS',\n",
    "    '/': 'SLASH',\n",
    "    '\\\\': 'BACKSLASH',\n",
    "    '@': 'AT_SYMBOL',\n",
    "    '#': 'HASH',\n",
    "    '$': 'DOLLAR',\n",
    "    '%': 'PERCENT',\n",
    "    '&': 'AMPERSAND',\n",
    "    '*': 'ASTERISK',\n",
    "    '+': 'PLUS',\n",
    "    '=': 'EQUALS',\n",
    "    '<': 'LESS_THAN',\n",
    "    '>': 'GREATER_THAN',\n",
    "    '|': 'PIPE',\n",
    "    '^': 'CARET',\n",
    "    '`': 'BACKTICK',\n",
    "    '~': 'TILDE'\n",
    "}\n",
    "\n",
    "# Automatically create label_list from punctuation_map\n",
    "label_list = [\"O\"] + list(punctuation_map.values())\n",
    "label_to_id = {l: i for i, l in enumerate(label_list)}\n",
    "\n",
    "print(\"Label list:\", label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3053ccfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5be5e42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Original Text: how old are you i am a language model\n",
      "\n",
      "| Token Word ID | Prediction ID | Predicted Label |\n",
      "|---------------|---------------|-----------------|\n",
      "|            -1 |             0 | O               |\n",
      "|             0 |             0 | O               |\n",
      "|             1 |             0 | O               |\n",
      "|             2 |             0 | O               |\n",
      "|             3 |             3 | QUESTION        |\n",
      "|             4 |             0 | O               |\n",
      "|             5 |             0 | O               |\n",
      "|             6 |             0 | O               |\n",
      "|             7 |             0 | O               |\n",
      "|             8 |             2 | PERIOD          |\n",
      "|            -1 |            17 | SINGLE_QUOTE    |\n",
      "--------------------------------------------------\n",
      "\n",
      "Original Text: what is the capital of france it is paris\n",
      "\n",
      "| Token Word ID | Prediction ID | Predicted Label |\n",
      "|---------------|---------------|-----------------|\n",
      "|            -1 |             0 | O               |\n",
      "|             0 |             0 | O               |\n",
      "|             1 |             0 | O               |\n",
      "|             2 |             0 | O               |\n",
      "|             3 |             0 | O               |\n",
      "|             4 |             0 | O               |\n",
      "|             5 |             3 | QUESTION        |\n",
      "|             6 |             0 | O               |\n",
      "|             7 |             0 | O               |\n",
      "|             8 |             2 | PERIOD          |\n",
      "|            -1 |            17 | SINGLE_QUOTE    |\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_name = \"thenlpresearcher/bert_punct_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Corrected Prediction Function\n",
    "# -------------------------------\n",
    "def get_word_and_prediction_ids(text: str, model, tokenizer, device) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Takes an unpunctuated text string and returns the word IDs and prediction IDs \n",
    "    for all tokens in the sequence.\n",
    "    \"\"\"\n",
    "    words = text.lower().split()\n",
    "    \n",
    "    if not words:\n",
    "        return np.array([], dtype=np.int64), np.array([], dtype=np.int64)\n",
    "    \n",
    "    encoded_input = tokenizer(\n",
    "        words, \n",
    "        is_split_into_words=True, \n",
    "        return_tensors=\"pt\", \n",
    "        padding=True, \n",
    "        truncation=True\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoded_input)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    \n",
    "    # Squeeze to handle single-item batch\n",
    "    pred_ids = torch.argmax(logits, dim=-1).squeeze().cpu().numpy()\n",
    "    \n",
    "    # Convert list of word IDs (including None) to a numpy array, \n",
    "    # replacing None with a placeholder -1 for special tokens\n",
    "    word_ids_list = encoded_input.word_ids()\n",
    "    word_ids_array = np.array([w if w is not None else -1 for w in word_ids_list], dtype=np.int64)\n",
    "\n",
    "    return word_ids_array, pred_ids\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Example Usage and Cleaned Output\n",
    "# -------------------------------\n",
    "\n",
    "def print_predictions_table(input_text: str, model, tokenizer, device, label_list):\n",
    "    \"\"\"Runs prediction and prints the formatted table.\"\"\"\n",
    "    print(f\"\\nOriginal Text: {input_text}\")\n",
    "    \n",
    "    w_ids, p_ids = get_word_and_prediction_ids(input_text, model, tokenizer, device)\n",
    "    \n",
    "    # Check if the sentence was truncated or padded (resulting in different lengths)\n",
    "    if w_ids.ndim == 0 and w_ids.size == 0:\n",
    "         print(\"No words found.\")\n",
    "         return\n",
    "         \n",
    "    # Handle the case where the output is a scalar (single token)\n",
    "    if w_ids.ndim == 0:\n",
    "        w_ids = np.array([w_ids.item()])\n",
    "        p_ids = np.array([p_ids.item()])\n",
    "        \n",
    "    print(\"\\n| Token Word ID | Prediction ID | Predicted Label |\")\n",
    "    print(\"|---------------|---------------|-----------------|\")\n",
    "    \n",
    "    for w, p in zip(w_ids, p_ids):\n",
    "        # Look up the label. Use 'PAD/UNK' if ID is out of bounds (like 17)\n",
    "        label = label_list[p] if p < len(label_list) else \"PAD/UNK\"\n",
    "        print(f\"| {w:13d} | {p:13d} | {label:15s} |\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "# Example 1\n",
    "input_text_1 = \"how old are you i am a language model\"\n",
    "print_predictions_table(input_text_1, model, tokenizer, device, label_list)\n",
    "\n",
    "# Example 2\n",
    "input_text_2 = \"what is the capital of france it is paris\"\n",
    "print_predictions_table(input_text_2, model, tokenizer, device, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d25f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_reverse_map = {v: k for k, v in punctuation_map.items()}\n",
    "punctuation_reverse_map[\"O\"] = \"\"   # no punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d5f4fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"thenlpresearcher/mpnet_token_cls_model\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"thenlpresearcher/mpnet_token_cls_model\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f58c260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "0\n",
      "O\n",
      "marshmallow\n",
      "0\n",
      "O\n",
      "has\n",
      "0\n",
      "O\n",
      "to\n",
      "1\n",
      "COMMA\n",
      "be\n",
      "0\n",
      "O\n",
      "on\n",
      "0\n",
      "O\n",
      "top\n",
      "0\n",
      "O\n",
      "The marshmallow has to, be on top\n"
     ]
    }
   ],
   "source": [
    "text = \"The marshmallow has to be on top\"\n",
    "print(restore_punctuation(text, tokenizer, model, label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6792558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████| 8079/8079 [00:01<00:00, 6188.07 examples/s]\n",
      "/tmp/ipykernel_16871/2312840007.py:74: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model=model, tokenizer=tokenizer)\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction sample: ['O', 'O', 'O', 'PERIOD', 'O', 'O', 'PERIOD', 'O', 'COMMA', 'O', 'O', 'O', 'COMMA', 'O', 'O', 'O', 'O', 'O', 'PERIOD']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer\n",
    "from datasets import load_dataset\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Device setup\n",
    "# -------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Load tokenizer and model\n",
    "# -------------------------------\n",
    "model_name = \"thenlpresearcher/mpnet_token_cls_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "def create_token_labels(sentence):\n",
    "    tokens = []\n",
    "    labels = []\n",
    "    parts = re.findall(r\"\\w+|[^\\w\\s]\", sentence)\n",
    "    for i, part in enumerate(parts):\n",
    "        if re.match(r\"\\w+\", part):  # token\n",
    "            tokens.append(part)\n",
    "            if i+1 < len(parts) and parts[i+1] in punctuation_map:\n",
    "                labels.append(punctuation_map[parts[i+1]])\n",
    "            else:\n",
    "                labels.append(\"O\")\n",
    "    return tokens, labels\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Load CSV and create token-label dataset\n",
    "# -------------------------------\n",
    "def load_and_process(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    all_tokens = []\n",
    "    all_labels = []\n",
    "\n",
    "    for sent in df['text']:\n",
    "        tokens, labels = create_token_labels(str(sent))\n",
    "        all_tokens.append(tokens)\n",
    "        all_labels.append([label_to_id[l] for l in labels])\n",
    "\n",
    "    return Dataset.from_dict({\"tokens\": all_tokens, \"labels\": all_labels})\n",
    "\n",
    "test_dataset  = load_and_process(\"../iwslt2017_en_test.csv\")\n",
    "\n",
    "def tokenize_and_align_labels(batch):\n",
    "    tokenized_inputs = tokenizer(batch[\"tokens\"], is_split_into_words=True, truncation=True, padding=\"max_length\", max_length=128)\n",
    "    new_labels = []\n",
    "    for i, label in enumerate(batch[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        aligned_labels = []\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:\n",
    "                aligned_labels.append(-100)\n",
    "            else:\n",
    "                aligned_labels.append(label[word_id])\n",
    "        new_labels.append(aligned_labels)\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "test_dataset = test_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Prepare Trainer\n",
    "# -------------------------------\n",
    "trainer = Trainer(model=model, tokenizer=tokenizer)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Make predictions\n",
    "# -------------------------------\n",
    "predictions, labels, _ = trainer.predict(test_dataset)\n",
    "pred_ids = np.argmax(predictions, axis=-1)\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Map predictions and labels back to strings\n",
    "# -------------------------------\n",
    "true_labels_list = []\n",
    "pred_labels_list = []\n",
    "\n",
    "for label_row, pred_row in zip(labels, pred_ids):\n",
    "    true_row = []\n",
    "    pred_row_labels = []\n",
    "    for l, p in zip(label_row, pred_row):\n",
    "        if l != -100:  # ignore padding\n",
    "            true_row.append(label_list[l])\n",
    "            pred_row_labels.append(label_list[p])\n",
    "    true_labels_list.append(true_row)\n",
    "    pred_labels_list.append(pred_row_labels)\n",
    "\n",
    "print(\"Prediction sample:\", pred_labels_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0eb8f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed classification report (per label) using sklearn:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    AMPERSAND     0.0000    0.0000    0.0000         8\n",
      "        COLON     0.0527    0.0925    0.0672       292\n",
      "        COMMA     0.2107    0.2850    0.2423      9916\n",
      "       DOLLAR     0.0000    0.0000    0.0000         8\n",
      " DOUBLE_QUOTE     0.0000    0.0000    0.0000       313\n",
      "      EM_DASH     0.0000    0.0000    0.0000        27\n",
      "       EQUALS     0.0000    0.0000    0.0000         2\n",
      "  EXCLAMATION     0.0000    0.0000    0.0000        58\n",
      "         HASH     0.0000    0.0000    0.0000         2\n",
      "       HYPHEN     0.0184    0.0206    0.0194      1117\n",
      " LEFT_BRACKET     0.0000    0.0000    0.0000        15\n",
      "            O     0.8914    0.8892    0.8903    117294\n",
      "       PERIOD     0.7745    0.8394    0.8057      8729\n",
      "         PLUS     0.0000    0.0000    0.0000         2\n",
      "     QUESTION     0.0420    0.0201    0.0272       795\n",
      "RIGHT_BRACKET     0.0000    0.0000    0.0000        34\n",
      "    SEMICOLON     0.0000    0.0000    0.0000       132\n",
      " SINGLE_QUOTE     0.0286    0.0035    0.0062      3720\n",
      "        SLASH     0.0000    0.0000    0.0000         9\n",
      "\n",
      "     accuracy                         0.8038    142473\n",
      "    macro avg     0.1062    0.1132    0.1083    142473\n",
      " weighted avg     0.7972    0.8038    0.7998    142473\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Flatten lists for sklearn\n",
    "y_true_flat = [label for seq in true_labels_list for label in seq]\n",
    "y_pred_flat = [label for seq in pred_labels_list for label in seq]\n",
    "\n",
    "print(\"\\nDetailed classification report (per label) using sklearn:\")\n",
    "print(classification_report(y_true_flat, y_pred_flat, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38a24f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 24 17:52:17 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.5     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          Off | 00000000:17:00.0 Off |                    0 |\n",
      "| N/A   55C    P0              71W / 300W |  16273MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80GB PCIe          Off | 00000000:31:00.0 Off |                    0 |\n",
      "| N/A   40C    P0              70W / 300W |  79577MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100 80GB PCIe          Off | 00000000:4B:00.0 Off |                    0 |\n",
      "| N/A   58C    P0              76W / 300W |  57684MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100 80GB PCIe          Off | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   62C    P0              74W / 300W |  15076MiB / 81920MiB |     76%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdfb3ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Punctuation Restoration Results ---\n",
      "[0 1 2 3 4 5 6 7 8]\n",
      "[0 0 0 3 0 0 0 0 2]\n",
      "Original: how old are you i am a language model\n",
      "Punctuated: **How  old  are  you QUESTION i  am  a  language  model PERIOD**\n",
      "[0 1 2 3 4 5 6 7 8]\n",
      "[0 0 0 0 0 3 0 0 2]\n",
      "\n",
      "Original: what is the capital of france it is paris\n",
      "Punctuated: **What  is  the  capital  of  france QUESTION it  is  paris PERIOD**\n",
      "[0 1 2 3 4 5 6 7 8]\n",
      "[0 0 0 0 0 1 0 0 2]\n",
      "\n",
      "Original: if you want to know more ask me anything\n",
      "Punctuated: **If  you  want  to  know  more COMMA ask  me  anything PERIOD**\n",
      "[0 1 2 3]\n",
      "[1 0 0 2]\n",
      "\n",
      "Original: wow that is amazing\n",
      "Punctuated: **Wow COMMA that  is  amazing PERIOD**\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 3. The Punctuation Restoration Function\n",
    "# -------------------------------\n",
    "def restore_punctuation(text: str, model, tokenizer, label_list, device) -> str:\n",
    "    \"\"\"\n",
    "    Restores punctuation to an unpunctuated text string using the BERT Punctuation model.\n",
    "    \"\"\"\n",
    "    words = text.strip().split()\n",
    "    w_ids, p_ids = get_word_and_prediction_ids(text, model, tokenizer, device)\n",
    "    w_ids = w_ids[1:-1]\n",
    "    print(w_ids)\n",
    "    \n",
    "    p_ids = p_ids[1:-1]\n",
    "    print(p_ids)\n",
    "    \n",
    "    final_output = []\n",
    "    for w_id, p_id in zip(w_ids, p_ids):\n",
    "        if label_list[p_id] != \"O\":\n",
    "            punct = label_list[p_id]\n",
    "        else:\n",
    "            punct = \"\"\n",
    "        final_output.extend([words[w_id], punct])\n",
    "                 \n",
    "    # Join the words back into a sentence string, capitalizing the first letter.\n",
    "    result = \" \".join(final_output).strip()\n",
    "    \n",
    "    if result:\n",
    "        # Capitalize the first letter\n",
    "        return result[0].upper() + result[1:]\n",
    "    return \"\"\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Apply to Example Sentences\n",
    "# -------------------------------\n",
    "print(\"\\n--- Punctuation Restoration Results ---\")\n",
    "\n",
    "# Example 1\n",
    "input_text_1 = \"how old are you i am a language model\"\n",
    "punctuated_text_1 = restore_punctuation(input_text_1, model, tokenizer, label_list, device)\n",
    "print(f\"Original: {input_text_1}\")\n",
    "print(f\"Punctuated: **{punctuated_text_1}**\")\n",
    "\n",
    "# Example 2\n",
    "input_text_2 = \"what is the capital of france it is paris\"\n",
    "punctuated_text_2 = restore_punctuation(input_text_2, model, tokenizer, label_list, device)\n",
    "print(f\"\\nOriginal: {input_text_2}\")\n",
    "print(f\"Punctuated: **{punctuated_text_2}**\")\n",
    "\n",
    "# Example 3 (for demonstration of comma prediction)\n",
    "input_text_3 = \"if you want to know more ask me anything\"\n",
    "punctuated_text_3 = restore_punctuation(input_text_3, model, tokenizer, label_list, device)\n",
    "print(f\"\\nOriginal: {input_text_3}\")\n",
    "print(f\"Punctuated: **{punctuated_text_3}**\")\n",
    "\n",
    "# Example 4 (for demonstration of exclamation)\n",
    "input_text_4 = \"wow that is amazing\"\n",
    "punctuated_text_4 = restore_punctuation(input_text_4, model, tokenizer, label_list, device)\n",
    "print(f\"\\nOriginal: {input_text_4}\")\n",
    "print(f\"Punctuated: **{punctuated_text_4}**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d2ee20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
