{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4f20ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 25 11:19:04 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.5     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          Off | 00000000:17:00.0 Off |                    0 |\n",
      "| N/A   72C    P0             148W / 300W |  10340MiB / 81920MiB |     70%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80GB PCIe          Off | 00000000:31:00.0 Off |                    0 |\n",
      "| N/A   36C    P0              69W / 300W |  78931MiB / 81920MiB |     25%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100 80GB PCIe          Off | 00000000:4B:00.0 Off |                    0 |\n",
      "| N/A   55C    P0              74W / 300W |  56538MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100 80GB PCIe          Off | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   62C    P0             133W / 300W |  43056MiB / 81920MiB |    100%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a2c8990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/Approach1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc35744f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d90b40ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label list: ['O', 'COMMA', 'PERIOD', 'QUESTION', 'EXCLAMATION', 'SEMICOLON', 'COLON', 'HYPHEN', 'EN_DASH', 'EM_DASH', 'LEFT_PAREN', 'RIGHT_PAREN', 'LEFT_BRACKET', 'RIGHT_BRACKET', 'LEFT_BRACE', 'RIGHT_BRACE', 'DOUBLE_QUOTE', 'SINGLE_QUOTE', 'ELLIPSIS', 'SLASH', 'BACKSLASH', 'AT_SYMBOL', 'HASH', 'DOLLAR', 'PERCENT', 'AMPERSAND', 'ASTERISK', 'PLUS', 'EQUALS', 'LESS_THAN', 'GREATER_THAN', 'PIPE', 'CARET', 'BACKTICK', 'TILDE']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import BertTokenizerFast\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. define punctuation map\n",
    "punctuation_map = {\n",
    "    ',': 'COMMA',\n",
    "    '.': 'PERIOD',\n",
    "    '?': 'QUESTION',\n",
    "    '!': 'EXCLAMATION',\n",
    "    ';': 'SEMICOLON',\n",
    "    ':': 'COLON',\n",
    "    '-': 'HYPHEN',\n",
    "    '–': 'EN_DASH',\n",
    "    '—': 'EM_DASH',\n",
    "    '(': 'LEFT_PAREN',\n",
    "    ')': 'RIGHT_PAREN',\n",
    "    '[': 'LEFT_BRACKET',\n",
    "    ']': 'RIGHT_BRACKET',\n",
    "    '{': 'LEFT_BRACE',\n",
    "    '}': 'RIGHT_BRACE',\n",
    "    '\"': 'DOUBLE_QUOTE',\n",
    "    \"'\": 'SINGLE_QUOTE',\n",
    "    '…': 'ELLIPSIS',\n",
    "    '/': 'SLASH',\n",
    "    '\\\\': 'BACKSLASH',\n",
    "    '@': 'AT_SYMBOL',\n",
    "    '#': 'HASH',\n",
    "    '$': 'DOLLAR',\n",
    "    '%': 'PERCENT',\n",
    "    '&': 'AMPERSAND',\n",
    "    '*': 'ASTERISK',\n",
    "    '+': 'PLUS',\n",
    "    '=': 'EQUALS',\n",
    "    '<': 'LESS_THAN',\n",
    "    '>': 'GREATER_THAN',\n",
    "    '|': 'PIPE',\n",
    "    '^': 'CARET',\n",
    "    '`': 'BACKTICK',\n",
    "    '~': 'TILDE'\n",
    "}\n",
    "\n",
    "# Automatically create label_list from punctuation_map\n",
    "label_list = [\"O\"] + list(punctuation_map.values())\n",
    "label_to_id = {l: i for i, l in enumerate(label_list)}\n",
    "\n",
    "print(\"Label list:\", label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7e9fd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_reverse_map = {v: k for k, v in punctuation_map.items()}\n",
    "punctuation_reverse_map[\"O\"] = \"\"   # no punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01406978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 11:19:45.053120: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-25 11:19:45.118255: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-25 11:19:47.642366: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "raw_datasets = load_dataset(\"thenlpresearcher/test_data_marathi\")\n",
    "metric = load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27a84ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def restore_punctuation(text: str, model, tokenizer, label_list, device, punctuation_reverse_map) -> str:\n",
    "    \"\"\"\n",
    "    Restores punctuation to an unpunctuated text string, utilizing tokenizer subwords\n",
    "    and word_ids() for accurate mapping.\n",
    "    \"\"\"\n",
    "    # 1. Tokenize the input text\n",
    "    words = re.findall(r\"\\w+|[^\\w\\s]\", text.strip())\n",
    "#     print(words)\n",
    "    encoded_input = tokenizer(\n",
    "        words, \n",
    "        is_split_into_words=True, \n",
    "        return_tensors=\"pt\", \n",
    "        padding=True, \n",
    "        truncation=True\n",
    "    ).to(device)\n",
    "    \n",
    "    # 2. Extract word IDs and perform inference\n",
    "    word_ids_list = encoded_input.word_ids() # Maps subword token index to original word index (or None for special tokens)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoded_input['input_ids'][0])\n",
    "    tokens = tokens[1:-1]\n",
    "    # Run model inference to get logits/predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoded_input)\n",
    "        logits = outputs.logits\n",
    "    \n",
    "    # Get the predicted label index (p_id) for each token\n",
    "    # We take the first element [0] because the input is a batch of size 1\n",
    "    p_ids = torch.argmax(logits, dim=-1).squeeze().tolist()\n",
    "    \n",
    "    p_ids = p_ids[1:-1]\n",
    "    word_ids_list = word_ids_list[1:-1]\n",
    "#     print(word_ids_list)\n",
    "#     print(p_ids)\n",
    "#     print(tokens)\n",
    "    \n",
    "    final_output = []\n",
    "    \n",
    "    i = 0\n",
    "    for i in range(len(tokens)):\n",
    "        t = tokens[i]\n",
    "        p = p_ids[i]\n",
    "        punct = punctuation_reverse_map[label_list[p]]\n",
    "        \n",
    "        t = t.strip('#')\n",
    "        if t == punct:\n",
    "            continue\n",
    "        \n",
    "        if i < len(tokens) -1 and punct == tokens[i+1]:\n",
    "            final_output.extend([t, punct])\n",
    "            i = i + 2\n",
    "            continue\n",
    "            \n",
    "        if punct != \" \" and i < len(word_ids_list) - 1 and word_ids_list[i] != word_ids_list[i+1]:\n",
    "            punct = punct + \" \"\n",
    "        if punct == \" \" and i < len(word_ids_list) - 1 and word_ids_list[i] == word_ids_list[i+1]:\n",
    "            punct = \"\"\n",
    "        \n",
    "        \n",
    "        if i < len(word_ids_list) - 1 and word_ids_list[i] == word_ids_list[i+1] and p_ids[i] == p_ids[i+1]:\n",
    "            final_output.append(t)\n",
    "        else:\n",
    "            final_output.extend([t, punct])\n",
    "        i = i + 1\n",
    "        \n",
    "    # 6. Final cleanup\n",
    "    result = \"\".join(final_output).strip()\n",
    "    \n",
    "    if result:\n",
    "        # Capitalize the first letter\n",
    "        return result[0].upper() + result[1:]\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7111d024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am going to school, but i forgot my bag.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"thenlpresearcher/bert_punct_model\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"thenlpresearcher/bert_punct_model\").to(device)\n",
    "\n",
    "sentence = \"i am going to school but i forgot my bag\"\n",
    "print(restore_punctuation(sentence, model, tokenizer, label_list, device, punctuation_reverse_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a49231a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 0,\n",
       " 'punct_type': 'Comma',\n",
       " 'sent_written': 'Chanting the choir raised the volume as the celebrant intoned the prayer.',\n",
       " 'sent_meant': 'Chanting, the choir raised the volume as the celebrant intoned the prayer.',\n",
       " 'gt_marathi': 'जल्लोष करणाऱ्या व्यक्तीने प्रार्थनेचा उच्चार करताच, गायनाने आवाज वाढवला.',\n",
       " 'gemini_out': 'धर्मगुरू प्रार्थना म्हणत असताना, घोष करणाऱ्या गायकवृंदाने आवाज वाढवला.',\n",
       " 'cfilt_out': 'उत्सवी प्रार्थनेचा उच्चार करत असताना, जप करत, गायकवृंदाने आवाज वाढवला.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2427b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chanting the choir raised the volume as the celebrant intoned the prayer.\n",
      "Chanting: the choir raised the volume as the celebrant intoned the prayer.\n",
      "---\n",
      "A six-month-old calf was submitted for examination, showing lameness in all four legs which had been present since soon after birth.\n",
      "A six-month-old calf was submitted for examination , showing lameness in all four legs, which had been present since soon after birth.\n",
      "---\n",
      "Planning authorities should provide alternative locations for small businesses which are or would be offensive in a residential area.\n",
      "Planning authorities should provide alternative locations for small businesses which are, or would be, offensive in a residential area.\n",
      "---\n",
      "As the machine develops the forms we use to record data from past projects will be amended.\n",
      "As the machine develops, the forms we use to record data from past projects will be amended.\n",
      "---\n",
      "As mentioned, first impressions can be misleading.\n",
      "As mentioned,, first impressions can be misleading.\n",
      "---\n",
      "To get a clean assembly load the assembled equals table before the assembly is run.\n",
      "To get a clean assembly load, the assembled equals table before the assembly is run.\n",
      "---\n",
      "Executors delay giving information about substantial deviations from agreed dates. Because of this action cannot be taken in time.\n",
      "Executors delay giving information about substantial deviations from agreed dates, . because of this, action cannot be taken in time.\n",
      "---\n",
      "These glycans are poorly transferred to proteins resulting in unoccupied glycosylation sequons.\n",
      "These glycans are poorly transferred to proteins, resulting in unoccupied glycosylation sequons.\n",
      "---\n",
      "X is an effective acute, oral treatment for migraine with a rapid onset of action\n",
      "X is an effective acute , oral treatment for migraine with a rapid onset of action.\n",
      "---\n",
      "No newspaper is completely unbiased in my expert opinion.\n",
      "No newspaper is completely unbiased, in my expert opinion.\n",
      "---\n",
      "Steam for example is just as damaging as acid for that material.\n",
      "Steam, for example, is just as damaging as acid for that material.\n",
      "---\n",
      "My favourite opera composers are Verdi, Puccini, Mozart and Gilbert and Sullivan.\n",
      "My favourite opera composers are verdi , puccini , mozart and gilbert and sullivan.\n",
      "---\n",
      "The only problem with the new project established in the desert at high cost is the lack of good access roads.\n",
      "The only problem with the new project established in the desert at high cost is the lack of good access roads.\n",
      "---\n",
      "Having failed in all previous attempts he evolved a new plan which surprised everybody.\n",
      "Having failed in all previous attempts, he evolved a new plan, which surprised everybody.\n",
      "---\n",
      "When the film was developed none of the pictures proved satisfactory.\n",
      "When the film was developed, none of the pictures proved satisfactory.\n",
      "---\n",
      "The school has adequate study facilities but hardly any sports facilities.\n",
      "The school has adequate study facilities, but hardly any sports facilities.\n",
      "---\n",
      "In his daily traffickings a Cairene resident is often made conscious of the suffocating pollution.\n",
      "In his daily traffickings, a cairene resident is often made conscious of the suffocating pollution.\n",
      "---\n",
      "If drama implies conflict and poetry metaphor then poetic drama must imply the dramatization of metaphor!\n",
      "If drama implies conflict and poetry metaphor, then poetic drama must imply the dramatization of metaphor, !.\n",
      "---\n",
      "Items serve as the nodes of the knowledge network and user-defined relators serve as the links between items.\n",
      "Items serve as the nodes of the knowledge network, and user-defined relators serve as the links between items.\n",
      "---\n",
      "A translator of technical texts often has to handle large amounts of information and needs to ensure that it is stored in an easily retrievable form.\n",
      "A translator of technical texts often has to handle large amounts of information and needs to ensure that it is stored in an easily retrievable form.\n",
      "---\n",
      "The calculator executed the functions that had been selected and displayed the results on the top half of the screen.\n",
      "The calculator executed the functions that had been selected and displayed the results on the top half of the screen.\n",
      "---\n",
      "There are many disturbing factors fatigue, poor eye-sight, poor reading ability, anxiety or undue caution, distractibility, and inadequate motivation.\n",
      "There are many disturbing factors: fatigue , poor eye-- sight , poor reading ability,, anxiety or undue caution , distractibility , and inadequate motivation.\n",
      "---\n",
      "These are the components required motor brushes, bearings, and wiring.\n",
      "These are the components required: motor brushes , bearings , and wiring.\n",
      "---\n",
      "When a source of sound is operating in a room or other enclosure, the sound pressure in the room consists of two components direct sound and reverberant sound.\n",
      "When a source of sound is operating in a room or other enclosure,, the sound pressure in the room consists of two components: direct sound and reverberant sound.\n",
      "---\n",
      "The crucial words in the specification are the signals must be routed internally.\n",
      "The crucial words in the specification are, the signals must be routed internally.\n",
      "---\n",
      "Would you please supply a list of the correct settings for the ABC\n",
      "Would you please supply a list of the correct settings for the abc?\n",
      "---\n",
      "Set BATTERY B switch to OFF set BATTERY C switch to ON.\n",
      "Set battery b switch to off, set battery c switch to on.\n",
      "---\n",
      "What we see, we believe what we hear, we register\n",
      "What we see , we believe, what we hear , we register.\n",
      "---\n",
      "However oxidative stress occurs when the balance is disturbed, through an increase in reactive oxygen species\n",
      "However, oxidative stress occurs when the balance is disturbed , through an increase in reactive oxygen species.\n",
      "---\n",
      "Should any burner fail to ignite its respective section will revert to 'purge' and in this way the system ensures safe removal of unburned fuel\n",
      "Should any burner fail to ignite, its respective section will revert to\" '\" purge, ', and in this way the system ensures safe removal of unburned fuel.\n",
      "---\n",
      "At present rates of return giving a net profit of only 7% are widespread in the industry, indicating increased competition and tighter profit margins.\n",
      "At present, rates of return, giving a net profit of only 7 %, are widespread in the industry , indicating increased competition and tighter profit margins.\n",
      "---\n",
      "He draws an analogy between this and the learning process of a new-born child as it develops into maturity and quotes Freud: \"Where id was, there ego shall be.\"\n",
      "He draws an analogy between this and the learning process of a new-- born child as it develops into maturity, and quotes freud :, \" where id was , there ego shall be..' \".\n",
      "---\n",
      "Unfortunately though incorrect predictions were made about both negative and positive experiments, leading to doubts about the reliability of the underlying model.\n",
      "Unfortunately, though, incorrect predictions were made about both negative and positive experiments,, leading to doubts about the reliability of the underlying model.\n",
      "---\n",
      "Reject the applicant using procedure XYZ to ensure compliance with standard evaluation protocols.\n",
      "Reject the applicant, using procedure xyz to ensure compliance with standard evaluation protocols.\n",
      "---\n",
      "It represents an early quantifiable hyperplastic response of the tissue to injury.\n",
      "It represents an early, quantifiable hyperplastic response of the tissue to injury.\n",
      "---\n",
      "Return the XYZ to the operator following the ABC routine to verify proper functioning and safety.\n",
      "Return the xyz to the operator following the abc routine to verify proper functioning and safety.\n",
      "---\n",
      "Insert the new disk into the disk drive with the notch at the bottom facing the drive’s entry slot.\n",
      "Insert the new disk into the disk drive with the notch at the bottom facing the drive' ’' s entry slot.\n",
      "---\n",
      "Replace the fuel lines and electrical conduits, which have cracks or damaged B-nut fittings to prevent leaks and ensure safe operation.\n",
      "Replace the fuel lines and electrical conduits,, which have cracks or damaged b-nut fittings, to prevent leaks and ensure safe operation.\n",
      "---\n",
      "The processor accepts data from input devices and checks it before computing to ensure accuracy and prevent errors.\n",
      "The processor accepts data from input devices and checks it before computing to ensure accuracy and prevent errors.\n",
      "---\n",
      "The orifice through which the exhaust gases leave the chamber, is larger than the intake valve opening.\n",
      "The orifice through which the exhaust gases leave the chamber , is larger than the intake valve opening.\n",
      "---\n",
      "Take no action as the camera operates automatically under all lighting conditions.\n",
      "Take no action as the camera operates automatically under all lighting conditions.\n",
      "---\n",
      "The species of fish supported by the reef are varied and abundant food supplies are available to sustain their populations.\n",
      "The species of fish supported by the reef are varied, and abundant food supplies are available to sustain their populations.\n",
      "---\n",
      "At high temperatures, all the ceramic materials show ductility and hardness decreases considerably, leading to a higher risk of deformation under load.\n",
      "At high temperatures , all the ceramic materials show ductility and hardness decreases considerably,, leading to a higher risk of deformation under load.\n",
      "---\n",
      "This produces hard copy that can be retained but printed sheets are bulky to handle, so digital storage and viewing are often preferred.\n",
      "This produces hard copy that can be retained, but printed sheets are bulky to handle,, so digital storage and viewing are often preferred.\n",
      "---\n",
      "Connection to PTT-supplied packet-switch networks will be a prime requirement of the workstation and gateways into these networks are planned by the PTTs to ensure seamless data communication.\n",
      "Connection to ptt-supplied packet-switch networks will be a prime requirement of the workstation, and gateways into these networks are planned by the ptts to ensure seamless data communication.\n",
      "---\n",
      "The system consistently achieved 50 gallons per hour optimum output.\n",
      "The system consistently achieved 50 gallons per hour optimum output.\n",
      "---\n",
      "percentage reduction is critical: over and under reduction cause the ink to be very uneven and prone to smudging.\n",
      "Percentage reduction is critical : over and under reduction cause the ink to be very uneven and prone to smudging.\n",
      "---\n",
      "Adopting a user-centered approach is a realistic strategy in the design of both paper and screen based forms.\n",
      "Adopting a user-centered approach is a realistic strategy in the design of both paper- and screen- based forms.\n",
      "---\n",
      "Morphological studies of paraquat or oxygen toxicity in rats have shown significant cellular damage in lung tissue.\n",
      "Morphological studies of paraquat or oxygen toxicity in rats have shown significant cellular damage in lung tissue.\n",
      "---\n",
      "One should read G. V. Carey’s chapter Proof Correction in Mind the Stop.\n",
      "One should read g . v . carey' ’' s chapter\" proof correction in\" mind the stop.\n",
      "---\n",
      "The glass content of this material is low, 10% by weight, for this application.\n",
      "The glass content of this material is low,, 10 % by weight for this application.\n",
      "---\n",
      "During the experiment, the animals will be fed with water, via an automatic system, ad libitum.\n",
      "During the experiment , the animals will be fed with water , via an automatic system , ad libitum.\n",
      "---\n",
      "a water:glycol ratio of 60:40 is preferred.\n",
      "A water :- glycol ratio of 60 : 40 is preferred.\n",
      "---\n",
      "It has thickness of only 16:240 inch.\n",
      "It has thickness of only 16, : 240 inch.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "predicted_sentences = []\n",
    "\n",
    "for text in raw_datasets[\"test\"]['sent_written']:\n",
    "    pred = restore_punctuation(text.strip('.').strip('?'), model, tokenizer, label_list, device, punctuation_reverse_map)\n",
    "    predicted_sentences.append(pred)\n",
    "    print(text)\n",
    "    print(pred)\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbd9f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6106f833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def batch_translate(input_sentences, src_lang, tgt_lang, model, tokenizer, ip, device, batch_size=8, max_length=256):\n",
    "    \"\"\"\n",
    "    Translate a batch of sentences using a seq2seq model like IndicTrans.\n",
    "\n",
    "    Args:\n",
    "        input_sentences (list of str): Source sentences to translate.\n",
    "        src_lang (str): Source language code, e.g., \"eng_Latn\".\n",
    "        tgt_lang (str): Target language code, e.g., \"mar_Deva\".\n",
    "        model: Hugging Face seq2seq model.\n",
    "        tokenizer: Corresponding tokenizer.\n",
    "        ip: Preprocessing object (IndicProcessor).\n",
    "        device: torch device (\"cuda\" or \"cpu\").\n",
    "        batch_size (int): Batch size for generation.\n",
    "        max_length (int): Maximum length of generated sequence.\n",
    "\n",
    "    Returns:\n",
    "        translations (list of str): Translated sentences.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    translations = []\n",
    "\n",
    "    for i in range(0, len(input_sentences), batch_size):\n",
    "        batch = input_sentences[i : i + batch_size]\n",
    "\n",
    "        # Preprocess the batch\n",
    "        batch = ip.preprocess_batch(batch, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "\n",
    "        # Tokenize\n",
    "        inputs = tokenizer(\n",
    "            batch,\n",
    "            truncation=True,\n",
    "            padding=\"longest\",\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=True,\n",
    "        )\n",
    "        # Move tensors to the correct device\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Generate translations\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = model.generate(\n",
    "                **inputs,\n",
    "                use_cache=True,\n",
    "                min_length=5,  # ensure some minimum length\n",
    "                max_length=max_length,\n",
    "                num_beams=5,\n",
    "                num_return_sequences=1,\n",
    "                early_stopping=True,\n",
    "                decoder_start_token_id=model.config.decoder_start_token_id\n",
    "            )\n",
    "\n",
    "        # Decode generated tokens\n",
    "        decoded_texts = tokenizer.batch_decode(\n",
    "            generated_tokens,\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=True,\n",
    "        )\n",
    "\n",
    "        # Postprocess translations (remove language prefix, entity replacement, etc.)\n",
    "        translations += ip.postprocess_batch(decoded_texts, lang=tgt_lang)\n",
    "\n",
    "        # Free GPU memory\n",
    "        del inputs, generated_tokens\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d63579f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "db4d60783a2b4cc9ac647f53524e9201",
      "23e6dd2b833d44aabc5b78a83d7ef136",
      "8aff67fa78c640bf83598dd7fccc5b97",
      "97ed312717014144af97d250fcd74d9d",
      "7b69f1226cf5457aa164146a890a2c5e",
      "d5ce787580584a40883fdac45df7917a",
      "1962a04347894250993d2eb3d2946e5c",
      "d5e1f379a1084c6e978a633698b4b02a",
      "b689909adc244204af714b9a19e158c0",
      "8c32a5f5cb724610a4ea8a5b42be5b28",
      "44db6a1a111148ceaa804f7302b0629b",
      "7e8253e0de7f426c9f9af4b15775c660",
      "adfbc16f0b6144b6ab06544ed060f8fe",
      "1425686f748e45b9921c501d0e5ce904",
      "632fb54ffc9b44b98d082d097c17d7de"
     ]
    },
    "id": "agDlgrOix5Uj",
    "outputId": "d52e9acb-10d0-464f-c9f1-1947b7a7b0e6"
   },
   "outputs": [],
   "source": [
    "def initialize_model_and_tokenizer(ckpt_dir, quantization=None):\n",
    "    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, BitsAndBytesConfig\n",
    "    import torch\n",
    "\n",
    "    # Quantization setup\n",
    "    if quantization == \"4-bit\":\n",
    "        qconfig = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        )\n",
    "    elif quantization == \"8-bit\":\n",
    "        qconfig = BitsAndBytesConfig(\n",
    "            load_in_8bit=True,\n",
    "            bnb_8bit_use_double_quant=True,\n",
    "            bnb_8bit_compute_dtype=torch.bfloat16,\n",
    "        )\n",
    "    else:\n",
    "        qconfig = None\n",
    "\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(ckpt_dir, trust_remote_code=True)\n",
    "\n",
    "    # Load model\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        ckpt_dir,\n",
    "        trust_remote_code=True,\n",
    "        low_cpu_mem_usage=True,\n",
    "        quantization_config=qconfig,\n",
    "    )\n",
    "\n",
    "    # Move to device and optionally convert to half precision\n",
    "    if qconfig is None:\n",
    "        model = model.to(DEVICE)\n",
    "        if DEVICE == \"cuda\":\n",
    "            model.half()\n",
    "\n",
    "    # Make sure model is in training mode for fine-tuning\n",
    "    model.eval()\n",
    "\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee23db3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def batch_translate(input_sentences, src_lang, tgt_lang, model, tokenizer, ip, device, batch_size=8, max_length=256):\n",
    "    \"\"\"\n",
    "    Translate a batch of sentences using a seq2seq model like IndicTrans.\n",
    "\n",
    "    Args:\n",
    "        input_sentences (list of str): Source sentences to translate.\n",
    "        src_lang (str): Source language code, e.g., \"eng_Latn\".\n",
    "        tgt_lang (str): Target language code, e.g., \"mar_Deva\".\n",
    "        model: Hugging Face seq2seq model.\n",
    "        tokenizer: Corresponding tokenizer.\n",
    "        ip: Preprocessing object (IndicProcessor).\n",
    "        device: torch device (\"cuda\" or \"cpu\").\n",
    "        batch_size (int): Batch size for generation.\n",
    "        max_length (int): Maximum length of generated sequence.\n",
    "\n",
    "    Returns:\n",
    "        translations (list of str): Translated sentences.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    translations = []\n",
    "\n",
    "    for i in range(0, len(input_sentences), batch_size):\n",
    "        batch = input_sentences[i : i + batch_size]\n",
    "\n",
    "        # Preprocess the batch\n",
    "        batch = ip.preprocess_batch(batch, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "\n",
    "        # Tokenize\n",
    "        inputs = tokenizer(\n",
    "            batch,\n",
    "            truncation=True,\n",
    "            padding=\"longest\",\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=True,\n",
    "        )\n",
    "        # Move tensors to the correct device\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Generate translations\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = model.generate(\n",
    "                **inputs,\n",
    "                use_cache=True,\n",
    "                min_length=5,  # ensure some minimum length\n",
    "                max_length=max_length,\n",
    "                num_beams=5,\n",
    "                num_return_sequences=1,\n",
    "                early_stopping=True,\n",
    "                decoder_start_token_id=model.config.decoder_start_token_id\n",
    "            )\n",
    "\n",
    "        # Decode generated tokens\n",
    "        decoded_texts = tokenizer.batch_decode(\n",
    "            generated_tokens,\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=True,\n",
    "        )\n",
    "\n",
    "        # Postprocess translations (remove language prefix, entity replacement, etc.)\n",
    "        translations += ip.postprocess_batch(decoded_texts, lang=tgt_lang)\n",
    "\n",
    "        # Free GPU memory\n",
    "        del inputs, generated_tokens\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "089d4016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "en_indic_ckpt_dir = \"ai4bharat/indictrans2-en-indic-dist-200M\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "quantization = None\n",
    "en_indic_tokenizer, en_indic_model = initialize_model_and_tokenizer(en_indic_ckpt_dir, quantization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8306f02d",
   "metadata": {
    "id": "E_XK7px-IDkC"
   },
   "source": [
    "Then we just need to pass all of this along with our datasets to the Seq2SeqTrainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4d0091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = en_indic_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3bda3338",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = en_indic_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d161cecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'punct_type', 'sent_written', 'sent_meant', 'gt_marathi', 'gemini_out', 'cfilt_out'],\n",
       "    num_rows: 54\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "958d0f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IndicTransToolkit.processor import IndicProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25112cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = IndicProcessor(inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d64fde9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "src_lang, tgt_lang = \"eng_Latn\", \"mar_Deva\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# -------------------- LOAD DATA --------------------\n",
    "src_sentences = predicted_sentences\n",
    "ref_gt     = raw_datasets['test'][\"gt_marathi\"]\n",
    "ref_gem    = raw_datasets['test'][\"gemini_out\"]\n",
    "ref_cfilt  = raw_datasets['test'][\"cfilt_out\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e35aa321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "54\n",
      "54\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "print(len(src_sentences))\n",
    "print(len(ref_gt))\n",
    "print(len(ref_gem))\n",
    "print(len(ref_cfilt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3883f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5127d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def batch_translate(input_sentences, src_lang, tgt_lang, model, tokenizer, ip, device, batch_size=8, max_length=256):\n",
    "    \"\"\"\n",
    "    Translate a batch of sentences using a seq2seq model like IndicTrans with safety checks.\n",
    "\n",
    "    Args:\n",
    "        input_sentences (list of str): Source sentences to translate.\n",
    "        src_lang (str): Source language code, e.g., \"eng_Latn\".\n",
    "        tgt_lang (str): Target language code, e.g., \"mar_Deva\".\n",
    "        model: Hugging Face seq2seq model.\n",
    "        tokenizer: Corresponding tokenizer.\n",
    "        ip: Preprocessing object (IndicProcessor).\n",
    "        device: torch device (\"cuda\" or \"cpu\").\n",
    "        batch_size (int): Batch size for generation.\n",
    "        max_length (int): Maximum length of generated sequence.\n",
    "\n",
    "    Returns:\n",
    "        translations (list of str): Translated sentences.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    translations = []\n",
    "\n",
    "    # Safe access for decoder_start_token_id\n",
    "    decoder_start_token_id = getattr(model.config, \"decoder_start_token_id\", None)\n",
    "    pad_token_id = getattr(tokenizer, \"pad_token_id\", None)\n",
    "    eos_token_id = getattr(tokenizer, \"eos_token_id\", None)\n",
    "\n",
    "    if decoder_start_token_id is None:\n",
    "        print(\"[Warning] decoder_start_token_id is None. Using default generation behavior.\")\n",
    "\n",
    "    for i in range(0, len(input_sentences), batch_size):\n",
    "        batch = input_sentences[i : i + batch_size]\n",
    "        print('here')\n",
    "\n",
    "        # Preprocess the batch\n",
    "        batch_preprocessed = ip.preprocess_batch(batch, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "        if not isinstance(batch_preprocessed, list) or len(batch_preprocessed) == 0:\n",
    "            print(f\"[Warning] Preprocessed batch is empty at index {i}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "#         Debug: print first 2 sentences after preprocessing\n",
    "        print(f\"[Debug] Preprocessed batch sample: {batch_preprocessed[:2]}\")\n",
    "\n",
    "        # Tokenize\n",
    "        inputs = tokenizer(\n",
    "            batch_preprocessed,\n",
    "            truncation=True,\n",
    "            padding=\"longest\",\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=True,\n",
    "        )\n",
    "\n",
    "        # Move tensors to the correct device\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Generate translations with safety parameters\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                generated_tokens = model.generate(\n",
    "                    **inputs,\n",
    "                    use_cache=True,\n",
    "                    min_length=5,\n",
    "                    max_length=max_length,\n",
    "                    num_beams=5,\n",
    "                    num_return_sequences=1,\n",
    "                    early_stopping=True,\n",
    "                    decoder_start_token_id=decoder_start_token_id,\n",
    "                    pad_token_id=pad_token_id,\n",
    "                    eos_token_id=eos_token_id\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"[Error] Generation failed for batch starting at index {i}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Decode generated tokens\n",
    "        decoded_texts = tokenizer.batch_decode(\n",
    "            generated_tokens,\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=True,\n",
    "        )\n",
    "\n",
    "#         Debug: print first 2 decoded outputs\n",
    "        print(f\"[Debug] Decoded sample: {decoded_texts[:2]}\")\n",
    "\n",
    "        # Postprocess translations\n",
    "        try:\n",
    "            postprocessed = ip.postprocess_batch(decoded_texts, lang=tgt_lang)\n",
    "            translations += postprocessed\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] Postprocessing failed for batch starting at index {i}: {e}\")\n",
    "            translations += decoded_texts  # fallback\n",
    "\n",
    "        # Free GPU memory\n",
    "        del inputs, generated_tokens\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eef6b663",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_lang, tgt_lang = \"eng_Latn\", \"mar_Deva\"\n",
    "\n",
    "prefix = f\"{tgt_lang} {src_lang}\"\n",
    "\n",
    "def remove_prefix(text):\n",
    "    if text.startswith(prefix):\n",
    "        return text[len(prefix):].strip()\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4ec9615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva Chanting : the choir raised the volume as the celebrant intoned the prayer .', 'eng_Latn mar_Deva A six-month-old calf was submitted for examination , showing lameness in all four legs , which had been present since soon after birth .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▊                                     | 1/14 [00:00<00:11,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['जपः गायकवृंदाने आवाज वाढवला आणि उत्सवी व्यक्तीने प्रार्थना केली.', 'जन्मानंतर लगेचच अस्तित्वात असलेल्या चारही पायांमध्ये लंगडेपणा दर्शविणाऱ्या सहा महिन्यांच्या वासराला तपासणीसाठी सादर करण्यात आले.']\n",
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva As mentioned , , first impressions can be misleading .', 'eng_Latn mar_Deva To get a clean assembly load , the assembled equals table before the assembly is run .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▋                                  | 2/14 [00:01<00:08,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['नमूद केल्याप्रमाणे, पहिली छाप दिशाभूल करणारी असू शकते.', 'स्वच्छ असेंब्ली लोड मिळविण्यासाठी, असेंब्ली चालवण्यापूर्वी असेंबल केलेले टेबल समान असते.']\n",
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva X is an effective acute , oral treatment for migraine with a rapid onset of action .', 'eng_Latn mar_Deva No newspaper is completely unbiased , in my expert opinion .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████▌                               | 3/14 [00:01<00:06,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['एक्स हा अर्धशिशीसाठी एक प्रभावी तीव्र, तोंडी उपचार आहे, ज्याची कृती जलद सुरू होते.', 'माझ्या तज्ज्ञांच्या मते कोणतेही वृत्तपत्र पूर्णपणे निःपक्षपाती नसते.']\n",
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva The only problem with the new project established in the desert at high cost is the lack of good access roads .', 'eng_Latn mar_Deva Having failed in all previous attempts , he evolved a new plan , which surprised everybody .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████▍                            | 4/14 [00:02<00:05,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['वाळवंटात मोठ्या खर्चात उभारण्यात आलेल्या नवीन प्रकल्पाची एकमेव समस्या म्हणजे चांगल्या रस्त्यांचा अभाव.', 'मागील सर्व प्रयत्नांमध्ये अपयशी ठरल्यानंतर, त्याने एक नवीन योजना तयार केली, ज्यामुळे सर्वांना आश्चर्य वाटले.']\n",
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva In his daily traffickings , a cairene resident is often made conscious of the suffocating pollution .', 'eng_Latn mar_Deva If drama implies conflict and poetry metaphor , then poetic drama must imply the dramatization of metaphor , ! .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████▎                         | 5/14 [00:02<00:05,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['त्याच्या दैनंदिन तस्करीमध्ये, कॅरेन रहिवाशांना अनेकदा गुदमरणाऱ्या प्रदूषणाची जाणीव करून दिली जाते.', 'जर नाटक म्हणजे संघर्ष आणि काव्याचे रूपक असेल, तर काव्यात्मक नाटक म्हणजे रूपकाचे नाट्यीकरण असावे.']\n",
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva The calculator executed the functions that had been selected and displayed the results on the top half of the screen .', 'eng_Latn mar_Deva There are many disturbing factors : fatigue , poor eye-- sight , poor reading ability , , anxiety or undue caution , distractibility , and inadequate motivation .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████▏                      | 6/14 [00:03<00:04,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['कॅल्क्युलेटरने निवडलेली कार्ये अंमलात आणली आणि स्क्रीनच्या वरच्या अर्ध्या भागात परिणाम प्रदर्शित केले.', 'अनेक त्रासदायक घटक आहेतः थकवा, कमकुवत दृष्टी, खराब वाचन क्षमता, चिंता किंवा अनावश्यक सावधगिरी, लक्ष विचलित करणे आणि अपुरी प्रेरणा.']\n",
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva The crucial words in the specification are , the signals must be routed internally .', 'eng_Latn mar_Deva Would you please supply a list of the correct settings for the abc ?']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████                    | 7/14 [00:04<00:03,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['विशिष्टतेतील महत्त्वाचे शब्द म्हणजे, संकेत अंतर्गतपणे निर्देशित केले जाणे आवश्यक आहे.', 'तुम्ही कृपया ए. बी. सी. साठी योग्य सेटिंग्जची यादी द्याल का?']\n",
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva However , oxidative stress occurs when the balance is disturbed , through an increase in reactive oxygen species .', 'eng_Latn mar_Deva Should any burner fail to ignite , its respective section will revert to \" \\' \" purge , \\' , and in this way the system ensures safe removal of unburned fuel .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████▊                 | 8/14 [00:04<00:03,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['तथापि, प्रतिक्रियाशील ऑक्सिजन प्रजातींमध्ये वाढ झाल्यामुळे संतुलन बिघडते तेव्हा ऑक्सिडेटिव्ह ताण उद्भवतो.', \"जर कोणतेही बर्नर प्रज्वलित करण्यात अयशस्वी ठरले, तर त्याचा संबंधित विभाग'शुध्दीकरण'कडे परत जाईल आणि अशा प्रकारे प्रणाली जळत नसलेले इंधन सुरक्षितपणे काढून टाकण्याची खात्री करते.\"]\n",
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva Unfortunately , though , incorrect predictions were made about both negative and positive experiments , , leading to doubts about the reliability of the underlying model .', 'eng_Latn mar_Deva Reject the applicant , using procedure xyz to ensure compliance with standard evaluation protocols .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|█████████████████████████▋              | 9/14 [00:05<00:02,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['दुर्दैवाने, तथापि, नकारात्मक आणि सकारात्मक दोन्ही प्रयोगांबद्दल चुकीचे अंदाज लावले गेले, ज्यामुळे अंतर्निहित मॉडेलच्या विश्वासार्हतेबद्दल शंका निर्माण झाली.', 'प्रमाणित मूल्यांकन प्रोटोकॉलचे पालन सुनिश्चित करण्यासाठी xyz प्रक्रिया वापरून अर्जदाराला नाकारणे.']\n",
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva Insert the new disk into the disk drive with the notch at the bottom facing the drive \\' \" s entry slot .', 'eng_Latn mar_Deva Replace the fuel lines and electrical conduits , , which have cracks or damaged b-nut fittings , to prevent leaks and ensure safe operation .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████████████████████████▊           | 10/14 [00:05<00:02,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['डिस्क ड्राइव्हमध्ये नवीन डिस्क घाला, ज्याच्या तळाशी ड्राइव्हच्या प्रवेश स्लॉटला तोंड देणारी खाच आहे.', 'गळती टाळण्यासाठी आणि सुरक्षित ऑपरेशन सुनिश्चित करण्यासाठी, इंधन रेषा आणि विद्युत वाहिन्या, ज्यात भेगा किंवा खराब झालेल्या बी - नट फिटिंग्स आहेत, त्या बदला.']\n",
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva Take no action as the camera operates automatically under all lighting conditions .', 'eng_Latn mar_Deva The species of fish supported by the reef are varied , and abundant food supplies are available to sustain their populations .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████▋        | 11/14 [00:06<00:01,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['कोणतीही कारवाई करू नका कारण कॅमेरा सर्व प्रकाश परिस्थितींमध्ये स्वयंचलितपणे कार्य करतो.', 'खडकांद्वारे समर्थित माशांच्या प्रजाती वैविध्यपूर्ण आहेत आणि त्यांची लोकसंख्या टिकवून ठेवण्यासाठी मुबलक अन्न पुरवठा उपलब्ध आहे.']\n",
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva Connection to ptt-supplied packet-switch networks will be a prime requirement of the workstation , and gateways into these networks are planned by the ptts to ensure seamless data communication .', 'eng_Latn mar_Deva The system consistently achieved 50 gallons per hour optimum output .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████▍     | 12/14 [00:07<00:01,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['पी. टी. टी. - पुरविलेल्या पॅकेट - स्विच नेटवर्कशी जोडणी ही वर्कस्टेशनची प्रमुख आवश्यकता असेल आणि अखंड डेटा संप्रेषण सुनिश्चित करण्यासाठी पी. टी. टी. द्वारे या नेटवर्कमधील प्रवेशद्वारांचे नियोजन केले जाते.', 'या प्रणालीने सातत्याने 50 गॅलन प्रति तास इष्टतम उत्पादन साध्य केले.']\n",
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva Morphological studies of paraquat or oxygen toxicity in rats have shown significant cellular damage in lung tissue .', 'eng_Latn mar_Deva One should read g . v . carey \\' \" s chapter \" proof correction in \" mind the stop .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|████████████████████████████████████▏  | 13/14 [00:07<00:00,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['उंदरांमधील पॅराक्वाट किंवा ऑक्सिजन विषाक्ततेच्या आकारशास्त्रीय अभ्यासात फुफ्फुसाच्या ऊतींमध्ये लक्षणीय पेशी नुकसान झाल्याचे दिसून आले आहे.', \"जी. व्ही. कॅरीचा'प्रूफ करेक्शन'हा अध्याय'माइंड द स्टॉप'मध्ये वाचला पाहिजे.\"]\n",
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva A water : - glycol ratio of < ID1 > is preferred .', 'eng_Latn mar_Deva It has thickness of only 16 , : 240 inch .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 14/14 [00:08<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['पाणीः - ग्लायकोल गुणोत्तर < आयडी1 > ला प्राधान्य दिले जाते.', 'त्याची जाडी केवळ 16,240 इंच आहे.']\n",
      "\n",
      "Successful translations: 54 / 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------- TRANSLATION --------------------\n",
    "valid_src = []\n",
    "valid_pred = []\n",
    "valid_gt = []\n",
    "valid_gem = []\n",
    "valid_cfilt = []\n",
    "\n",
    "# Translate in batches\n",
    "all_translations = []\n",
    "for i in tqdm(range(0, len(src_sentences), BATCH_SIZE)):\n",
    "    batch = src_sentences[i:i+BATCH_SIZE]\n",
    "#     print(batch)\n",
    "    translations = batch_translate(\n",
    "        batch,\n",
    "        src_lang,\n",
    "        tgt_lang,\n",
    "        en_indic_model,\n",
    "        en_indic_tokenizer,\n",
    "        ip,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    all_translations.extend(translations)\n",
    "\n",
    "    if translations is None:\n",
    "        print(f\"[SKIPPED] Batch {i}: Returned None\")\n",
    "        continue\n",
    "\n",
    "    cleaned = [remove_prefix(t) for t in translations]\n",
    "\n",
    "    valid_src.extend(batch)\n",
    "    valid_pred.extend(cleaned)\n",
    "    valid_gt.extend(ref_gt[i:i + len(batch)])\n",
    "    valid_gem.extend(ref_gem[i:i + len(batch)])\n",
    "    valid_cfilt.extend(ref_cfilt[i:i + len(batch)])\n",
    "\n",
    "print(f\"\\nSuccessful translations: {len(valid_pred)} / {len(src_sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ed62380",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"approach1_bert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fffb7191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved predictions to approach1_bert_outputs.csv\n",
      "\n",
      "===== FINAL METRICS =====\n",
      "All references combined → BLEU: 75.95, chrF++: 87.50\n",
      "GT Marathi → BLEU: 59.73\n",
      "Gemini    → BLEU: 23.84\n",
      "CFILT     → BLEU: 59.91\n",
      "\n",
      "🎯 BEST REFERENCE = CFILT (by highest BLEU)\n",
      "Metrics written to punct_approach1_bert_baseline_outputs_eval_metrics.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "\n",
    "# -------------------- SAVE OUTPUTS --------------------\n",
    "results_df = pd.DataFrame({\n",
    "    \"src\": valid_src,\n",
    "    \"prediction\": valid_pred,\n",
    "    \"gt\": valid_gt,\n",
    "    \"gemini\": valid_gem,\n",
    "    \"cfilt\": valid_cfilt\n",
    "})\n",
    "\n",
    "results_df.to_csv(f\"{mode}_outputs.csv\", index=False)\n",
    "print(f\"✔ Saved predictions to {mode}_outputs.csv\")\n",
    "\n",
    "# -------------------- METRICS --------------------\n",
    "bleu = load(\"sacrebleu\")\n",
    "chrf = load(\"chrf\")\n",
    "\n",
    "def compute_scores(preds, ref1, ref2, ref3):\n",
    "    \"\"\"\n",
    "    Compute BLEU and chrF++ scores using all three references for each sentence.\n",
    "    \"\"\"\n",
    "    references = [[r1, r2, r3] for r1, r2, r3 in zip(ref1, ref2, ref3)]  # sacrebleu format\n",
    "    bleu_score = bleu.compute(predictions=preds, references=references)[\"score\"]\n",
    "    chrf_score = chrf.compute(predictions=preds, references=references)[\"score\"]\n",
    "    return bleu_score, chrf_score\n",
    "\n",
    "bleu_score, chrf_score = compute_scores(valid_pred, valid_gt, valid_gem, valid_cfilt)\n",
    "\n",
    "# Determine best reference per metric (based on BLEU)\n",
    "all_scores = {\n",
    "    \"GT\":    bleu.compute(predictions=valid_pred, references=[[r] for r in valid_gt])[\"score\"],\n",
    "    \"Gemini\": bleu.compute(predictions=valid_pred, references=[[r] for r in valid_gem])[\"score\"],\n",
    "    \"CFILT\":  bleu.compute(predictions=valid_pred, references=[[r] for r in valid_cfilt])[\"score\"]\n",
    "}\n",
    "\n",
    "best_ref = max(all_scores, key=all_scores.get)\n",
    "\n",
    "print(\"\\n===== FINAL METRICS =====\")\n",
    "print(f\"All references combined → BLEU: {bleu_score:.2f}, chrF++: {chrf_score:.2f}\")\n",
    "print(f\"GT Marathi → BLEU: {all_scores['GT']:.2f}\")\n",
    "print(f\"Gemini    → BLEU: {all_scores['Gemini']:.2f}\")\n",
    "print(f\"CFILT     → BLEU: {all_scores['CFILT']:.2f}\")\n",
    "print(f\"\\n🎯 BEST REFERENCE = {best_ref} (by highest BLEU)\")\n",
    "\n",
    "# -------------------- SAVE METRICS --------------------\n",
    "with open(f\"{mode}_indictrans2_eval_metrics.txt\", \"w\") as f:\n",
    "    f.write(f\"All references combined → BLEU {bleu_score:.2f}, chrF++ {chrf_score:.2f}\\n\")\n",
    "    f.write(f\"GT    BLEU {all_scores['GT']:.2f}\\n\")\n",
    "    f.write(f\"Gem   BLEU {all_scores['Gemini']:.2f}\\n\")\n",
    "    f.write(f\"CFILT BLEU {all_scores['CFILT']:.2f}\\n\")\n",
    "    f.write(f\"\\nBEST REFERENCE = {best_ref}\\n\")\n",
    "\n",
    "print(f\"Metrics written to punct_{mode}_baseline_outputs_eval_metrics.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b14612b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'अफगाणिस्तानमध्ये हिंदू खूप कमी आहेत आणि मालदीवमध्ये हिंदू नाहीत.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['prediction'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5fa853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_sentences = raw_datasets['test'][\"sent_meant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c12d5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva Chanting , the choir raised the volume as the celebrant intoned the prayer .', 'eng_Latn mar_Deva A six-month-old calf was submitted for examination , showing lameness in all four legs , which had been present since soon after birth .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▊                                     | 1/14 [00:00<00:11,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['उत्सवी व्यक्तीने प्रार्थनेचा उच्चार करत असताना, गायकवृंदाने जप करत आवाज वाढवला.', 'जन्मानंतर लगेचच अस्तित्वात असलेल्या चारही पायांमध्ये लंगडेपणा दर्शविणाऱ्या सहा महिन्यांच्या वासराला तपासणीसाठी सादर करण्यात आले.']\n",
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva As mentioned first , impressions can be misleading .', 'eng_Latn mar_Deva To get a clean assembly , load the assembled equals table before the assembly is run .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▋                                  | 2/14 [00:01<00:10,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['प्रथम नमूद केल्याप्रमाणे, छाप दिशाभूल करणारी असू शकतात.', 'स्वच्छ असेंब्ली मिळविण्यासाठी, असेंब्ली चालवण्यापूर्वी असेंबल केलेले समान टेबल लोड करा.']\n",
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva X is an effective acute , oral treatment for migraine , with a rapid onset of action', 'eng_Latn mar_Deva No newspaper is completely unbiased , in my expert opinion .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████▌                               | 3/14 [00:02<00:08,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['एक्स हा अर्धशिशीसाठी एक प्रभावी तीव्र, तोंडी उपचार आहे, ज्यात कृतीची जलद सुरुवात होते.', 'माझ्या तज्ज्ञांच्या मते कोणतेही वृत्तपत्र पूर्णपणे निःपक्षपाती नसते.']\n",
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva The only problem with the new project , established in the desert at high cost , is the lack of good access roads .', 'eng_Latn mar_Deva Having failed in all previous attempts , he evolved a new plan which surprised everybody .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████▍                            | 4/14 [00:03<00:07,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['वाळवंटात मोठ्या खर्चात उभारण्यात आलेल्या नवीन प्रकल्पाची एकमेव समस्या म्हणजे चांगल्या रस्त्यांचा अभाव.', 'मागील सर्व प्रयत्नांमध्ये अपयशी ठरल्यानंतर, त्याने एक नवीन योजना तयार केली ज्यामुळे सर्वांना आश्चर्य वाटले.']\n",
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva In his daily traffickings , a Cairene resident is often made conscious of the suffocating pollution .', 'eng_Latn mar_Deva If drama implies conflict , and poetry metaphor , then poetic drama must imply the dramatization of metaphor !']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████▎                         | 5/14 [00:04<00:07,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['त्याच्या दैनंदिन तस्करीमध्ये, कॅरेनच्या रहिवाशाला अनेकदा गुदमरणाऱ्या प्रदूषणाची जाणीव करून दिली जाते.', 'जर नाटक म्हणजे संघर्ष आणि काव्याचे रूपक असेल, तर काव्यात्मक नाटक म्हणजे रूपकाचे नाट्यीकरण असावे!']\n",
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva The calculator executed the functions that had been selected , and displayed the results on the top half of the screen .', 'eng_Latn mar_Deva There are many disturbing factors : fatigue , poor eye-sight , poor reading ability , anxiety or undue caution , distractibility , and inadequate motivation .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████▏                      | 6/14 [00:05<00:06,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['कॅल्क्युलेटरने निवडलेली कार्ये अंमलात आणली आणि स्क्रीनच्या वरच्या अर्ध्या भागात परिणाम प्रदर्शित केले.', 'थकवा, कमकुवत दृष्टी, खराब वाचन क्षमता, चिंता किंवा अनावश्यक सावधगिरी, लक्ष विचलित करणे आणि अपुरी प्रेरणा असे अनेक त्रासदायक घटक आहेत.']\n",
      "here\n",
      "[Debug] Preprocessed batch sample: [\"eng_Latn mar_Deva The crucial words in the specification are ' the signals must be routed internally ' .\", 'eng_Latn mar_Deva Would you please supply a list of the correct settings for the ABC ?']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████                    | 7/14 [00:05<00:05,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: [\"विशिष्टतेतील महत्त्वाचे शब्द म्हणजे'संकेत अंतर्गतपणे निर्देशित केले जाणे आवश्यक आहे '.\", 'कृपया तुम्ही ए. बी. सी. साठी योग्य सेटिंग्जची यादी द्याल का?']\n",
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva However , oxidative stress occurs when the balance is disturbed , through an increase in reactive oxygen species .', \"eng_Latn mar_Deva Should any burner fail to ignite , its respective section will revert to ' purge ' , and in this way the system ensures safe removal of unburned fuel\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████▊                 | 8/14 [00:06<00:05,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['तथापि, प्रतिक्रियाशील ऑक्सिजन प्रजातींमध्ये वाढ झाल्यामुळे संतुलन बिघडते तेव्हा ऑक्सिडेटिव्ह ताण उद्भवतो.', \"जर कोणतेही बर्नर प्रज्वलित करण्यात अयशस्वी ठरले, तर त्याचा संबंधित विभाग'शुध्दीकरण'कडे परत जाईल आणि अशा प्रकारे प्रणाली न जळलेले इंधन सुरक्षितपणे काढून टाकण्याची खात्री करते.\"]\n",
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva Unfortunately though , incorrect predictions were made about both negative and positive experiments , leading to doubts about the reliability of the underlying model .', 'eng_Latn mar_Deva Reject the applicant , using procedure XYZ to ensure compliance with standard evaluation protocols .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|█████████████████████████▋              | 9/14 [00:07<00:04,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['दुर्दैवाने, नकारात्मक आणि सकारात्मक अशा दोन्ही प्रयोगांबद्दल चुकीचे अंदाज लावले गेले, ज्यामुळे अंतर्निहित मॉडेलच्या विश्वासार्हतेबद्दल शंका निर्माण झाली.', 'प्रमाणित मूल्यांकन प्रोटोकॉलचे पालन सुनिश्चित करण्यासाठी XYZ प्रक्रिया वापरून अर्जदाराला नाकारणे.']\n",
      "here\n",
      "[Debug] Preprocessed batch sample: [\"eng_Latn mar_Deva Insert the new disk into the disk drive , with the notch at the bottom facing the drive 's entry slot .\", 'eng_Latn mar_Deva Replace the fuel lines and electrical conduits which have cracks or damaged B-nut fittings to prevent leaks and ensure safe operation .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████████████████████████▊           | 10/14 [00:08<00:03,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['डिस्क ड्राइव्हमध्ये नवीन डिस्क घाला, ज्याच्या तळाशी ड्राइव्हच्या प्रवेश स्लॉटला तोंड देणारी खाच आहे.', 'गळती टाळण्यासाठी आणि सुरक्षित ऑपरेशन सुनिश्चित करण्यासाठी इंधन तार आणि विजेच्या वाहिन्या ज्या फाटल्या आहेत किंवा खराब झालेल्या बी - नट फिटिंग्ज आहेत त्या बदला.']\n",
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva Take no action , as the camera operates automatically under all lighting conditions .', 'eng_Latn mar_Deva The species of fish supported by the reef are varied , and abundant food supplies are available to sustain their populations .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████▋        | 11/14 [00:09<00:02,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['कोणतीही कारवाई करू नका, कारण कॅमेरा सर्व प्रकाश परिस्थितींमध्ये स्वयंचलितपणे कार्य करतो.', 'खडकांद्वारे समर्थित माशांच्या प्रजाती वैविध्यपूर्ण आहेत आणि त्यांची लोकसंख्या टिकवून ठेवण्यासाठी मुबलक अन्न पुरवठा उपलब्ध आहे.']\n",
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva Connection to PTT-supplied packet-switch networks will be a prime requirement of the workstation , and gateways into these networks are planned by the PTTs to ensure seamless data communication .', 'eng_Latn mar_Deva The system consistently achieved 50 gallons per hour - optimum output .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████▍     | 12/14 [00:10<00:02,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['पी. टी. टी. - पुरविलेल्या पॅकेट - स्विच नेटवर्कशी जोडणी ही वर्कस्टेशनची प्रमुख आवश्यकता असेल आणि अखंड डेटा संप्रेषण सुनिश्चित करण्यासाठी पी. टी. टी. द्वारे या नेटवर्कमधील प्रवेशद्वारांचे नियोजन केले जाते.', 'प्रणालीने सातत्याने 50 गॅलन प्रति तास साध्य केले - इष्टतम उत्पादन.']\n",
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva Morphological studies of paraquat- or oxygen-toxicity in rats have shown significant cellular damage in lung tissue .', \"eng_Latn mar_Deva One should read G. V. Carey 's chapter ' Proof Correction ' in Mind the Stop .\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|████████████████████████████████████▏  | 13/14 [00:11<00:01,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['उंदरांमधील पॅराक्वाट - किंवा ऑक्सिजन - विषाक्ततेच्या आकारशास्त्रीय अभ्यासातून फुफ्फुसाच्या ऊतींमध्ये लक्षणीय पेशीय नुकसान झाल्याचे दिसून आले आहे.', \"जी. व्ही. कॅरी यांचा'प्रूफ करेक्शन'हा अध्याय'माइंड द स्टॉप'मध्ये वाचला पाहिजे.\"]\n",
      "here\n",
      "[Debug] Preprocessed batch sample: ['eng_Latn mar_Deva a water / glycol ratio of < ID1 > is preferred .', 'eng_Latn mar_Deva It has thickness of only < ID1 > inch .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 14/14 [00:12<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Decoded sample: ['< आयडी1 > चे पाणी / ग्लायकोल गुणोत्तर पसंत केले जाते.', 'त्याची जाडी फक्त < आयडी1 > इंच आहे.']\n",
      "\n",
      "Successful translations: 54 / 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------- TRANSLATION --------------------\n",
    "valid_src = []\n",
    "valid_pred = []\n",
    "valid_gt = []\n",
    "valid_gem = []\n",
    "valid_cfilt = []\n",
    "\n",
    "# Translate in batches\n",
    "all_translations = []\n",
    "for i in tqdm(range(0, len(src_sentences), BATCH_SIZE)):\n",
    "    batch = src_sentences[i:i+BATCH_SIZE]\n",
    "#     print(batch)\n",
    "    translations = batch_translate(\n",
    "        batch,\n",
    "        src_lang,\n",
    "        tgt_lang,\n",
    "        en_indic_model,\n",
    "        en_indic_tokenizer,\n",
    "        ip,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    all_translations.extend(translations)\n",
    "\n",
    "    if translations is None:\n",
    "        print(f\"[SKIPPED] Batch {i}: Returned None\")\n",
    "        continue\n",
    "\n",
    "    cleaned = [remove_prefix(t) for t in translations]\n",
    "\n",
    "    valid_src.extend(batch)\n",
    "    valid_pred.extend(cleaned)\n",
    "    valid_gt.extend(ref_gt[i:i + len(batch)])\n",
    "    valid_gem.extend(ref_gem[i:i + len(batch)])\n",
    "    valid_cfilt.extend(ref_cfilt[i:i + len(batch)])\n",
    "\n",
    "print(f\"\\nSuccessful translations: {len(valid_pred)} / {len(src_sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e858a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"sent_meant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab8ed5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved predictions to sent_meant_outputs.csv\n",
      "\n",
      "===== FINAL METRICS =====\n",
      "All references combined → BLEU: 83.34, chrF++: 90.50\n",
      "GT Marathi → BLEU: 63.29\n",
      "Gemini    → BLEU: 26.20\n",
      "CFILT     → BLEU: 67.17\n",
      "\n",
      "🎯 BEST REFERENCE = CFILT (by highest BLEU)\n",
      "Metrics written to punct_sent_meant_baseline_outputs_eval_metrics.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "\n",
    "# -------------------- SAVE OUTPUTS --------------------\n",
    "results_df = pd.DataFrame({\n",
    "    \"src\": valid_src,\n",
    "    \"prediction\": valid_pred,\n",
    "    \"gt\": valid_gt,\n",
    "    \"gemini\": valid_gem,\n",
    "    \"cfilt\": valid_cfilt\n",
    "})\n",
    "\n",
    "results_df.to_csv(f\"{mode}_outputs.csv\", index=False)\n",
    "print(f\"✔ Saved predictions to {mode}_outputs.csv\")\n",
    "\n",
    "# -------------------- METRICS --------------------\n",
    "bleu = load(\"sacrebleu\")\n",
    "chrf = load(\"chrf\")\n",
    "\n",
    "def compute_scores(preds, ref1, ref2, ref3):\n",
    "    \"\"\"\n",
    "    Compute BLEU and chrF++ scores using all three references for each sentence.\n",
    "    \"\"\"\n",
    "    references = [[r1, r2, r3] for r1, r2, r3 in zip(ref1, ref2, ref3)]  # sacrebleu format\n",
    "    bleu_score = bleu.compute(predictions=preds, references=references)[\"score\"]\n",
    "    chrf_score = chrf.compute(predictions=preds, references=references)[\"score\"]\n",
    "    return bleu_score, chrf_score\n",
    "\n",
    "bleu_score, chrf_score = compute_scores(valid_pred, valid_gt, valid_gem, valid_cfilt)\n",
    "\n",
    "# Determine best reference per metric (based on BLEU)\n",
    "all_scores = {\n",
    "    \"GT\":    bleu.compute(predictions=valid_pred, references=[[r] for r in valid_gt])[\"score\"],\n",
    "    \"Gemini\": bleu.compute(predictions=valid_pred, references=[[r] for r in valid_gem])[\"score\"],\n",
    "    \"CFILT\":  bleu.compute(predictions=valid_pred, references=[[r] for r in valid_cfilt])[\"score\"]\n",
    "}\n",
    "\n",
    "best_ref = max(all_scores, key=all_scores.get)\n",
    "\n",
    "print(\"\\n===== FINAL METRICS =====\")\n",
    "print(f\"All references combined → BLEU: {bleu_score:.2f}, chrF++: {chrf_score:.2f}\")\n",
    "print(f\"GT Marathi → BLEU: {all_scores['GT']:.2f}\")\n",
    "print(f\"Gemini    → BLEU: {all_scores['Gemini']:.2f}\")\n",
    "print(f\"CFILT     → BLEU: {all_scores['CFILT']:.2f}\")\n",
    "print(f\"\\n🎯 BEST REFERENCE = {best_ref} (by highest BLEU)\")\n",
    "\n",
    "# -------------------- SAVE METRICS --------------------\n",
    "with open(f\"punct_{mode}_indictrans2_eval_metrics.txt\", \"w\") as f:\n",
    "    f.write(f\"All references combined → BLEU {bleu_score:.2f}, chrF++ {chrf_score:.2f}\\n\")\n",
    "    f.write(f\"GT    BLEU {all_scores['GT']:.2f}\\n\")\n",
    "    f.write(f\"Gem   BLEU {all_scores['Gemini']:.2f}\\n\")\n",
    "    f.write(f\"CFILT BLEU {all_scores['CFILT']:.2f}\\n\")\n",
    "    f.write(f\"\\nBEST REFERENCE = {best_ref}\\n\")\n",
    "\n",
    "print(f\"Metrics written to punct_{mode}_baseline_outputs_eval_metrics.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "051f6921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['These glycans are poorly transferred to proteins resulting in unoccupied, glycosylation sequons.',\n",
       " 'X is an effective acute, oral treatment for migraine with a rapid onset of action',\n",
       " 'No newspaper is completely unbiased in, my, expert, opinion.',\n",
       " 'Steam, for, example is, just as damaging as acid for that material.',\n",
       " 'My favourite opera composers are Verdi, Puccini, Mozart and Gilbert and Sullivan.',\n",
       " 'The only problem with the new project established in the desert at high cost is the lack of good access roads.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_sentences[7:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b4486b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['These glycans are poorly transferred to proteins, resulting in unoccupied glycosylation sequons.',\n",
       " 'X is an effective acute, oral treatment for migraine, with a rapid onset of action',\n",
       " 'No newspaper is completely unbiased, in my expert opinion.',\n",
       " 'Steam, for example, is just as damaging as acid for that material.',\n",
       " 'My favourite opera composers are Verdi, Puccini, Mozart, and Gilbert and Sullivan.',\n",
       " 'The only problem with the new project, established in the desert at high cost, is the lack of good access roads.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_sentences[7:13]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
