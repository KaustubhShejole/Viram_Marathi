{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0ab2e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "152fe251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/Approach1/perf-outputs'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbb955ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(197285, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labse_tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/LaBSE\")\n",
    "labse_model = AutoModel.from_pretrained(\"sentence-transformers/LaBSE\")\n",
    "\n",
    "muril_tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\n",
    "muril_model = AutoModel.from_pretrained(\"google/muril-base-cased\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "labse_model.to(device)\n",
    "muril_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "283f7e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ref_based_scores(mt_texts, ref_texts, method=\"max\"):\n",
    "    results = []\n",
    "    \n",
    "    for i, mt in enumerate(mt_texts):\n",
    "        ref = ref_texts[i]\n",
    "        \n",
    "        labse_ref_scores = []\n",
    "        muril_ref_scores = []\n",
    "        \n",
    "        # --- LaBSE ---\n",
    "        inputs = labse_tokenizer([ref, mt], padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            embeddings = labse_model(**inputs).pooler_output\n",
    "        labse_ref_mt = F.cosine_similarity(embeddings[0].unsqueeze(0), embeddings[1].unsqueeze(0)).item()\n",
    "\n",
    "        # --- MuRIL ---\n",
    "        inputs = muril_tokenizer([ref, mt], padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = muril_model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        muril_ref_mt = F.cosine_similarity(embeddings[0].unsqueeze(0), embeddings[1].unsqueeze(0)).item()\n",
    "\n",
    "        results.append({\n",
    "            \"mt\": mt,\n",
    "            \"labse_ref_mt\": labse_ref_mt,\n",
    "            \"muril_ref_mt\": muril_ref_mt\n",
    "        })\n",
    "    \n",
    "    df_scores = pd.DataFrame(results)\n",
    "    \n",
    "    # System-level averages\n",
    "    system_scores = {\n",
    "        \"labse_ref_mt\": df_scores[\"labse_ref_mt\"].mean(),\n",
    "        \"muril_ref_mt\": df_scores[\"muril_ref_mt\"].mean()\n",
    "    }\n",
    "    \n",
    "    return system_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2843934",
   "metadata": {},
   "outputs": [],
   "source": [
    "labse = {}\n",
    "muril = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cd24ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from evaluate import load\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "def compute_translation_scores(predictions, references, lang='en'):\n",
    "    \"\"\"\n",
    "    Compute reference-based translation evaluation scores using:\n",
    "    1. BERTScore (MuRIL)\n",
    "    2. LaBSE cosine similarity\n",
    "    \n",
    "    Args:\n",
    "        predictions (list of str): Model outputs\n",
    "        references (list of str): Reference translations\n",
    "        lang (str): Language code for BERTScore ('en', 'hi', etc.)\n",
    "    \n",
    "    Returns:\n",
    "        dict: {'muril_f1': float, 'labse_cosine': float}\n",
    "    \"\"\"\n",
    "    assert len(predictions) == len(references), \"Predictions and references must have the same length\"\n",
    "\n",
    "    # ---------- BERTScore (MuRIL) ----------\n",
    "    bertscore = load(\"bertscore\")\n",
    "    bert_results = bertscore.compute(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "        model_type='google/muril-base-cased',\n",
    "        num_layers=4,\n",
    "        lang=lang\n",
    "    )\n",
    "    muril_f1_mean = float(np.mean(bert_results['f1']))\n",
    "\n",
    "    # ---------- LaBSE Cosine Similarity ----------\n",
    "    model = SentenceTransformer('sentence-transformers/LaBSE')\n",
    "    pred_emb = model.encode(predictions, convert_to_tensor=True)\n",
    "    ref_emb = model.encode(references, convert_to_tensor=True)\n",
    "    cosine_sim_matrix = util.cos_sim(pred_emb, ref_emb)\n",
    "    # Take diagonal (each prediction with its reference)\n",
    "    labse_cosine_mean = float(cosine_sim_matrix.diag().mean())\n",
    "\n",
    "    return {'muril_score': muril_f1_mean, 'labse_cosine': labse_cosine_mean}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c01c57d",
   "metadata": {},
   "source": [
    "## T5 Punctuation Restoration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9df24cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"approach1_eng_to_eng_t5_outputs_punct_restor_data.csv\"\n",
    "mode = \"t5_punct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0982f0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaBSE and MuRIL Scores for t5_punct:\n",
      "{'labse_ref_mt': 0.9895218774622835, 'muril_ref_mt': 0.9998911888104498}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file_name)\n",
    "\n",
    "predictions = df['prediction'].tolist()\n",
    "references = df['gt'].tolist()\n",
    "\n",
    "scores = compute_ref_based_scores(predictions, references)\n",
    "labse[mode] = scores['labse_ref_mt']\n",
    "muril[mode] = scores['muril_ref_mt']\n",
    "\n",
    "print(f\"LaBSE and MuRIL Scores for {mode}:\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253c05f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53ab84fe",
   "metadata": {},
   "source": [
    "## T5 Seq-to-Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dec154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"approach1_eng_to_eng_t5_outputs_mar_data.csv\"\n",
    "mode = \"t5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cfce135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>src</th>\n",
       "      <th>gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chanting, the choir raised the volume as the c...</td>\n",
       "      <td>Chanting the choir raised the volume as the ce...</td>\n",
       "      <td>Chanting, the choir raised the volume as the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A six-month-old calf was submitted for examina...</td>\n",
       "      <td>A six-month-old calf was submitted for examina...</td>\n",
       "      <td>A six-month-old calf was submitted for examina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Planning authorities should provide alternativ...</td>\n",
       "      <td>Planning authorities should provide alternativ...</td>\n",
       "      <td>Planning authorities should provide alternativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As the machine develops, the forms we use to r...</td>\n",
       "      <td>As the machine develops the forms we use to re...</td>\n",
       "      <td>As the machine develops, the forms we use to r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As mentioned, first impressions can be mislead...</td>\n",
       "      <td>As mentioned, first impressions can be mislead...</td>\n",
       "      <td>As mentioned first, impressions can be mislead...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prediction  \\\n",
       "0  Chanting, the choir raised the volume as the c...   \n",
       "1  A six-month-old calf was submitted for examina...   \n",
       "2  Planning authorities should provide alternativ...   \n",
       "3  As the machine develops, the forms we use to r...   \n",
       "4  As mentioned, first impressions can be mislead...   \n",
       "\n",
       "                                                 src  \\\n",
       "0  Chanting the choir raised the volume as the ce...   \n",
       "1  A six-month-old calf was submitted for examina...   \n",
       "2  Planning authorities should provide alternativ...   \n",
       "3  As the machine develops the forms we use to re...   \n",
       "4  As mentioned, first impressions can be mislead...   \n",
       "\n",
       "                                                  gt  \n",
       "0  Chanting, the choir raised the volume as the c...  \n",
       "1  A six-month-old calf was submitted for examina...  \n",
       "2  Planning authorities should provide alternativ...  \n",
       "3  As the machine develops, the forms we use to r...  \n",
       "4  As mentioned first, impressions can be mislead...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file_name)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4970187c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'muril_score': 0.9779256262161113, 'labse_cosine': 0.9862358570098877}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = df['prediction'].tolist()\n",
    "references = df['gt'].tolist()\n",
    "\n",
    "compute_translation_scores(predictions, references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39519f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9048b36",
   "metadata": {},
   "source": [
    "## IndicTrans2 Sentences Meant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b9d41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"sent_meant_outputs.csv\"\n",
    "mode = \"original_meant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4270799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaBSE and MuRIL Scores for original_meant:\n",
      "{'labse_ref_mt': 0.9312928307939459, 'muril_ref_mt': 0.9983996759962153}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file_name)\n",
    "\n",
    "predictions = df['prediction'].tolist()\n",
    "references = df['gemini'].tolist()\n",
    "\n",
    "scores = compute_ref_based_scores(predictions, references)\n",
    "labse[mode] = scores['labse_ref_mt']\n",
    "muril[mode] = scores['muril_ref_mt']\n",
    "\n",
    "print(f\"LaBSE and MuRIL Scores for {mode}:\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11f39b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5029c601",
   "metadata": {},
   "source": [
    "## Cadence Approach1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dbb5191",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"cadence_outputs.csv\"\n",
    "mode = \"cadence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc0f6a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>prediction_mar</th>\n",
       "      <th>gt_mar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chanting the choir raised the volume as the ce...</td>\n",
       "      <td>उत्सवी गायकांनी प्रार्थनेचा उच्चार केल्याने गा...</td>\n",
       "      <td>धर्मगुरू प्रार्थना म्हणत असताना, घोष करणाऱ्या ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A six-month-old calf was submitted for examina...</td>\n",
       "      <td>जन्मानंतर लगेचच अस्तित्वात असलेल्या चारही पाया...</td>\n",
       "      <td>तपासणीसाठी आणलेल्या सहा महिन्यांच्या एका वासरा...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Planning authorities should provide alternativ...</td>\n",
       "      <td>नियोजन अधिकाऱ्यांनी छोट्या व्यवसायांसाठी पर्या...</td>\n",
       "      <td>नियोजन प्राधिकरणांनी लहान व्यवसायांसाठी पर्याय...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As the machine develops the forms we use to re...</td>\n",
       "      <td>जसजसे मशीन विकसित होईल तसतसे आम्ही मागील प्रकल...</td>\n",
       "      <td>जसजशी यंत्रणा विकसित होईल, तसतसे मागील प्रकल्प...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As mentioned, first impressions can be mislead...</td>\n",
       "      <td>नमूद केल्याप्रमाणे, पहिली छाप दिशाभूल करणारी अ...</td>\n",
       "      <td>आधी सांगितल्याप्रमाणे, पहिली छाप फसवी असू शकते.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 src  \\\n",
       "0  Chanting the choir raised the volume as the ce...   \n",
       "1  A six-month-old calf was submitted for examina...   \n",
       "2  Planning authorities should provide alternativ...   \n",
       "3  As the machine develops the forms we use to re...   \n",
       "4  As mentioned, first impressions can be mislead...   \n",
       "\n",
       "                                      prediction_mar  \\\n",
       "0  उत्सवी गायकांनी प्रार्थनेचा उच्चार केल्याने गा...   \n",
       "1  जन्मानंतर लगेचच अस्तित्वात असलेल्या चारही पाया...   \n",
       "2  नियोजन अधिकाऱ्यांनी छोट्या व्यवसायांसाठी पर्या...   \n",
       "3  जसजसे मशीन विकसित होईल तसतसे आम्ही मागील प्रकल...   \n",
       "4  नमूद केल्याप्रमाणे, पहिली छाप दिशाभूल करणारी अ...   \n",
       "\n",
       "                                              gt_mar  \n",
       "0  धर्मगुरू प्रार्थना म्हणत असताना, घोष करणाऱ्या ...  \n",
       "1  तपासणीसाठी आणलेल्या सहा महिन्यांच्या एका वासरा...  \n",
       "2  नियोजन प्राधिकरणांनी लहान व्यवसायांसाठी पर्याय...  \n",
       "3  जसजशी यंत्रणा विकसित होईल, तसतसे मागील प्रकल्प...  \n",
       "4    आधी सांगितल्याप्रमाणे, पहिली छाप फसवी असू शकते.  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44da6831",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'prediction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'prediction'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      2\u001b[0m references \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      4\u001b[0m compute_translation_scores(predictions, references)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'prediction'"
     ]
    }
   ],
   "source": [
    "predictions = df['prediction'].tolist()\n",
    "references = df['gt'].tolist()\n",
    "\n",
    "compute_translation_scores(predictions, references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5de210e",
   "metadata": {},
   "source": [
    "## Cadence Punctuation Restoration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3452fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"approach1_eng_to_eng_cadence_outputs_punct_restor_data.csv\"\n",
    "mode = \"cadence_approach1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "818cc7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>src</th>\n",
       "      <th>gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chanting the choir raised the volume as the ce...</td>\n",
       "      <td>Chanting the choir raised the volume as the ce...</td>\n",
       "      <td>Chanting, the choir raised the volume as the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A six-month-old calf was submitted for examina...</td>\n",
       "      <td>A six-month-old calf was submitted for examina...</td>\n",
       "      <td>A six-month-old calf was submitted for examina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Planning authorities should provide alternativ...</td>\n",
       "      <td>Planning authorities should provide alternativ...</td>\n",
       "      <td>Planning authorities should provide alternativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As the machine develops the forms we use to re...</td>\n",
       "      <td>As the machine develops the forms we use to re...</td>\n",
       "      <td>As the machine develops, the forms we use to r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As mentioned, first impressions can be mislead...</td>\n",
       "      <td>As mentioned, first impressions can be mislead...</td>\n",
       "      <td>As mentioned first, impressions can be mislead...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prediction  \\\n",
       "0  Chanting the choir raised the volume as the ce...   \n",
       "1  A six-month-old calf was submitted for examina...   \n",
       "2  Planning authorities should provide alternativ...   \n",
       "3  As the machine develops the forms we use to re...   \n",
       "4  As mentioned, first impressions can be mislead...   \n",
       "\n",
       "                                                 src  \\\n",
       "0  Chanting the choir raised the volume as the ce...   \n",
       "1  A six-month-old calf was submitted for examina...   \n",
       "2  Planning authorities should provide alternativ...   \n",
       "3  As the machine develops the forms we use to re...   \n",
       "4  As mentioned, first impressions can be mislead...   \n",
       "\n",
       "                                                  gt  \n",
       "0  Chanting, the choir raised the volume as the c...  \n",
       "1  A six-month-old calf was submitted for examina...  \n",
       "2  Planning authorities should provide alternativ...  \n",
       "3  As the machine develops, the forms we use to r...  \n",
       "4  As mentioned first, impressions can be mislead...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20f149ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'muril_score': 0.9736823285067523, 'labse_cosine': 0.9833676218986511}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = df['prediction'].tolist()\n",
    "references = df['gt'].tolist()\n",
    "\n",
    "compute_translation_scores(predictions, references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e172d42",
   "metadata": {},
   "source": [
    "## DeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0023eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"shalaka_deepseek_outputs.csv\"\n",
    "mode = \"deepseek\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef9a2f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaBSE and MuRIL Scores for deepseek:\n",
      "{'labse_ref_mt': 0.9197003432997951, 'muril_ref_mt': 0.9981370844222881}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file_name)\n",
    "\n",
    "predictions = df['prediction'].tolist()\n",
    "references = df['gt'].tolist()\n",
    "\n",
    "scores = compute_ref_based_scores(predictions, references)\n",
    "labse[mode] = scores['labse_ref_mt']\n",
    "muril[mode] = scores['muril_ref_mt']\n",
    "\n",
    "print(f\"LaBSE and MuRIL Scores for {mode}:\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a388c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a727f14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cadence : 0.9210\n",
      "cadence_approach1 : 0.9834\n",
      "deepseek : 0.9197\n"
     ]
    }
   ],
   "source": [
    "for key, val in labse.items():\n",
    "    print(f\"{key} : {val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e8d7c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cadence : 0.998364\n",
      "cadence_approach1 : 0.999806\n",
      "deepseek : 0.998137\n"
     ]
    }
   ],
   "source": [
    "for key, val in muril.items():\n",
    "    print(f\"{key} : {val:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
