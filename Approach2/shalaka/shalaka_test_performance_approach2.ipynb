{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52e9e5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall -y flash-attn\n",
    "# !pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61ef3eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --force-reinstall torch --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce198e0",
   "metadata": {},
   "source": [
    "üîπ Why chrF2++ is preferred for EN‚ÜíIndic MT\n",
    "\n",
    "Indic languages (Marathi, Hindi, Bengali, Tamil, etc.) are:\n",
    "\n",
    "morphologically rich\n",
    "\n",
    "often longer than English\n",
    "\n",
    "have free word order\n",
    "\n",
    "contain agglutination and fused morphemes\n",
    "\n",
    "Because of this:\n",
    "\n",
    "chrF++ (Œ≤=3) tends to inflate scores for long/verbose translations\n",
    "\n",
    "chrF2++ (Œ≤=2) balances precision and recall better\n",
    "\n",
    "chrF2++ correlates more strongly with human judgment in EN‚ÜíIndic evaluations\n",
    "(reported in FLORES, WAT, ITTB, AI4Bharat, Microsoft MT work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1932caeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_punct_model = \"thenlpresearcher/shalaka_indictrans2-en-indic-dist-200M_finetuned_eng_Latn_to_mar_Deva\"\n",
    "combined_punct_model_data_changed = \"thenlpresearcher/shalaka_fd_indictrans2-en-indic-dist-200M_finetuned_eng_Latn_to_mar_Deva\"\n",
    "combined_punct_model_name = \"thenlpresearcher/iitb_en_indic_robust_punctuation_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa49ac49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "raw_datasets = load_dataset(\"thenlpresearcher/test_data_marathi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9ce6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- LOAD DATA --------------------\n",
    "src_sentences = raw_datasets['test'][\"sent_written\"]\n",
    "ref_gt     = raw_datasets['test'][\"gt_marathi\"]\n",
    "ref_gem    = raw_datasets['test'][\"gemini_out\"]\n",
    "ref_cfilt  = raw_datasets['test'][\"cfilt_out\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eea8b249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/Approach2/shalaka'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77e8444b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 24 18:02:49 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.5     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          Off | 00000000:17:00.0 Off |                    0 |\n",
      "| N/A   56C    P0              71W / 300W |  24249MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80GB PCIe          Off | 00000000:31:00.0 Off |                    0 |\n",
      "| N/A   43C    P0              73W / 300W |  79577MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100 80GB PCIe          Off | 00000000:4B:00.0 Off |                    0 |\n",
      "| N/A   55C    P0              74W / 300W |  57684MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100 80GB PCIe          Off | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   41C    P0              62W / 300W |   2036MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0e3007",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b99f9fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ai4bharat/indictrans2-en-indic-dist-200M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d98a5658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 18:02:54.940247: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-24 18:02:55.016544: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-24 18:02:57.458444: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng_Latn: Chanting the choir raised the volume as the celebrant intoned the prayer.\n",
      "mar_Deva: ‡§â‡§§‡•ç‡§∏‡§µ‡•Ä ‡§ó‡§æ‡§Ø‡§ï‡§æ‡§Ç‡§®‡•Ä ‡§™‡•ç‡§∞‡§æ‡§∞‡•ç‡§•‡§®‡•á‡§ö‡§æ ‡§â‡§ö‡•ç‡§ö‡§æ‡§∞ ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§®‡•á ‡§ó‡§æ‡§Ø‡§ï‡§µ‡•É‡§Ç‡§¶‡§æ‡§ö‡§æ ‡§ú‡§™ ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§®‡•á ‡§ß‡•ç‡§µ‡§®‡•Ä‡§Æ‡•Å‡§¶‡•ç‡§∞‡§£ ‡§µ‡§æ‡§¢‡§≤‡•á...........................................................................................................................................................................................................................................\n",
      "eng_Latn: A six-month-old calf was submitted for examination, showing lameness in all four legs which had been present since soon after birth.\n",
      "mar_Deva: ‡§ú‡§®‡•ç‡§Æ‡§æ‡§®‡§Ç‡§§‡§∞ ‡§≤‡§ó‡•á‡§ö‡§ö ‡§Ö‡§∏‡•ç‡§§‡§ø‡§§‡•ç‡§µ‡§æ‡§§ ‡§Ö‡§∏‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§ö‡§æ‡§∞‡§π‡•Ä ‡§™‡§æ‡§Ø‡§æ‡§Ç‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§≤‡§Ç‡§ó‡§°‡•á‡§™‡§£‡§æ ‡§¶‡§∞‡•ç‡§∂‡§µ‡§ø‡§£‡§æ‡§±‡•ç‡§Ø‡§æ ‡§∏‡§π‡§æ ‡§Æ‡§π‡§ø‡§®‡•ç‡§Ø‡§æ‡§Ç‡§ö‡•ç‡§Ø‡§æ ‡§µ‡§æ‡§∏‡§∞‡§æ‡§≤‡§æ ‡§§‡§™‡§æ‡§∏‡§£‡•Ä‡§∏‡§æ‡§†‡•Ä ‡§∏‡§æ‡§¶‡§∞ ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§§ ‡§Ü‡§≤‡•á....................................................................................................................................................................................................................................\n",
      "eng_Latn: Planning authorities should provide alternative locations for small businesses which are or would be offensive in a residential area.\n",
      "mar_Deva: ‡§®‡§ø‡§Ø‡•ã‡§ú‡§® ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§±‡•ç‡§Ø‡§æ‡§Ç‡§®‡•Ä ‡§õ‡•ã‡§ü‡•ç‡§Ø‡§æ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø‡§æ‡§Ç‡§∏‡§æ‡§†‡•Ä ‡§™‡§∞‡•ç‡§Ø‡§æ‡§Ø‡•Ä ‡§†‡§ø‡§ï‡§æ‡§£‡•á ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§ï‡§∞‡•Ç‡§® ‡§¶‡§ø‡§≤‡•Ä ‡§™‡§æ‡§π‡§ø‡§ú‡•á‡§§ ‡§ú‡•Ä ‡§®‡§ø‡§µ‡§æ‡§∏‡•Ä ‡§≠‡§æ‡§ó‡§æ‡§§ ‡§Ü‡§ï‡•ç‡§∑‡•á‡§™‡§æ‡§∞‡•ç‡§π ‡§Ü‡§π‡•á‡§§ ‡§ï‡§ø‡§Ç‡§µ‡§æ ‡§Ö‡§∏‡§§‡•Ä‡§≤...........................................................................................................................................................................................................................................\n",
      "eng_Latn: As the machine develops the forms we use to record data from past projects will be amended.\n",
      "mar_Deva: ‡§ú‡§∏‡§ú‡§∏‡•á ‡§Æ‡§∂‡•Ä‡§® ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§π‡•ã‡§à‡§≤ ‡§§‡§∏‡§§‡§∏‡•á ‡§Ü‡§Æ‡•ç‡§π‡•Ä ‡§Æ‡§æ‡§ó‡•Ä‡§≤ ‡§™‡•ç‡§∞‡§ï‡§≤‡•ç‡§™‡§æ‡§Ç‡§Æ‡§ß‡•Ä‡§≤ ‡§°‡•á‡§ü‡§æ ‡§∞‡•á‡§ï‡•â‡§∞‡•ç‡§° ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§µ‡§æ‡§™‡§∞‡§§ ‡§Ö‡§∏‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§´‡•â‡§∞‡•ç‡§Æ‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§∏‡•Å‡§ß‡§æ‡§∞‡§£‡§æ ‡§ï‡•á‡§≤‡•Ä ‡§ú‡§æ‡§à‡§≤........................................................................................................................................................................................................................................\n",
      "eng_Latn: As mentioned, first impressions can be misleading.\n",
      "mar_Deva: ‡§®‡§Æ‡•Ç‡§¶ ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§™‡•ç‡§∞‡§Æ‡§æ‡§£‡•á, ‡§™‡§π‡§ø‡§≤‡•Ä ‡§õ‡§æ‡§™ ‡§¶‡§ø‡§∂‡§æ‡§≠‡•Ç‡§≤ ‡§ï‡§∞‡§£‡§æ‡§∞‡•Ä ‡§Ö‡§∏‡•Ç ‡§∂‡§ï‡§§‡•á...................................................................................................................................................................................................................................................\n",
      "eng_Latn: To get a clean assembly load the assembled equals table before the assembly is run.\n",
      "mar_Deva: ‡§∏‡•ç‡§µ‡§ö‡•ç‡§õ ‡§Ö‡§∏‡•á‡§Ç‡§¨‡•ç‡§≤‡•Ä ‡§≤‡•ã‡§° ‡§Æ‡§ø‡§≥‡§µ‡§ø‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§Ö‡§∏‡•á‡§Ç‡§¨‡•ç‡§≤‡•Ä ‡§ö‡§æ‡§≤‡§µ‡§£‡•ç‡§Ø‡§æ‡§™‡•Ç‡§∞‡•ç‡§µ‡•Ä ‡§Ö‡§∏‡•á‡§Ç‡§¨‡§≤ ‡§ï‡•á‡§≤‡•á‡§≤‡•á ‡§∏‡§Æ‡§æ‡§® ‡§ü‡•á‡§¨‡§≤...............................................................................................................................................................................................................................................\n",
      "eng_Latn: Executors delay giving information about substantial deviations from agreed dates. Because of this action cannot be taken in time.\n",
      "mar_Deva: ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§ï‡•á‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§§‡§æ‡§∞‡§ñ‡§æ‡§Ç‡§™‡§æ‡§∏‡•Ç‡§® ‡§≤‡§ï‡•ç‡§∑‡§£‡•Ä‡§Ø ‡§µ‡§ø‡§ö‡§≤‡§®‡§æ‡§Ç‡§ö‡•Ä ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä ‡§¶‡•á‡§£‡•ç‡§Ø‡§æ‡§∏ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡§æ‡§∞‡•Ä ‡§µ‡§ø‡§≤‡§Ç‡§¨ ‡§ï‡§∞‡§§‡§æ‡§§. ‡§§‡•ç‡§Ø‡§æ‡§Æ‡•Å‡§≥‡•á ‡§π‡•Ä ‡§ï‡§æ‡§∞‡§µ‡§æ‡§à ‡§µ‡•á‡§≥‡•á‡§µ‡§∞ ‡§ï‡•á‡§≤‡•Ä ‡§ú‡§æ‡§ä ‡§∂‡§ï‡§§ ‡§®‡§æ‡§π‡•Ä, ‡§Ö‡§∏‡•á ‡§∏‡§æ‡§Ç‡§ó‡§£‡•ç‡§Ø‡§æ‡§§ ‡§Ü‡§≤‡•á.................................................................................................................................................................................................................................\n",
      "eng_Latn: These glycans are poorly transferred to proteins resulting in unoccupied glycosylation sequons.\n",
      "mar_Deva: ‡§π‡•á ‡§ó‡•ç‡§≤‡§æ‡§Ø‡§ï‡•á‡§®‡•ç‡§∏ ‡§™‡•ç‡§∞‡§•‡§ø‡§®‡§æ‡§Ç‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§ñ‡§∞‡§æ‡§¨‡§∞‡§ø‡§§‡•ç‡§Ø‡§æ ‡§π‡§∏‡•ç‡§§‡§æ‡§Ç‡§§‡§∞‡§ø‡§§ ‡§ï‡•á‡§≤‡•á ‡§ú‡§æ‡§§‡§æ‡§§, ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ‡•Ä ‡§∞‡§ø‡§ï‡•ç‡§§ ‡§ó‡•ç‡§≤‡§æ‡§Ø‡§ï‡•ã‡§∏‡§ø‡§≤‡•á‡§∂‡§® ‡§∏‡§ø‡§ï‡•ç‡§µ‡§æ‡§Ç‡§∏ ‡§§‡§Ø‡§æ‡§∞ ‡§π‡•ã‡§§‡§æ‡§§...................................................................................................................................................................................................................................\n",
      "eng_Latn: X is an effective acute, oral treatment for migraine with a rapid onset of action\n",
      "mar_Deva: ‡§è‡§ï‡•ç‡§∏ ‡§π‡§æ ‡§Ö‡§∞‡•ç‡§ß‡§∂‡§ø‡§∂‡•Ä‡§∏‡§æ‡§†‡•Ä ‡§è‡§ï ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡•Ä ‡§§‡•Ä‡§µ‡•ç‡§∞, ‡§§‡•ã‡§Ç‡§°‡•Ä ‡§â‡§™‡§ö‡§æ‡§∞ ‡§Ü‡§π‡•á, ‡§ú‡•ç‡§Ø‡§æ‡§ö‡•Ä ‡§ï‡•É‡§§‡•Ä ‡§ú‡§≤‡§¶ ‡§∏‡•Å‡§∞‡•Ç ‡§π‡•ã‡§§‡•á..........................................................................................................................................................................................................................................\n",
      "eng_Latn: No newspaper is completely unbiased in my expert opinion.\n",
      "mar_Deva: ‡§Æ‡§æ‡§ù‡•ç‡§Ø‡§æ ‡§§‡§ú‡•ç‡§ú‡•ç‡§û‡§æ‡§Ç‡§ö‡•ç‡§Ø‡§æ ‡§Æ‡§§‡•á ‡§ï‡•ã‡§£‡§§‡•á‡§π‡•Ä ‡§µ‡§∞‡•ç‡§§‡§Æ‡§æ‡§®‡§™‡§§‡•ç‡§∞ ‡§™‡•Ç‡§∞‡•ç‡§£‡§™‡§£‡•á ‡§®‡§ø‡§É‡§™‡§ï‡•ç‡§∑‡§™‡§æ‡§§‡•Ä ‡§®‡§æ‡§π‡•Ä...................................................................................................................................................................................................................................................\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from IndicTransToolkit.processor import IndicProcessor\n",
    "# recommended to run this on a gpu with flash_attn installed\n",
    "# don't set attn_implemetation if you don't have flash_attn\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE = torch.device(\"cuda:3\")\n",
    "\n",
    "src_lang, tgt_lang = \"eng_Latn\", \"mar_Deva\"\n",
    "tokenizer_name =  \"ai4bharat/indictrans2-en-indic-dist-200M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name, \n",
    "    trust_remote_code=True, \n",
    "    torch_dtype=torch.float16, # performance might slightly vary for bfloat16\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ").to(DEVICE)\n",
    "\n",
    "ip = IndicProcessor(inference=True)\n",
    "\n",
    "input_sentences = src_sentences\n",
    "\n",
    "batch = ip.preprocess_batch(input_sentences, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "\n",
    "# Tokenize the sentences and generate input encodings\n",
    "inputs = tokenizer(\n",
    "    batch,\n",
    "    truncation=True,\n",
    "    padding=\"longest\",\n",
    "    return_tensors=\"pt\",\n",
    "    return_attention_mask=True,\n",
    ").to(DEVICE)\n",
    "\n",
    "# Generate translations using the model\n",
    "with torch.no_grad():\n",
    "    generated_tokens = model.generate(\n",
    "        **inputs,\n",
    "        use_cache=True,\n",
    "        min_length=0,\n",
    "        max_length=256,\n",
    "        num_beams=5,\n",
    "        num_return_sequences=1,\n",
    "    )\n",
    "\n",
    "# Decode the generated tokens into text\n",
    "generated_tokens = tokenizer.batch_decode(\n",
    "    generated_tokens,\n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=True,\n",
    ")\n",
    "\n",
    "# Postprocess the translations, including entity replacement\n",
    "translations = ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
    "\n",
    "for input_sentence, translation in zip(input_sentences[:10], translations[:10]):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b88aa683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§â‡§§‡•ç‡§∏‡§µ‡•Ä ‡§ó‡§æ‡§Ø‡§ï‡§æ‡§Ç‡§®‡•Ä ‡§™‡•ç‡§∞‡§æ‡§∞‡•ç‡§•‡§®‡•á‡§ö‡§æ ‡§â‡§ö‡•ç‡§ö‡§æ‡§∞ ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§®‡•á ‡§ó‡§æ‡§Ø‡§ï‡§µ‡•É‡§Ç‡§¶‡§æ‡§ö‡§æ ‡§ú‡§™ ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§®‡•á ‡§ß‡•ç‡§µ‡§®‡•Ä‡§Æ‡•Å‡§¶‡•ç‡§∞‡§£ ‡§µ‡§æ‡§¢‡§≤‡•á.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def remove_prefix(translations, prefix):\n",
    "    ans = []\n",
    "    for t in translations:\n",
    "        t = t.strip()\n",
    "        if t.startswith(prefix):\n",
    "            t = t[len(prefix):]\n",
    "        t = re.sub(r'\\.+', '.', t)\n",
    "        ans.append(t)\n",
    "    return ans\n",
    "\n",
    "translations = remove_prefix(translations, \"mar_Deva eng_Latn \")\n",
    "print(translations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "143dab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"original\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc7a722e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Saved predictions to shalaka_original_outputs.csv\n",
      "\n",
      "===== FINAL METRICS =====\n",
      "All references combined ‚Üí BLEU: 68.35, chrF++: 84.70, chrF2++: 82.58\n",
      "GT Marathi ‚Üí BLEU: 56.64\n",
      "Gemini    ‚Üí BLEU: 21.72\n",
      "CFILT     ‚Üí BLEU: 50.55\n",
      "\n",
      "üéØ BEST REFERENCE = GT (by highest BLEU)\n",
      "Metrics written to shalaka_punct_original_baseline_outputs_eval_metrics.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "\n",
    "# -------------------- SAVE OUTPUTS --------------------\n",
    "results_df = pd.DataFrame({\n",
    "    \"src\": src_sentences,\n",
    "    \"prediction\": translations,\n",
    "    \"gt\": ref_gt,\n",
    "    \"gemini\": ref_gem,\n",
    "    \"cfilt\": ref_cfilt\n",
    "})\n",
    "\n",
    "results_df.to_csv(f\"shalaka_{mode}_outputs.csv\", index=False)\n",
    "print(f\"‚úî Saved predictions to shalaka_{mode}_outputs.csv\")\n",
    "\n",
    "# -------------------- METRICS --------------------\n",
    "bleu = load(\"sacrebleu\")\n",
    "chrf = load(\"chrf\")\n",
    "\n",
    "def compute_scores(preds, ref1, ref2, ref3):\n",
    "    \"\"\"\n",
    "    Compute BLEU and chrF++ scores using all three references for each sentence.\n",
    "    \"\"\"\n",
    "    references = [[r1, r2, r3] for r1, r2, r3 in zip(ref1, ref2, ref3)]  # sacrebleu format\n",
    "    bleu_score = bleu.compute(predictions=preds, references=references)[\"score\"]\n",
    "    chrf_score = chrf.compute(predictions=preds, references=references)[\"score\"]\n",
    "    chrf2_score = chrf.compute(predictions=preds, references=references, char_order=6, word_order=2,  beta=2)[\"score\"]\n",
    "    return bleu_score, chrf_score, chrf2_score\n",
    "\n",
    "bleu_score, chrf_score, chrf2_score = compute_scores(translations, ref_gt, ref_gem, ref_cfilt)\n",
    "\n",
    "# Determine best reference per metric (based on BLEU)\n",
    "all_scores = {\n",
    "    \"GT\":    bleu.compute(predictions=translations, references=[[r] for r in ref_gt])[\"score\"],\n",
    "    \"Gemini\": bleu.compute(predictions=translations, references=[[r] for r in ref_gem])[\"score\"],\n",
    "    \"CFILT\":  bleu.compute(predictions=translations, references=[[r] for r in ref_cfilt])[\"score\"]\n",
    "}\n",
    "\n",
    "best_ref = max(all_scores, key=all_scores.get)\n",
    "\n",
    "print(\"\\n===== FINAL METRICS =====\")\n",
    "print(f\"All references combined ‚Üí BLEU: {bleu_score:.2f}, chrF++: {chrf_score:.2f}, chrF2++: {chrf2_score:.2f}\")\n",
    "print(f\"GT Marathi ‚Üí BLEU: {all_scores['GT']:.2f}\")\n",
    "print(f\"Gemini    ‚Üí BLEU: {all_scores['Gemini']:.2f}\")\n",
    "print(f\"CFILT     ‚Üí BLEU: {all_scores['CFILT']:.2f}\")\n",
    "print(f\"\\nüéØ BEST REFERENCE = {best_ref} (by highest BLEU)\")\n",
    "\n",
    "# -------------------- SAVE METRICS --------------------\n",
    "with open(f\"shalaka_punct_{mode}_indictrans2_eval_metrics.txt\", \"w\") as f:\n",
    "    f.write(f\"All references combined ‚Üí BLEU {bleu_score:.2f}, chrF++ {chrf_score:.2f}, chrF2++: {chrf2_score:.2f}\\n\")\n",
    "    f.write(f\"GT    BLEU {all_scores['GT']:.2f}\\n\")\n",
    "    f.write(f\"Gem   BLEU {all_scores['Gemini']:.2f}\\n\")\n",
    "    f.write(f\"CFILT BLEU {all_scores['CFILT']:.2f}\\n\")\n",
    "    f.write(f\"\\nBEST REFERENCE = {best_ref}\\n\")\n",
    "\n",
    "print(f\"Metrics written to shalaka_punct_{mode}_baseline_outputs_eval_metrics.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3884881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a515e45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32149d9c",
   "metadata": {},
   "source": [
    "## Only Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c07c531",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"thenlpresearcher/iitb-en-indic-only-punct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8578add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng_Latn: Chanting the choir raised the volume as the celebrant intoned the prayer.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§â‡§§‡•ç‡§∏‡§µ ‡§∏‡§æ‡§ú‡§∞‡§æ ‡§ï‡§∞‡§£‡§æ‡§∞\\u093C‡•ç‡§Ø‡§æ‡§®‡•á ‡§™‡•ç‡§∞‡§æ‡§∞‡•ç‡§•‡§®‡§æ ‡§ï‡•á‡§≤‡•Ä ‡§§‡•á‡§µ‡•ç‡§π‡§æ ‡§ó‡§æ‡§Ø‡§ï‡§µ‡•É‡§Ç‡§¶‡§æ‡§ö‡§æ ‡§ú‡§™ ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§®‡•á ‡§Ü‡§µ‡§æ‡§ú ‡§µ‡§æ‡§¢‡§≤‡§æ.\n",
      "eng_Latn: A six-month-old calf was submitted for examination, showing lameness in all four legs which had been present since soon after birth.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§ú‡§®‡•ç‡§Æ‡§æ‡§®‡§Ç‡§§‡§∞ ‡§≤‡§ó‡•á‡§ö‡§ö ‡§Ö‡§∏‡•ç‡§§‡§ø‡§§‡•ç‡§µ‡§æ‡§§ ‡§Ö‡§∏‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§ö‡§æ‡§∞‡§π‡•Ä ‡§™‡§æ‡§Ø‡§æ‡§Ç‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§≤‡§Ç‡§ó‡§°‡•á‡§™‡§£‡§æ ‡§¶‡§ø‡§∏‡•Ç‡§® ‡§Ø‡•á‡§§ ‡§Ö‡§∏‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§∏‡§π‡§æ ‡§Æ‡§π‡§ø‡§®‡•ç‡§Ø‡§æ‡§Ç‡§ö‡•ç‡§Ø‡§æ ‡§µ‡§æ‡§∏‡•Ç‡§≤‡§æ ‡§§‡§™‡§æ‡§∏‡§£‡•Ä‡§∏‡§æ‡§†‡•Ä ‡§∏‡§æ‡§¶‡§∞ ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§§ ‡§Ü‡§≤‡•á.\n",
      "eng_Latn: Planning authorities should provide alternative locations for small businesses which are or would be offensive in a residential area.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§®‡§ø‡§Ø‡•ã‡§ú‡§® ‡§™‡•ç‡§∞‡§æ‡§ß‡§ø‡§ï‡§∞‡§£‡§æ‡§Ç‡§®‡•Ä ‡§®‡§ø‡§µ‡§æ‡§∏‡•Ä ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡§æ‡§§ ‡§Ü‡§ï‡•ç‡§∑‡•á‡§™‡§æ‡§∞‡•ç‡§π ‡§Ö‡§∏‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§ï‡§ø‡§Ç‡§µ‡§æ ‡§Ö‡§∏‡§£‡§æ‡§∞\\u093C‡•ç‡§Ø‡§æ ‡§≤‡§π‡§æ‡§® ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø‡§æ‡§Ç‡§∏‡§æ‡§†‡•Ä ‡§™‡§∞‡•ç‡§Ø‡§æ‡§Ø‡•Ä ‡§†‡§ø‡§ï‡§æ‡§£‡•á ‡§™‡•Å‡§∞‡§µ‡§≤‡•Ä ‡§™‡§æ‡§π‡§ø‡§ú‡•á‡§§.\n",
      "eng_Latn: As the machine develops the forms we use to record data from past projects will be amended.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§ú‡§∏‡§ú‡§∏‡•á ‡§Æ‡§∂‡•Ä‡§® ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§π‡•ã‡§à‡§≤ ‡§§‡§∏‡§§‡§∏‡•á ‡§Ü‡§Æ‡•ç‡§π‡•Ä ‡§Æ‡§æ‡§ó‡•Ä‡§≤ ‡§™‡•ç‡§∞‡§ï‡§≤‡•ç‡§™‡§æ‡§Ç‡§Æ‡§ß‡•Ä‡§≤ ‡§°‡•á‡§ü‡§æ ‡§∞‡•á‡§ï‡•â‡§∞‡•ç‡§° ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§µ‡§æ‡§™‡§∞‡§§ ‡§Ö‡§∏‡§≤‡•á‡§≤‡•á ‡§´‡•â‡§∞‡•ç‡§Æ ‡§∏‡•Å‡§ß‡§æ‡§∞‡§ø‡§§ ‡§ï‡•á‡§≤‡•á ‡§ú‡§æ‡§§‡•Ä‡§≤.\n",
      "eng_Latn: As mentioned, first impressions can be misleading.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§®‡§Æ‡•Ç‡§¶ ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§™‡•ç‡§∞‡§Æ‡§æ‡§£‡•á, ‡§™‡§π‡§ø‡§≤‡•Ä ‡§õ‡§æ‡§™ ‡§≠‡•ç‡§∞‡§æ‡§Æ‡§ï ‡§Ö‡§∏‡•Ç ‡§∂‡§ï‡§§‡•á.\n",
      "eng_Latn: To get a clean assembly load the assembled equals table before the assembly is run.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§è‡§ï ‡§∏‡•ç‡§µ‡§ö‡•ç‡§õ ‡§Ö‡§∏‡•á‡§Ç‡§¨‡•ç‡§≤‡•Ä ‡§≠‡§æ‡§∞ ‡§Æ‡§ø‡§≥‡§µ‡§ø‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§Ö‡§∏‡•á‡§Ç‡§¨‡•ç‡§≤‡•Ä ‡§ö‡§æ‡§≤‡§µ‡§£‡•ç‡§Ø‡§æ‡§™‡•Ç‡§∞‡•ç‡§µ‡•Ä ‡§Ö‡§∏‡•á‡§Ç‡§¨‡§≤ ‡§ï‡•á‡§≤‡•á‡§≤‡•á ‡§ü‡•á‡§¨‡§≤ ‡§∏‡§Æ‡§æ‡§® ‡§ü‡•á‡§¨‡§≤.\n",
      "eng_Latn: Executors delay giving information about substantial deviations from agreed dates. Because of this action cannot be taken in time.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§ï‡•á‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§§‡§æ‡§∞‡§ñ‡§æ‡§Ç‡§™‡§æ‡§∏‡•Ç‡§® ‡§≤‡§ï‡•ç‡§∑‡§£‡•Ä‡§Ø ‡§µ‡§ø‡§ö‡§≤‡§®‡§æ‡§Ç‡§¨‡§¶‡•ç‡§¶‡§≤ ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä ‡§¶‡•á‡§£‡•ç‡§Ø‡§æ‡§∏ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡§æ‡§∞‡•Ä ‡§µ‡§ø‡§≤‡§Ç‡§¨ ‡§ï‡§∞‡§§‡§æ‡§§. ‡§Ø‡§æ‡§Æ‡•Å‡§≥‡•á ‡§µ‡•á‡§≥‡•á‡§µ‡§∞ ‡§ï‡§æ‡§∞‡§µ‡§æ‡§à ‡§ï‡•á‡§≤‡•Ä ‡§ú‡§æ‡§ä ‡§∂‡§ï‡§§ ‡§®‡§æ‡§π‡•Ä.\n",
      "eng_Latn: These glycans are poorly transferred to proteins resulting in unoccupied glycosylation sequons.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§π‡•á ‡§ó‡•ç‡§≤‡§æ‡§Ø‡§ï‡•á‡§®‡•ç‡§∏ ‡§™‡•ç‡§∞‡§•‡§ø‡§®‡§æ‡§Ç‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§ñ‡§∞‡§æ‡§¨‡§∞‡§ø‡§§‡•ç‡§Ø‡§æ ‡§π‡§∏‡•ç‡§§‡§æ‡§Ç‡§§‡§∞‡§ø‡§§ ‡§ï‡•á‡§≤‡•á ‡§ú‡§æ‡§§‡§æ‡§§ ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ‡•Ä ‡§∞‡§ø‡§ï‡•ç‡§§ ‡§ó‡•ç‡§≤‡§æ‡§Ø‡§ï‡•ã‡§∏‡§ø‡§≤‡•á‡§∂‡§® ‡§∏‡§ø‡§ï‡•ç‡§µ‡•á‡§®‡•ç‡§∏ ‡§§‡§Ø‡§æ‡§∞ ‡§π‡•ã‡§§‡§æ‡§§.\n",
      "eng_Latn: X is an effective acute, oral treatment for migraine with a rapid onset of action\n",
      "mar_Deva: mar_Deva eng_Latn ‡§è‡§ï‡•ç‡§∏ ‡§π‡§æ ‡§Æ‡§æ‡§Ø‡§ó‡•ç‡§∞‡•á‡§®‡§∏‡§æ‡§†‡•Ä ‡§è‡§ï ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡•Ä ‡§§‡•Ä‡§µ‡•ç‡§∞, ‡§§‡•ã‡§Ç‡§°‡•Ä ‡§â‡§™‡§ö‡§æ‡§∞ ‡§Ü‡§π‡•á ‡§ú‡•ç‡§Ø‡§æ‡§ö‡•Ä ‡§ï‡•É‡§§‡•Ä ‡§ú‡§≤‡§¶ ‡§ó‡§§‡•Ä‡§®‡•á ‡§∏‡•Å‡§∞‡•Ç ‡§π‡•ã‡§§‡•á.\n",
      "eng_Latn: No newspaper is completely unbiased in my expert opinion.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§Æ‡§æ‡§ù‡•ç‡§Ø‡§æ ‡§§‡§ú‡•ç‡§û‡§æ‡§Ç‡§ö‡•ç‡§Ø‡§æ ‡§Æ‡§§‡•á ‡§ï‡•ã‡§£‡§§‡•á‡§π‡•Ä ‡§µ‡•É‡§§‡•ç‡§§‡§™‡§§‡•ç‡§∞ ‡§™‡•Ç‡§∞‡•ç‡§£‡§™‡§£‡•á ‡§®‡§ø‡§É‡§™‡§ï‡•ç‡§∑‡§™‡§æ‡§§‡•Ä ‡§®‡§æ‡§π‡•Ä.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from IndicTransToolkit.processor import IndicProcessor\n",
    "# recommended to run this on a gpu with flash_attn installed\n",
    "# don't set attn_implemetation if you don't have flash_attn\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE = torch.device(\"cuda:3\")\n",
    "\n",
    "src_lang, tgt_lang = \"eng_Latn\", \"mar_Deva\"\n",
    "tokenizer_name =  \"ai4bharat/indictrans2-en-indic-dist-200M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name, \n",
    "    trust_remote_code=True, \n",
    "    torch_dtype=torch.float16, # performance might slightly vary for bfloat16\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ").to(DEVICE)\n",
    "\n",
    "ip = IndicProcessor(inference=True)\n",
    "\n",
    "input_sentences = src_sentences\n",
    "\n",
    "batch = ip.preprocess_batch(input_sentences, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "\n",
    "# Tokenize the sentences and generate input encodings\n",
    "inputs = tokenizer(\n",
    "    batch,\n",
    "    truncation=True,\n",
    "    padding=\"longest\",\n",
    "    return_tensors=\"pt\",\n",
    "    return_attention_mask=True,\n",
    ").to(DEVICE)\n",
    "\n",
    "# Generate translations using the model\n",
    "with torch.no_grad():\n",
    "    generated_tokens = model.generate(\n",
    "        **inputs,\n",
    "        use_cache=True,\n",
    "        min_length=0,\n",
    "        max_length=256,\n",
    "        num_beams=5,\n",
    "        num_return_sequences=1,\n",
    "    )\n",
    "\n",
    "# Decode the generated tokens into text\n",
    "generated_tokens = tokenizer.batch_decode(\n",
    "    generated_tokens,\n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=True,\n",
    ")\n",
    "\n",
    "# Postprocess the translations, including entity replacement\n",
    "translations = ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
    "\n",
    "for input_sentence, translation in zip(input_sentences[:10], translations[:10]):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f3dde20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§â‡§§‡•ç‡§∏‡§µ ‡§∏‡§æ‡§ú‡§∞‡§æ ‡§ï‡§∞‡§£‡§æ‡§∞\\u093C‡•ç‡§Ø‡§æ‡§®‡•á ‡§™‡•ç‡§∞‡§æ‡§∞‡•ç‡§•‡§®‡§æ ‡§ï‡•á‡§≤‡•Ä ‡§§‡•á‡§µ‡•ç‡§π‡§æ ‡§ó‡§æ‡§Ø‡§ï‡§µ‡•É‡§Ç‡§¶‡§æ‡§ö‡§æ ‡§ú‡§™ ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§®‡•á ‡§Ü‡§µ‡§æ‡§ú ‡§µ‡§æ‡§¢‡§≤‡§æ.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def remove_prefix(translations, prefix):\n",
    "    ans = []\n",
    "    for t in translations:\n",
    "        t = t.strip()\n",
    "        if t.startswith(prefix):\n",
    "            t = t[len(prefix):]\n",
    "        t = re.sub(r'\\.+', '.', t)\n",
    "        ans.append(t)\n",
    "    return ans\n",
    "\n",
    "translations = remove_prefix(translations, \"mar_Deva eng_Latn \")\n",
    "print(translations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80865519",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"only_punct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82a3b674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Saved predictions to shalaka_only_punct_outputs.csv\n",
      "\n",
      "===== FINAL METRICS =====\n",
      "All references combined ‚Üí BLEU: 60.76, chrF++: 80.54, chrF2++: 77.72\n",
      "GT Marathi ‚Üí BLEU: 42.34\n",
      "Gemini    ‚Üí BLEU: 21.21\n",
      "CFILT     ‚Üí BLEU: 49.06\n",
      "\n",
      "üéØ BEST REFERENCE = CFILT (by highest BLEU)\n",
      "Metrics written to shalaka_punct_only_punct_baseline_outputs_eval_metrics.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "\n",
    "# -------------------- SAVE OUTPUTS --------------------\n",
    "results_df = pd.DataFrame({\n",
    "    \"src\": src_sentences,\n",
    "    \"prediction\": translations,\n",
    "    \"gt\": ref_gt,\n",
    "    \"gemini\": ref_gem,\n",
    "    \"cfilt\": ref_cfilt\n",
    "})\n",
    "\n",
    "results_df.to_csv(f\"shalaka_{mode}_outputs.csv\", index=False)\n",
    "print(f\"‚úî Saved predictions to shalaka_{mode}_outputs.csv\")\n",
    "\n",
    "# -------------------- METRICS --------------------\n",
    "bleu = load(\"sacrebleu\")\n",
    "chrf = load(\"chrf\")\n",
    "\n",
    "def compute_scores(preds, ref1, ref2, ref3):\n",
    "    \"\"\"\n",
    "    Compute BLEU and chrF++ scores using all three references for each sentence.\n",
    "    \"\"\"\n",
    "    references = [[r1, r2, r3] for r1, r2, r3 in zip(ref1, ref2, ref3)]  # sacrebleu format\n",
    "    bleu_score = bleu.compute(predictions=preds, references=references)[\"score\"]\n",
    "    chrf_score = chrf.compute(predictions=preds, references=references)[\"score\"]\n",
    "    chrf2_score = chrf.compute(predictions=preds, references=references, char_order=6, word_order=2,  beta=2)[\"score\"]\n",
    "    return bleu_score, chrf_score, chrf2_score\n",
    "\n",
    "bleu_score, chrf_score, chrf2_score = compute_scores(translations, ref_gt, ref_gem, ref_cfilt)\n",
    "\n",
    "# Determine best reference per metric (based on BLEU)\n",
    "all_scores = {\n",
    "    \"GT\":    bleu.compute(predictions=translations, references=[[r] for r in ref_gt])[\"score\"],\n",
    "    \"Gemini\": bleu.compute(predictions=translations, references=[[r] for r in ref_gem])[\"score\"],\n",
    "    \"CFILT\":  bleu.compute(predictions=translations, references=[[r] for r in ref_cfilt])[\"score\"]\n",
    "}\n",
    "\n",
    "best_ref = max(all_scores, key=all_scores.get)\n",
    "\n",
    "print(\"\\n===== FINAL METRICS =====\")\n",
    "print(f\"All references combined ‚Üí BLEU: {bleu_score:.2f}, chrF++: {chrf_score:.2f}, chrF2++: {chrf2_score:.2f}\")\n",
    "print(f\"GT Marathi ‚Üí BLEU: {all_scores['GT']:.2f}\")\n",
    "print(f\"Gemini    ‚Üí BLEU: {all_scores['Gemini']:.2f}\")\n",
    "print(f\"CFILT     ‚Üí BLEU: {all_scores['CFILT']:.2f}\")\n",
    "print(f\"\\nüéØ BEST REFERENCE = {best_ref} (by highest BLEU)\")\n",
    "\n",
    "# -------------------- SAVE METRICS --------------------\n",
    "with open(f\"shalaka_punct_{mode}_indictrans2_eval_metrics.txt\", \"w\") as f:\n",
    "    f.write(f\"All references combined ‚Üí BLEU {bleu_score:.2f}, chrF++ {chrf_score:.2f}, chrF2++: {chrf2_score:.2f}\\n\")\n",
    "    f.write(f\"GT    BLEU {all_scores['GT']:.2f}\\n\")\n",
    "    f.write(f\"Gem   BLEU {all_scores['Gemini']:.2f}\\n\")\n",
    "    f.write(f\"CFILT BLEU {all_scores['CFILT']:.2f}\\n\")\n",
    "    f.write(f\"\\nBEST REFERENCE = {best_ref}\\n\")\n",
    "\n",
    "print(f\"Metrics written to shalaka_punct_{mode}_baseline_outputs_eval_metrics.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600ad2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ca980d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc5d81a9",
   "metadata": {},
   "source": [
    "## Without Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bba6c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"thenlpresearcher/iitb-en-indic-without-punct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb7e30b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng_Latn: Chanting the choir raised the volume as the celebrant intoned the prayer.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§â‡§§‡•ç‡§∏‡§µ ‡§∏‡§æ‡§ú‡§∞‡§æ ‡§ï‡§∞‡§£‡§æ‡§∞\\u093C‡•ç‡§Ø‡§æ‡§®‡•á ‡§™‡•ç‡§∞‡§æ‡§∞‡•ç‡§•‡§®‡•á‡§ö‡§æ ‡§â‡§ö‡•ç‡§ö‡§æ‡§∞ ‡§ï‡§∞‡§§‡§æ‡§ö ‡§ó‡§æ‡§Ø‡§ï‡§µ‡•É‡§Ç‡§¶‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§™‡§†‡§£‡§æ‡§®‡•á ‡§Ü‡§µ‡§æ‡§ú ‡§µ‡§æ‡§¢‡§µ‡§≤‡§æ.\n",
      "eng_Latn: A six-month-old calf was submitted for examination, showing lameness in all four legs which had been present since soon after birth.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§ú‡§®‡•ç‡§Æ‡§æ‡§®‡§Ç‡§§‡§∞ ‡§≤‡§ó‡•á‡§ö‡§ö ‡§Ö‡§∏‡•ç‡§§‡§ø‡§§‡•ç‡§µ‡§æ‡§§ ‡§Ö‡§∏‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§∏‡§∞‡•ç‡§µ ‡§ö‡§æ‡§∞‡§π‡•Ä ‡§™‡§æ‡§Ø‡§æ‡§Ç‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§≤‡§Ç‡§ó‡§°‡•á‡§™‡§£‡§æ ‡§¶‡§∞‡•ç‡§∂‡§µ‡§ø‡§£‡§æ‡§∞‡•Ä ‡§∏‡§π‡§æ ‡§Æ‡§π‡§ø‡§®‡•ç‡§Ø‡§æ‡§Ç‡§ö‡•Ä ‡§è‡§ï ‡§µ‡§æ‡§∏‡§∞ ‡§§‡§™‡§æ‡§∏‡§£‡•Ä‡§∏‡§æ‡§†‡•Ä ‡§∏‡§æ‡§¶‡§∞ ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§§ ‡§Ü‡§≤‡•Ä.\n",
      "eng_Latn: Planning authorities should provide alternative locations for small businesses which are or would be offensive in a residential area.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§®‡§ø‡§Ø‡•ã‡§ú‡§® ‡§™‡•ç‡§∞‡§æ‡§ß‡§ø‡§ï‡§∞‡§£‡§æ‡§Ç‡§®‡•Ä ‡§õ‡•ã‡§ü‡•ç‡§Ø‡§æ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø‡§æ‡§Ç‡§∏‡§æ‡§†‡•Ä ‡§™‡§∞‡•ç‡§Ø‡§æ‡§Ø‡•Ä ‡§†‡§ø‡§ï‡§æ‡§£‡•á ‡§™‡•Å‡§∞‡§µ‡§≤‡•Ä ‡§™‡§æ‡§π‡§ø‡§ú‡•á‡§§ ‡§ú‡•Ä ‡§®‡§ø‡§µ‡§æ‡§∏‡•Ä ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡§æ‡§§ ‡§Ü‡§ï‡•ç‡§∑‡•á‡§™‡§æ‡§∞‡•ç‡§π ‡§Ü‡§π‡•á‡§§ ‡§ï‡§ø‡§Ç‡§µ‡§æ ‡§Ö‡§∏‡§§‡•Ä‡§≤.\n",
      "eng_Latn: As the machine develops the forms we use to record data from past projects will be amended.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§ú‡§∏‡§ú‡§∏‡•á ‡§Æ‡§∂‡•Ä‡§® ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§π‡•ã‡§§‡•á, ‡§§‡§∏‡§§‡§∏‡•á ‡§Ü‡§™‡§£ ‡§Æ‡§æ‡§ó‡•Ä‡§≤ ‡§™‡•ç‡§∞‡§ï‡§≤‡•ç‡§™‡§æ‡§Ç‡§Æ‡§ß‡•Ä‡§≤ ‡§°‡•á‡§ü‡§æ ‡§∞‡•á‡§ï‡•â‡§∞‡•ç‡§° ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§µ‡§æ‡§™‡§∞‡§§ ‡§Ö‡§∏‡§≤‡•á‡§≤‡•á ‡§´‡•â‡§∞‡•ç‡§Æ ‡§∏‡•Å‡§ß‡§æ‡§∞‡§ø‡§§ ‡§ï‡•á‡§≤‡•á ‡§ú‡§æ‡§§‡•Ä‡§≤.\n",
      "eng_Latn: As mentioned, first impressions can be misleading.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§®‡§Æ‡•Ç‡§¶ ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§™‡•ç‡§∞‡§Æ‡§æ‡§£‡•á, ‡§™‡§π‡§ø‡§≤‡•Ä ‡§õ‡§æ‡§™ ‡§≠‡•ç‡§∞‡§æ‡§Æ‡§ï ‡§Ö‡§∏‡•Ç ‡§∂‡§ï‡§§‡•á.\n",
      "eng_Latn: To get a clean assembly load the assembled equals table before the assembly is run.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§è‡§ï ‡§∏‡•ç‡§µ‡§ö‡•ç‡§õ ‡§Ö‡§∏‡•á‡§Ç‡§¨‡•ç‡§≤‡•Ä ‡§≠‡§æ‡§∞ ‡§Æ‡§ø‡§≥‡§µ‡§ø‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä, ‡§Ö‡§∏‡•á‡§Ç‡§¨‡•ç‡§≤‡•Ä ‡§ö‡§æ‡§≤‡§µ‡§£‡•ç‡§Ø‡§æ‡§™‡•Ç‡§∞‡•ç‡§µ‡•Ä ‡§Ö‡§∏‡•á‡§Ç‡§¨‡§≤ ‡§ï‡•á‡§≤‡•á‡§≤‡•á ‡§ü‡•á‡§¨‡§≤ ‡§∏‡§Æ‡§æ‡§® ‡§Ü‡§π‡•á.\n",
      "eng_Latn: Executors delay giving information about substantial deviations from agreed dates. Because of this action cannot be taken in time.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§ï‡•á‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§§‡§æ‡§∞‡§ñ‡§æ‡§Ç‡§™‡§æ‡§∏‡•Ç‡§® ‡§≤‡§ï‡•ç‡§∑‡§£‡•Ä‡§Ø ‡§µ‡§ø‡§ö‡§≤‡§®‡§æ‡§Ç‡§¨‡§¶‡•ç‡§¶‡§≤ ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä ‡§¶‡•á‡§£‡•ç‡§Ø‡§æ‡§∏ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡§æ‡§∞‡•Ä ‡§µ‡§ø‡§≤‡§Ç‡§¨ ‡§ï‡§∞‡§§‡§æ‡§§. ‡§Ø‡§æ‡§Æ‡•Å‡§≥‡•á ‡§µ‡•á‡§≥‡•á‡§µ‡§∞ ‡§ï‡§æ‡§∞‡§µ‡§æ‡§à ‡§ï‡•á‡§≤‡•Ä ‡§ú‡§æ‡§ä ‡§∂‡§ï‡§§ ‡§®‡§æ‡§π‡•Ä.\n",
      "eng_Latn: These glycans are poorly transferred to proteins resulting in unoccupied glycosylation sequons.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§π‡•á ‡§ó‡•ç‡§≤‡§æ‡§Ø‡§ï‡§®‡•ç‡§∏ ‡§™‡•ç‡§∞‡§•‡§ø‡§®‡§æ‡§Ç‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§ñ‡§∞‡§æ‡§¨‡§∞‡§ø‡§§‡•ç‡§Ø‡§æ ‡§π‡§∏‡•ç‡§§‡§æ‡§Ç‡§§‡§∞‡§ø‡§§ ‡§ï‡•á‡§≤‡•á ‡§ú‡§æ‡§§‡§æ‡§§, ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ‡•Ä ‡§∞‡§ø‡§ï‡•ç‡§§ ‡§ó‡•ç‡§≤‡§æ‡§Ø‡§ï‡•ã‡§∏‡§ø‡§≤‡•á‡§∂‡§® ‡§∏‡§ø‡§ï‡•ç‡§µ‡•á‡§®‡•ç‡§∏ ‡§§‡§Ø‡§æ‡§∞ ‡§π‡•ã‡§§‡§æ‡§§.\n",
      "eng_Latn: X is an effective acute, oral treatment for migraine with a rapid onset of action\n",
      "mar_Deva: mar_Deva eng_Latn ‡§è‡§ï‡•ç‡§∏ ‡§π‡§æ ‡§Æ‡§æ‡§Ø‡§ó‡•ç‡§∞‡•á‡§®‡§∏‡§æ‡§†‡•Ä ‡§è‡§ï ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡•Ä, ‡§§‡•Ä‡§µ‡•ç‡§∞, ‡§§‡•ã‡§Ç‡§°‡•Ä ‡§â‡§™‡§ö‡§æ‡§∞ ‡§Ü‡§π‡•á, ‡§ú‡•ç‡§Ø‡§æ‡§ö‡•Ä ‡§ï‡•É‡§§‡•Ä ‡§ú‡§≤‡§¶ ‡§∏‡•Å‡§∞‡•Ç ‡§π‡•ã‡§§‡•á.\n",
      "eng_Latn: No newspaper is completely unbiased in my expert opinion.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§Æ‡§æ‡§ù‡•ç‡§Ø‡§æ ‡§§‡§ú‡•ç‡§û‡§æ‡§Ç‡§ö‡•ç‡§Ø‡§æ ‡§Æ‡§§‡•á ‡§ï‡•ã‡§£‡§§‡•á‡§π‡•Ä ‡§µ‡•É‡§§‡•ç‡§§‡§™‡§§‡•ç‡§∞ ‡§™‡•Ç‡§∞‡•ç‡§£‡§™‡§£‡•á ‡§®‡§ø‡§É‡§™‡§ï‡•ç‡§∑‡§™‡§æ‡§§‡•Ä ‡§®‡§æ‡§π‡•Ä.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from IndicTransToolkit.processor import IndicProcessor\n",
    "# recommended to run this on a gpu with flash_attn installed\n",
    "# don't set attn_implemetation if you don't have flash_attn\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE = torch.device(\"cuda:3\")\n",
    "\n",
    "src_lang, tgt_lang = \"eng_Latn\", \"mar_Deva\"\n",
    "tokenizer_name =  \"ai4bharat/indictrans2-en-indic-dist-200M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name, \n",
    "    trust_remote_code=True, \n",
    "    torch_dtype=torch.float16, # performance might slightly vary for bfloat16\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ").to(DEVICE)\n",
    "\n",
    "ip = IndicProcessor(inference=True)\n",
    "\n",
    "input_sentences = src_sentences\n",
    "\n",
    "batch = ip.preprocess_batch(input_sentences, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "\n",
    "# Tokenize the sentences and generate input encodings\n",
    "inputs = tokenizer(\n",
    "    batch,\n",
    "    truncation=True,\n",
    "    padding=\"longest\",\n",
    "    return_tensors=\"pt\",\n",
    "    return_attention_mask=True,\n",
    ").to(DEVICE)\n",
    "\n",
    "# Generate translations using the model\n",
    "with torch.no_grad():\n",
    "    generated_tokens = model.generate(\n",
    "        **inputs,\n",
    "        use_cache=True,\n",
    "        min_length=0,\n",
    "        max_length=256,\n",
    "        num_beams=5,\n",
    "        num_return_sequences=1,\n",
    "    )\n",
    "\n",
    "# Decode the generated tokens into text\n",
    "generated_tokens = tokenizer.batch_decode(\n",
    "    generated_tokens,\n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=True,\n",
    ")\n",
    "\n",
    "# Postprocess the translations, including entity replacement\n",
    "translations = ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
    "\n",
    "for input_sentence, translation in zip(input_sentences[:10], translations[:10]):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bfaaad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§â‡§§‡•ç‡§∏‡§µ ‡§∏‡§æ‡§ú‡§∞‡§æ ‡§ï‡§∞‡§£‡§æ‡§∞\\u093C‡•ç‡§Ø‡§æ‡§®‡•á ‡§™‡•ç‡§∞‡§æ‡§∞‡•ç‡§•‡§®‡•á‡§ö‡§æ ‡§â‡§ö‡•ç‡§ö‡§æ‡§∞ ‡§ï‡§∞‡§§‡§æ‡§ö ‡§ó‡§æ‡§Ø‡§ï‡§µ‡•É‡§Ç‡§¶‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§™‡§†‡§£‡§æ‡§®‡•á ‡§Ü‡§µ‡§æ‡§ú ‡§µ‡§æ‡§¢‡§µ‡§≤‡§æ.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def remove_prefix(translations, prefix):\n",
    "    ans = []\n",
    "    for t in translations:\n",
    "        t = t.strip()\n",
    "        if t.startswith(prefix):\n",
    "            t = t[len(prefix):]\n",
    "        t = re.sub(r'\\.+', '.', t)\n",
    "        ans.append(t)\n",
    "    return ans\n",
    "\n",
    "translations = remove_prefix(translations, \"mar_Deva eng_Latn \")\n",
    "print(translations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cfd355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"without_punct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7db3d8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Saved predictions to shalaka_without_punct_outputs.csv\n",
      "\n",
      "===== FINAL METRICS =====\n",
      "All references combined ‚Üí BLEU: 63.10, chrF++: 80.97, chrF2++: 78.39\n",
      "GT Marathi ‚Üí BLEU: 43.28\n",
      "Gemini    ‚Üí BLEU: 24.66\n",
      "CFILT     ‚Üí BLEU: 51.86\n",
      "\n",
      "üéØ BEST REFERENCE = CFILT (by highest BLEU)\n",
      "Metrics written to shalaka_punct_without_punct_baseline_outputs_eval_metrics.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "\n",
    "# -------------------- SAVE OUTPUTS --------------------\n",
    "results_df = pd.DataFrame({\n",
    "    \"src\": src_sentences,\n",
    "    \"prediction\": translations,\n",
    "    \"gt\": ref_gt,\n",
    "    \"gemini\": ref_gem,\n",
    "    \"cfilt\": ref_cfilt\n",
    "})\n",
    "\n",
    "results_df.to_csv(f\"shalaka_{mode}_outputs.csv\", index=False)\n",
    "print(f\"‚úî Saved predictions to shalaka_{mode}_outputs.csv\")\n",
    "\n",
    "# -------------------- METRICS --------------------\n",
    "bleu = load(\"sacrebleu\")\n",
    "chrf = load(\"chrf\")\n",
    "\n",
    "def compute_scores(preds, ref1, ref2, ref3):\n",
    "    \"\"\"\n",
    "    Compute BLEU and chrF++ scores using all three references for each sentence.\n",
    "    \"\"\"\n",
    "    references = [[r1, r2, r3] for r1, r2, r3 in zip(ref1, ref2, ref3)]  # sacrebleu format\n",
    "    bleu_score = bleu.compute(predictions=preds, references=references)[\"score\"]\n",
    "    chrf_score = chrf.compute(predictions=preds, references=references)[\"score\"]\n",
    "    chrf2_score = chrf.compute(predictions=preds, references=references, char_order=6, word_order=2,  beta=2)[\"score\"]\n",
    "    return bleu_score, chrf_score, chrf2_score\n",
    "\n",
    "bleu_score, chrf_score, chrf2_score = compute_scores(translations, ref_gt, ref_gem, ref_cfilt)\n",
    "\n",
    "# Determine best reference per metric (based on BLEU)\n",
    "all_scores = {\n",
    "    \"GT\":    bleu.compute(predictions=translations, references=[[r] for r in ref_gt])[\"score\"],\n",
    "    \"Gemini\": bleu.compute(predictions=translations, references=[[r] for r in ref_gem])[\"score\"],\n",
    "    \"CFILT\":  bleu.compute(predictions=translations, references=[[r] for r in ref_cfilt])[\"score\"]\n",
    "}\n",
    "\n",
    "best_ref = max(all_scores, key=all_scores.get)\n",
    "\n",
    "print(\"\\n===== FINAL METRICS =====\")\n",
    "print(f\"All references combined ‚Üí BLEU: {bleu_score:.2f}, chrF++: {chrf_score:.2f}, chrF2++: {chrf2_score:.2f}\")\n",
    "print(f\"GT Marathi ‚Üí BLEU: {all_scores['GT']:.2f}\")\n",
    "print(f\"Gemini    ‚Üí BLEU: {all_scores['Gemini']:.2f}\")\n",
    "print(f\"CFILT     ‚Üí BLEU: {all_scores['CFILT']:.2f}\")\n",
    "print(f\"\\nüéØ BEST REFERENCE = {best_ref} (by highest BLEU)\")\n",
    "\n",
    "# -------------------- SAVE METRICS --------------------\n",
    "with open(f\"shalaka_punct_{mode}_indictrans2_eval_metrics.txt\", \"w\") as f:\n",
    "    f.write(f\"All references combined ‚Üí BLEU {bleu_score:.2f}, chrF++ {chrf_score:.2f}, chrF2++: {chrf2_score:.2f}\\n\")\n",
    "    f.write(f\"GT    BLEU {all_scores['GT']:.2f}\\n\")\n",
    "    f.write(f\"Gem   BLEU {all_scores['Gemini']:.2f}\\n\")\n",
    "    f.write(f\"CFILT BLEU {all_scores['CFILT']:.2f}\\n\")\n",
    "    f.write(f\"\\nBEST REFERENCE = {best_ref}\\n\")\n",
    "\n",
    "print(f\"Metrics written to shalaka_punct_{mode}_baseline_outputs_eval_metrics.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1860ab69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b16e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5cc7c83",
   "metadata": {},
   "source": [
    "## Combined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a62a1791",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = combined_punct_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "516191aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng_Latn: Chanting the choir raised the volume as the celebrant intoned the prayer.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§â‡§§‡•ç‡§∏‡§µ ‡§∏‡§æ‡§ú‡§∞‡§æ ‡§ï‡§∞‡§£‡§æ‡§∞\\u093C‡•ç‡§Ø‡§æ‡§®‡•á ‡§™‡•ç‡§∞‡§æ‡§∞‡•ç‡§•‡§®‡•á‡§ö‡§æ ‡§∏‡•Ç‡§∞ ‡§µ‡§æ‡§ú‡§µ‡§≤‡•ç‡§Ø‡§æ‡§Æ‡•Å‡§≥‡•á ‡§ó‡§æ‡§Ø‡§ï‡§µ‡•É‡§Ç‡§¶‡§æ‡§ö‡§æ ‡§ú‡§™ ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§®‡•á ‡§Ü‡§µ‡§æ‡§ú ‡§µ‡§æ‡§¢‡§≤‡§æ.\n",
      "eng_Latn: A six-month-old calf was submitted for examination, showing lameness in all four legs which had been present since soon after birth.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§ú‡§®‡•ç‡§Æ‡§æ‡§®‡§Ç‡§§‡§∞ ‡§≤‡§ó‡•á‡§ö‡§ö ‡§Ö‡§∏‡•ç‡§§‡§ø‡§§‡•ç‡§µ‡§æ‡§§ ‡§Ö‡§∏‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§ö‡§æ‡§∞‡§π‡•Ä ‡§™‡§æ‡§Ø‡§æ‡§Ç‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§≤‡§Ç‡§ó‡§°‡•á‡§™‡§£‡§æ ‡§¶‡§∞‡•ç‡§∂‡§µ‡§ø‡§£‡§æ‡§∞‡§æ ‡§∏‡§π‡§æ ‡§Æ‡§π‡§ø‡§®‡•ç‡§Ø‡§æ‡§Ç‡§ö‡§æ ‡§è‡§ï ‡§µ‡§æ‡§∏‡§∞ ‡§§‡§™‡§æ‡§∏‡§£‡•Ä‡§∏‡§æ‡§†‡•Ä ‡§∏‡§æ‡§¶‡§∞ ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§§ ‡§Ü‡§≤‡§æ.\n",
      "eng_Latn: Planning authorities should provide alternative locations for small businesses which are or would be offensive in a residential area.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§®‡§ø‡§Ø‡•ã‡§ú‡§® ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞\\u093C‡•ç‡§Ø‡§æ‡§Ç‡§®‡•Ä ‡§õ‡•ã‡§ü‡•ç‡§Ø‡§æ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø‡§æ‡§Ç‡§∏‡§æ‡§†‡•Ä ‡§™‡§∞‡•ç‡§Ø‡§æ‡§Ø‡•Ä ‡§†‡§ø‡§ï‡§æ‡§£‡•á ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡•á‡§≤‡•Ä ‡§™‡§æ‡§π‡§ø‡§ú‡•á‡§§ ‡§ú‡•Ä ‡§®‡§ø‡§µ‡§æ‡§∏‡•Ä ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡§æ‡§§ ‡§Ü‡§ï‡•ç‡§∑‡•á‡§™‡§æ‡§∞‡•ç‡§π ‡§Ü‡§π‡•á‡§§ ‡§ï‡§ø‡§Ç‡§µ‡§æ ‡§Ö‡§∏‡§§‡•Ä‡§≤.\n",
      "eng_Latn: As the machine develops the forms we use to record data from past projects will be amended.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§ú‡§∏‡§ú‡§∏‡•á ‡§Æ‡§∂‡•Ä‡§® ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§π‡•ã‡§à‡§≤ ‡§§‡§∏‡§§‡§∏‡•á ‡§Ü‡§™‡§£ ‡§Æ‡§æ‡§ó‡•Ä‡§≤ ‡§™‡•ç‡§∞‡§ï‡§≤‡•ç‡§™‡§æ‡§Ç‡§Æ‡§ß‡•Ä‡§≤ ‡§°‡•á‡§ü‡§æ ‡§∞‡•á‡§ï‡•â‡§∞‡•ç‡§° ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§µ‡§æ‡§™‡§∞‡§§ ‡§Ö‡§∏‡§≤‡•á‡§≤‡•á ‡§´‡•â‡§∞‡•ç‡§Æ ‡§∏‡•Å‡§ß‡§æ‡§∞‡§ø‡§§ ‡§ï‡•á‡§≤‡•á ‡§ú‡§æ‡§§‡•Ä‡§≤.\n",
      "eng_Latn: As mentioned, first impressions can be misleading.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§®‡§Æ‡•Ç‡§¶ ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§™‡•ç‡§∞‡§Æ‡§æ‡§£‡•á, ‡§™‡§π‡§ø‡§≤‡•Ä ‡§õ‡§æ‡§™ ‡§¶‡§ø‡§∂‡§æ‡§≠‡•Ç‡§≤ ‡§ï‡§∞‡§£‡§æ‡§∞‡•Ä ‡§Ö‡§∏‡•Ç ‡§∂‡§ï‡§§‡•á.\n",
      "eng_Latn: To get a clean assembly load the assembled equals table before the assembly is run.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§∏‡•ç‡§µ‡§ö‡•ç‡§õ ‡§Ö‡§∏‡•á‡§Ç‡§¨‡•ç‡§≤‡•Ä ‡§≤‡•ã‡§° ‡§Æ‡§ø‡§≥‡§µ‡§ø‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§Ö‡§∏‡•á‡§Ç‡§¨‡•ç‡§≤‡•Ä ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§ø‡§§ ‡§π‡•ã‡§£‡•ç‡§Ø‡§æ‡§™‡•Ç‡§∞‡•ç‡§µ‡•Ä ‡§Ö‡§∏‡•á‡§Ç‡§¨‡§≤ ‡§ï‡•á‡§≤‡•á‡§≤‡•á ‡§∏‡§Æ‡§æ‡§® ‡§ü‡•á‡§¨‡§≤.\n",
      "eng_Latn: Executors delay giving information about substantial deviations from agreed dates. Because of this action cannot be taken in time.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡§æ‡§∞‡•Ä ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§ï‡•á‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§§‡§æ‡§∞‡§ñ‡§æ‡§Ç‡§™‡§æ‡§∏‡•Ç‡§® ‡§≤‡§ï‡•ç‡§∑‡§£‡•Ä‡§Ø ‡§µ‡§ø‡§ö‡§≤‡§®‡§æ‡§Ç‡§¨‡§¶‡•ç‡§¶‡§≤ ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä ‡§¶‡•á‡§£‡•ç‡§Ø‡§æ‡§∏ ‡§µ‡§ø‡§≤‡§Ç‡§¨ ‡§ï‡§∞‡§§‡§æ‡§§. ‡§Ø‡§æ ‡§ï‡§æ‡§∞‡§£‡§æ‡§∏‡•ç‡§§‡§µ ‡§ï‡§æ‡§∞‡§µ‡§æ‡§à ‡§µ‡•á‡§≥‡•á‡§§ ‡§ï‡•á‡§≤‡•Ä ‡§ú‡§æ‡§ä ‡§∂‡§ï‡§§ ‡§®‡§æ‡§π‡•Ä.\n",
      "eng_Latn: These glycans are poorly transferred to proteins resulting in unoccupied glycosylation sequons.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§π‡•á ‡§ó‡•ç‡§≤‡§æ‡§Ø‡§ï‡•á‡§®‡•ç‡§∏ ‡§™‡•ç‡§∞‡§•‡§ø‡§®‡§æ‡§Ç‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§ñ‡§∞‡§æ‡§¨ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞‡•á ‡§π‡§∏‡•ç‡§§‡§æ‡§Ç‡§§‡§∞‡§ø‡§§ ‡§ï‡•á‡§≤‡•á ‡§ú‡§æ‡§§‡§æ‡§§, ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ‡•Ä ‡§∞‡§ø‡§ï‡•ç‡§§ ‡§ó‡•ç‡§≤‡§æ‡§Ø‡§ï‡•ã‡§∏‡§ø‡§≤‡•á‡§∂‡§® ‡§∏‡•Ä‡§ï‡•ç‡§µ‡§æ‡§Ç‡§∏ ‡§§‡§Ø‡§æ‡§∞ ‡§π‡•ã‡§§‡§æ‡§§.\n",
      "eng_Latn: X is an effective acute, oral treatment for migraine with a rapid onset of action\n",
      "mar_Deva: mar_Deva eng_Latn ‡§è‡§ï‡•ç‡§∏ ‡§π‡§æ ‡§Ö‡§∞‡•ç‡§ß‡§∂‡§ø‡§∂‡•Ä‡§∏‡§æ‡§†‡•Ä ‡§è‡§ï ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡•Ä ‡§§‡•Ä‡§µ‡•ç‡§∞, ‡§§‡•ã‡§Ç‡§°‡•Ä ‡§â‡§™‡§ö‡§æ‡§∞ ‡§Ü‡§π‡•á, ‡§ú‡•ç‡§Ø‡§æ‡§ö‡•Ä ‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§ú‡§≤‡§¶ ‡§∏‡•Å‡§∞‡•Ç ‡§π‡•ã‡§§‡•á.\n",
      "eng_Latn: No newspaper is completely unbiased in my expert opinion.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§Æ‡§æ‡§ù‡•ç‡§Ø‡§æ ‡§§‡§ú‡•ç‡§û‡§æ‡§Ç‡§ö‡•ç‡§Ø‡§æ ‡§Æ‡§§‡•á ‡§ï‡•ã‡§£‡§§‡•á‡§π‡•Ä ‡§µ‡•É‡§§‡•ç‡§§‡§™‡§§‡•ç‡§∞ ‡§™‡•Ç‡§∞‡•ç‡§£‡§™‡§£‡•á ‡§®‡§ø‡§É‡§™‡§ï‡•ç‡§∑‡§™‡§æ‡§§‡•Ä ‡§®‡§æ‡§π‡•Ä.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from IndicTransToolkit.processor import IndicProcessor\n",
    "# recommended to run this on a gpu with flash_attn installed\n",
    "# don't set attn_implemetation if you don't have flash_attn\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE = torch.device(\"cuda:3\")\n",
    "\n",
    "src_lang, tgt_lang = \"eng_Latn\", \"mar_Deva\"\n",
    "tokenizer_name =  \"ai4bharat/indictrans2-en-indic-dist-200M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name, \n",
    "    trust_remote_code=True, \n",
    "    torch_dtype=torch.float16, # performance might slightly vary for bfloat16\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ").to(DEVICE)\n",
    "\n",
    "ip = IndicProcessor(inference=True)\n",
    "\n",
    "input_sentences = src_sentences\n",
    "\n",
    "batch = ip.preprocess_batch(input_sentences, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "\n",
    "# Tokenize the sentences and generate input encodings\n",
    "inputs = tokenizer(\n",
    "    batch,\n",
    "    truncation=True,\n",
    "    padding=\"longest\",\n",
    "    return_tensors=\"pt\",\n",
    "    return_attention_mask=True,\n",
    ").to(DEVICE)\n",
    "\n",
    "# Generate translations using the model\n",
    "with torch.no_grad():\n",
    "    generated_tokens = model.generate(\n",
    "        **inputs,\n",
    "        use_cache=True,\n",
    "        min_length=0,\n",
    "        max_length=256,\n",
    "        num_beams=5,\n",
    "        num_return_sequences=1,\n",
    "    )\n",
    "\n",
    "# Decode the generated tokens into text\n",
    "generated_tokens = tokenizer.batch_decode(\n",
    "    generated_tokens,\n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=True,\n",
    ")\n",
    "\n",
    "# Postprocess the translations, including entity replacement\n",
    "translations = ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
    "\n",
    "for input_sentence, translation in zip(input_sentences[:10], translations[:10]):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94fb5bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§â‡§§‡•ç‡§∏‡§µ ‡§∏‡§æ‡§ú‡§∞‡§æ ‡§ï‡§∞‡§£‡§æ‡§∞\\u093C‡•ç‡§Ø‡§æ‡§®‡•á ‡§™‡•ç‡§∞‡§æ‡§∞‡•ç‡§•‡§®‡•á‡§ö‡§æ ‡§∏‡•Ç‡§∞ ‡§µ‡§æ‡§ú‡§µ‡§≤‡•ç‡§Ø‡§æ‡§Æ‡•Å‡§≥‡•á ‡§ó‡§æ‡§Ø‡§ï‡§µ‡•É‡§Ç‡§¶‡§æ‡§ö‡§æ ‡§ú‡§™ ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§®‡•á ‡§Ü‡§µ‡§æ‡§ú ‡§µ‡§æ‡§¢‡§≤‡§æ.\n"
     ]
    }
   ],
   "source": [
    "def remove_prefix(translations, prefix):\n",
    "    ans = []\n",
    "    for t in translations:\n",
    "        t = t.strip()\n",
    "        if t.startswith(prefix):\n",
    "            t = t[len(prefix):]\n",
    "        ans.append(t)\n",
    "    return ans\n",
    "\n",
    "translations = remove_prefix(translations, \"mar_Deva eng_Latn \")\n",
    "print(translations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05954cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"combined\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d77cfcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Saved predictions to shalaka_combined_outputs.csv\n",
      "\n",
      "===== FINAL METRICS =====\n",
      "All references combined ‚Üí BLEU: 64.73, chrF++: 81.78, chrF2++: 79.09\n",
      "GT Marathi ‚Üí BLEU: 43.30\n",
      "Gemini    ‚Üí BLEU: 25.18\n",
      "CFILT     ‚Üí BLEU: 54.13\n",
      "\n",
      "üéØ BEST REFERENCE = CFILT (by highest BLEU)\n",
      "Metrics written to shalaka_punct_combined_indictrans2_eval_metrics.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "\n",
    "# -------------------- SAVE OUTPUTS --------------------\n",
    "results_df = pd.DataFrame({\n",
    "    \"src\": src_sentences,\n",
    "    \"prediction\": translations,\n",
    "    \"gt\": ref_gt,\n",
    "    \"gemini\": ref_gem,\n",
    "    \"cfilt\": ref_cfilt\n",
    "})\n",
    "\n",
    "results_df.to_csv(f\"shalaka_{mode}_outputs.csv\", index=False)\n",
    "print(f\"‚úî Saved predictions to shalaka_{mode}_outputs.csv\")\n",
    "\n",
    "# -------------------- METRICS --------------------\n",
    "bleu = load(\"sacrebleu\")\n",
    "chrf = load(\"chrf\")\n",
    "\n",
    "def compute_scores(preds, ref1, ref2, ref3):\n",
    "    \"\"\"\n",
    "    Compute BLEU and chrF++ scores using all three references for each sentence.\n",
    "    \"\"\"\n",
    "    references = [[r1, r2, r3] for r1, r2, r3 in zip(ref1, ref2, ref3)]  # sacrebleu format\n",
    "    bleu_score = bleu.compute(predictions=preds, references=references)[\"score\"]\n",
    "    chrf_score = chrf.compute(predictions=preds, references=references)[\"score\"]\n",
    "    chrf2_score = chrf.compute(predictions=preds, references=references, char_order=6, word_order=2,  beta=2)[\"score\"]\n",
    "    return bleu_score, chrf_score, chrf2_score\n",
    "\n",
    "bleu_score, chrf_score, chrf2_score = compute_scores(translations, ref_gt, ref_gem, ref_cfilt)\n",
    "\n",
    "# Determine best reference per metric (based on BLEU)\n",
    "all_scores = {\n",
    "    \"GT\":    bleu.compute(predictions=translations, references=[[r] for r in ref_gt])[\"score\"],\n",
    "    \"Gemini\": bleu.compute(predictions=translations, references=[[r] for r in ref_gem])[\"score\"],\n",
    "    \"CFILT\":  bleu.compute(predictions=translations, references=[[r] for r in ref_cfilt])[\"score\"]\n",
    "}\n",
    "\n",
    "best_ref = max(all_scores, key=all_scores.get)\n",
    "\n",
    "print(\"\\n===== FINAL METRICS =====\")\n",
    "print(f\"All references combined ‚Üí BLEU: {bleu_score:.2f}, chrF++: {chrf_score:.2f}, chrF2++: {chrf2_score:.2f}\")\n",
    "print(f\"GT Marathi ‚Üí BLEU: {all_scores['GT']:.2f}\")\n",
    "print(f\"Gemini    ‚Üí BLEU: {all_scores['Gemini']:.2f}\")\n",
    "print(f\"CFILT     ‚Üí BLEU: {all_scores['CFILT']:.2f}\")\n",
    "print(f\"\\nüéØ BEST REFERENCE = {best_ref} (by highest BLEU)\")\n",
    "\n",
    "# -------------------- SAVE METRICS --------------------\n",
    "with open(f\"shalaka_punct_{mode}_indictrans2_eval_metrics.txt\", \"w\") as f:\n",
    "    f.write(f\"All references combined ‚Üí BLEU {bleu_score:.2f}, chrF++ {chrf_score:.2f}, chrF2++: {chrf2_score:.2f}\\n\")\n",
    "    f.write(f\"GT    BLEU {all_scores['GT']:.2f}\\n\")\n",
    "    f.write(f\"Gem   BLEU {all_scores['Gemini']:.2f}\\n\")\n",
    "    f.write(f\"CFILT BLEU {all_scores['CFILT']:.2f}\\n\")\n",
    "    f.write(f\"\\nBEST REFERENCE = {best_ref}\\n\")\n",
    "\n",
    "print(f\"Metrics written to shalaka_punct_{mode}_indictrans2_eval_metrics.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c4e510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a64fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76967d2c",
   "metadata": {},
   "source": [
    "## Combined Model - Shalaka LR=5e-6 & Epochs=3 Changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e6d9024",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = combined_punct_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2af10846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng_Latn: Chanting the choir raised the volume as the celebrant intoned the prayer.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§â‡§§‡•ç‡§∏‡§µ ‡§∏‡§æ‡§ú‡§∞‡§æ ‡§ï‡§∞‡§£‡§æ‡§∞\\u093C‡•ç‡§Ø‡§æ‡§®‡•á ‡§™‡•ç‡§∞‡§æ‡§∞‡•ç‡§•‡§®‡•á‡§ö‡§æ ‡§â‡§ö‡•ç‡§ö‡§æ‡§∞ ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§Æ‡•Å‡§≥‡•á ‡§ó‡§æ‡§Ø‡§ï‡§µ‡•É‡§Ç‡§¶‡§æ‡§®‡•á ‡§ú‡§™ ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§®‡•á ‡§Ü‡§µ‡§æ‡§ú ‡§µ‡§æ‡§¢‡§≤‡§æ.\n",
      "eng_Latn: A six-month-old calf was submitted for examination, showing lameness in all four legs which had been present since soon after birth.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§ú‡§®‡•ç‡§Æ‡§æ‡§®‡§Ç‡§§‡§∞ ‡§≤‡§ó‡•á‡§ö‡§ö ‡§Ö‡§∏‡•ç‡§§‡§ø‡§§‡•ç‡§µ‡§æ‡§§ ‡§Ö‡§∏‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§ö‡§æ‡§∞‡§π‡•Ä ‡§™‡§æ‡§Ø‡§æ‡§Ç‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§≤‡§Ç‡§ó‡§°‡•á‡§™‡§£‡§æ ‡§¶‡§∞‡•ç‡§∂‡§µ‡§ø‡§£‡§æ‡§∞‡§æ ‡§∏‡§π‡§æ ‡§Æ‡§π‡§ø‡§®‡•ç‡§Ø‡§æ‡§Ç‡§ö‡§æ ‡§µ‡§æ‡§∏‡§∞ ‡§§‡§™‡§æ‡§∏‡§£‡•Ä‡§∏‡§æ‡§†‡•Ä ‡§∏‡§æ‡§¶‡§∞ ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§§ ‡§Ü‡§≤‡§æ.\n",
      "eng_Latn: Planning authorities should provide alternative locations for small businesses which are or would be offensive in a residential area.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§®‡§ø‡§Ø‡•ã‡§ú‡§® ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞\\u093C‡•ç‡§Ø‡§æ‡§Ç‡§®‡•Ä ‡§õ‡•ã‡§ü‡•ç‡§Ø‡§æ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø‡§æ‡§Ç‡§∏‡§æ‡§†‡•Ä ‡§™‡§∞‡•ç‡§Ø‡§æ‡§Ø‡•Ä ‡§†‡§ø‡§ï‡§æ‡§£‡•á ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡•á‡§≤‡•Ä ‡§™‡§æ‡§π‡§ø‡§ú‡•á‡§§ ‡§ú‡•Ä ‡§®‡§ø‡§µ‡§æ‡§∏‡•Ä ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡§æ‡§§ ‡§Ü‡§ï‡•ç‡§∑‡•á‡§™‡§æ‡§∞‡•ç‡§π ‡§Ü‡§π‡•á‡§§ ‡§ï‡§ø‡§Ç‡§µ‡§æ ‡§Ö‡§∏‡§§‡•Ä‡§≤.\n",
      "eng_Latn: As the machine develops the forms we use to record data from past projects will be amended.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§ú‡§∏‡§ú‡§∏‡•á ‡§Æ‡§∂‡•Ä‡§® ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§π‡•ã‡§à‡§≤ ‡§§‡§∏‡§§‡§∏‡•á ‡§Æ‡§æ‡§ó‡•Ä‡§≤ ‡§™‡•ç‡§∞‡§ï‡§≤‡•ç‡§™‡§æ‡§Ç‡§Æ‡§ß‡•Ä‡§≤ ‡§°‡•á‡§ü‡§æ ‡§∞‡•á‡§ï‡•â‡§∞‡•ç‡§° ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§Ü‡§™‡§£ ‡§µ‡§æ‡§™‡§∞‡§§ ‡§Ö‡§∏‡§≤‡•á‡§≤‡•á ‡§´‡•â‡§∞‡•ç‡§Æ ‡§∏‡•Å‡§ß‡§æ‡§∞‡§ø‡§§ ‡§ï‡•á‡§≤‡•á ‡§ú‡§æ‡§§‡•Ä‡§≤.\n",
      "eng_Latn: As mentioned, first impressions can be misleading.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§®‡§Æ‡•Ç‡§¶ ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§™‡•ç‡§∞‡§Æ‡§æ‡§£‡•á, ‡§™‡§π‡§ø‡§≤‡•Ä ‡§õ‡§æ‡§™ ‡§¶‡§ø‡§∂‡§æ‡§≠‡•Ç‡§≤ ‡§ï‡§∞‡§£‡§æ‡§∞‡•Ä ‡§Ö‡§∏‡•Ç ‡§∂‡§ï‡§§‡•á.\n",
      "eng_Latn: To get a clean assembly load the assembled equals table before the assembly is run.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§∏‡•ç‡§µ‡§ö‡•ç‡§õ ‡§Ö‡§∏‡•á‡§Ç‡§¨‡•ç‡§≤‡•Ä ‡§≤‡•ã‡§° ‡§Æ‡§ø‡§≥‡§µ‡§ø‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§Ö‡§∏‡•á‡§Ç‡§¨‡•ç‡§≤‡•Ä ‡§ö‡§æ‡§≤‡§µ‡§£‡•ç‡§Ø‡§æ‡§™‡•Ç‡§∞‡•ç‡§µ‡•Ä ‡§Ö‡§∏‡•á‡§Ç‡§¨‡§≤ ‡§ï‡•á‡§≤‡•á‡§≤‡•á ‡§∏‡§Æ‡§æ‡§® ‡§ü‡•á‡§¨‡§≤.\n",
      "eng_Latn: Executors delay giving information about substantial deviations from agreed dates. Because of this action cannot be taken in time.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§ï‡•á‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§§‡§æ‡§∞‡§ñ‡§æ‡§Ç‡§™‡§æ‡§∏‡•Ç‡§® ‡§≤‡§ï‡•ç‡§∑‡§£‡•Ä‡§Ø ‡§µ‡§ø‡§ö‡§≤‡§®‡§æ‡§Ç‡§ö‡•Ä ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä ‡§¶‡•á‡§£‡•ç‡§Ø‡§æ‡§∏ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡§æ‡§∞‡•Ä ‡§µ‡§ø‡§≤‡§Ç‡§¨ ‡§ï‡§∞‡§§‡§æ‡§§. ‡§Ø‡§æ‡§Æ‡•Å‡§≥‡•á ‡§ï‡§æ‡§∞‡§µ‡§æ‡§à ‡§µ‡•á‡§≥‡•á‡§§ ‡§ï‡•á‡§≤‡•Ä ‡§ú‡§æ‡§ä ‡§∂‡§ï‡§§ ‡§®‡§æ‡§π‡•Ä.\n",
      "eng_Latn: These glycans are poorly transferred to proteins resulting in unoccupied glycosylation sequons.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§π‡•á ‡§ó‡•ç‡§≤‡§æ‡§Ø‡§ï‡•á‡§®‡•ç‡§∏ ‡§™‡•ç‡§∞‡§•‡§ø‡§®‡§æ‡§Ç‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§ñ‡§∞‡§æ‡§¨ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞‡•á ‡§π‡§∏‡•ç‡§§‡§æ‡§Ç‡§§‡§∞‡§ø‡§§ ‡§ï‡•á‡§≤‡•á ‡§ú‡§æ‡§§‡§æ‡§§, ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ‡•Ä ‡§∞‡§ø‡§ï‡•ç‡§§ ‡§ó‡•ç‡§≤‡§æ‡§Ø‡§ï‡•ã‡§∏‡§æ‡§á‡§≤‡•á‡§∂‡§® ‡§∏‡•Ä‡§ï‡•ç‡§µ‡§æ‡§Ç‡§∏ ‡§§‡§Ø‡§æ‡§∞ ‡§π‡•ã‡§§‡§æ‡§§.\n",
      "eng_Latn: X is an effective acute, oral treatment for migraine with a rapid onset of action\n",
      "mar_Deva: mar_Deva eng_Latn ‡§è‡§ï‡•ç‡§∏ ‡§π‡§æ ‡§Ö‡§∞‡•ç‡§ß‡§∂‡§ø‡§∂‡•Ä‡§∏‡§æ‡§†‡•Ä ‡§è‡§ï ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡•Ä, ‡§§‡•Ä‡§µ‡•ç‡§∞, ‡§§‡•ã‡§Ç‡§°‡•Ä ‡§â‡§™‡§ö‡§æ‡§∞ ‡§Ü‡§π‡•á, ‡§ú‡•ç‡§Ø‡§æ‡§ö‡•Ä ‡§ï‡•É‡§§‡•Ä ‡§ú‡§≤‡§¶ ‡§∏‡•Å‡§∞‡•Ç ‡§π‡•ã‡§§‡•á.\n",
      "eng_Latn: No newspaper is completely unbiased in my expert opinion.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§Æ‡§æ‡§ù‡•ç‡§Ø‡§æ ‡§§‡§ú‡•ç‡§û‡§æ‡§Ç‡§ö‡•ç‡§Ø‡§æ ‡§Æ‡§§‡•á ‡§ï‡•ã‡§£‡§§‡•á‡§π‡•Ä ‡§µ‡•É‡§§‡•ç‡§§‡§™‡§§‡•ç‡§∞ ‡§™‡•Ç‡§∞‡•ç‡§£‡§™‡§£‡•á ‡§®‡§ø‡§É‡§™‡§ï‡•ç‡§∑‡§™‡§æ‡§§‡•Ä ‡§®‡§æ‡§π‡•Ä.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from IndicTransToolkit.processor import IndicProcessor\n",
    "# recommended to run this on a gpu with flash_attn installed\n",
    "# don't set attn_implemetation if you don't have flash_attn\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE = torch.device(\"cuda:3\")\n",
    "\n",
    "src_lang, tgt_lang = \"eng_Latn\", \"mar_Deva\"\n",
    "tokenizer_name =  \"ai4bharat/indictrans2-en-indic-dist-200M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name, \n",
    "    trust_remote_code=True, \n",
    "    torch_dtype=torch.float16, # performance might slightly vary for bfloat16\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ").to(DEVICE)\n",
    "\n",
    "ip = IndicProcessor(inference=True)\n",
    "\n",
    "input_sentences = src_sentences\n",
    "\n",
    "batch = ip.preprocess_batch(input_sentences, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "\n",
    "# Tokenize the sentences and generate input encodings\n",
    "inputs = tokenizer(\n",
    "    batch,\n",
    "    truncation=True,\n",
    "    padding=\"longest\",\n",
    "    return_tensors=\"pt\",\n",
    "    return_attention_mask=True,\n",
    ").to(DEVICE)\n",
    "\n",
    "# Generate translations using the model\n",
    "with torch.no_grad():\n",
    "    generated_tokens = model.generate(\n",
    "        **inputs,\n",
    "        use_cache=True,\n",
    "        min_length=0,\n",
    "        max_length=256,\n",
    "        num_beams=5,\n",
    "        num_return_sequences=1,\n",
    "    )\n",
    "\n",
    "# Decode the generated tokens into text\n",
    "generated_tokens = tokenizer.batch_decode(\n",
    "    generated_tokens,\n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=True,\n",
    ")\n",
    "\n",
    "# Postprocess the translations, including entity replacement\n",
    "translations = ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
    "\n",
    "for input_sentence, translation in zip(input_sentences[:10], translations[:10]):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4533875c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§â‡§§‡•ç‡§∏‡§µ ‡§∏‡§æ‡§ú‡§∞‡§æ ‡§ï‡§∞‡§£‡§æ‡§∞\\u093C‡•ç‡§Ø‡§æ‡§®‡•á ‡§™‡•ç‡§∞‡§æ‡§∞‡•ç‡§•‡§®‡•á‡§ö‡§æ ‡§â‡§ö‡•ç‡§ö‡§æ‡§∞ ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§Æ‡•Å‡§≥‡•á ‡§ó‡§æ‡§Ø‡§ï‡§µ‡•É‡§Ç‡§¶‡§æ‡§®‡•á ‡§ú‡§™ ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§®‡•á ‡§Ü‡§µ‡§æ‡§ú ‡§µ‡§æ‡§¢‡§≤‡§æ.\n"
     ]
    }
   ],
   "source": [
    "def remove_prefix(translations, prefix):\n",
    "    ans = []\n",
    "    for t in translations:\n",
    "        t = t.strip()\n",
    "        if t.startswith(prefix):\n",
    "            t = t[len(prefix):]\n",
    "        ans.append(t)\n",
    "    return ans\n",
    "\n",
    "translations = remove_prefix(translations, \"mar_Deva eng_Latn \")\n",
    "print(translations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72cb4cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"combined_le\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed28a7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Saved predictions to shalaka_combined_le_outputs.csv\n",
      "\n",
      "===== FINAL METRICS =====\n",
      "All references combined ‚Üí BLEU: 70.01, chrF++: 85.50, chrF2++: 83.17\n",
      "GT Marathi ‚Üí BLEU: 49.12\n",
      "Gemini    ‚Üí BLEU: 24.27\n",
      "CFILT     ‚Üí BLEU: 58.46\n",
      "\n",
      "üéØ BEST REFERENCE = CFILT (by highest BLEU)\n",
      "Metrics written to shalaka_punct_combined_le_indictrans2_eval_metrics.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "\n",
    "# -------------------- SAVE OUTPUTS --------------------\n",
    "results_df = pd.DataFrame({\n",
    "    \"src\": src_sentences,\n",
    "    \"prediction\": translations,\n",
    "    \"gt\": ref_gt,\n",
    "    \"gemini\": ref_gem,\n",
    "    \"cfilt\": ref_cfilt\n",
    "})\n",
    "\n",
    "results_df.to_csv(f\"shalaka_{mode}_outputs.csv\", index=False)\n",
    "print(f\"‚úî Saved predictions to shalaka_{mode}_outputs.csv\")\n",
    "\n",
    "# -------------------- METRICS --------------------\n",
    "bleu = load(\"sacrebleu\")\n",
    "chrf = load(\"chrf\")\n",
    "\n",
    "def compute_scores(preds, ref1, ref2, ref3):\n",
    "    \"\"\"\n",
    "    Compute BLEU and chrF++ scores using all three references for each sentence.\n",
    "    \"\"\"\n",
    "    references = [[r1, r2, r3] for r1, r2, r3 in zip(ref1, ref2, ref3)]  # sacrebleu format\n",
    "    bleu_score = bleu.compute(predictions=preds, references=references)[\"score\"]\n",
    "    chrf_score = chrf.compute(predictions=preds, references=references)[\"score\"]\n",
    "    chrf2_score = chrf.compute(predictions=preds, references=references, char_order=6, word_order=2,  beta=2)[\"score\"]\n",
    "    return bleu_score, chrf_score, chrf2_score\n",
    "\n",
    "bleu_score, chrf_score, chrf2_score = compute_scores(translations, ref_gt, ref_gem, ref_cfilt)\n",
    "\n",
    "# Determine best reference per metric (based on BLEU)\n",
    "all_scores = {\n",
    "    \"GT\":    bleu.compute(predictions=translations, references=[[r] for r in ref_gt])[\"score\"],\n",
    "    \"Gemini\": bleu.compute(predictions=translations, references=[[r] for r in ref_gem])[\"score\"],\n",
    "    \"CFILT\":  bleu.compute(predictions=translations, references=[[r] for r in ref_cfilt])[\"score\"]\n",
    "}\n",
    "\n",
    "best_ref = max(all_scores, key=all_scores.get)\n",
    "\n",
    "print(\"\\n===== FINAL METRICS =====\")\n",
    "print(f\"All references combined ‚Üí BLEU: {bleu_score:.2f}, chrF++: {chrf_score:.2f}, chrF2++: {chrf2_score:.2f}\")\n",
    "print(f\"GT Marathi ‚Üí BLEU: {all_scores['GT']:.2f}\")\n",
    "print(f\"Gemini    ‚Üí BLEU: {all_scores['Gemini']:.2f}\")\n",
    "print(f\"CFILT     ‚Üí BLEU: {all_scores['CFILT']:.2f}\")\n",
    "print(f\"\\nüéØ BEST REFERENCE = {best_ref} (by highest BLEU)\")\n",
    "\n",
    "# -------------------- SAVE METRICS --------------------\n",
    "with open(f\"shalaka_punct_{mode}_indictrans2_eval_metrics.txt\", \"w\") as f:\n",
    "    f.write(f\"All references combined ‚Üí BLEU {bleu_score:.2f}, chrF++ {chrf_score:.2f}, chrF2++: {chrf2_score:.2f}\\n\")\n",
    "    f.write(f\"GT    BLEU {all_scores['GT']:.2f}\\n\")\n",
    "    f.write(f\"Gem   BLEU {all_scores['Gemini']:.2f}\\n\")\n",
    "    f.write(f\"CFILT BLEU {all_scores['CFILT']:.2f}\\n\")\n",
    "    f.write(f\"\\nBEST REFERENCE = {best_ref}\\n\")\n",
    "\n",
    "print(f\"Metrics written to shalaka_punct_{mode}_indictrans2_eval_metrics.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05781992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db53565b",
   "metadata": {},
   "source": [
    "## Combined Model- Shalaka LR=5e-6 & Epochs=3 & Dataset Changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f08c3e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = combined_punct_model_data_changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07a4c3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng_Latn: Chanting the choir raised the volume as the celebrant intoned the prayer.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§â‡§§‡•ç‡§∏‡§µ ‡§∏‡§æ‡§ú‡§∞‡§æ ‡§ï‡§∞‡§£‡§æ‡§∞\\u093C‡•ç‡§Ø‡§æ‡§®‡•á ‡§™‡•ç‡§∞‡§æ‡§∞‡•ç‡§•‡§®‡•á‡§ö‡§æ ‡§â‡§ö‡•ç‡§ö‡§æ‡§∞ ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§Æ‡•Å‡§≥‡•á ‡§ó‡§æ‡§Ø‡§ï‡§µ‡•É‡§Ç‡§¶‡§æ‡§®‡•á ‡§ú‡§™ ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§®‡•á ‡§Ü‡§µ‡§æ‡§ú ‡§µ‡§æ‡§¢‡§≤‡§æ.\n",
      "eng_Latn: A six-month-old calf was submitted for examination, showing lameness in all four legs which had been present since soon after birth.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§ú‡§®‡•ç‡§Æ‡§æ‡§®‡§Ç‡§§‡§∞ ‡§≤‡§ó‡•á‡§ö‡§ö ‡§Ö‡§∏‡•ç‡§§‡§ø‡§§‡•ç‡§µ‡§æ‡§§ ‡§Ö‡§∏‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§ö‡§æ‡§∞‡§π‡•Ä ‡§™‡§æ‡§Ø‡§æ‡§Ç‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§≤‡§Ç‡§ó‡§°‡•á‡§™‡§£‡§æ ‡§¶‡§∞‡•ç‡§∂‡§µ‡§ø‡§£‡§æ‡§∞‡§æ ‡§∏‡§π‡§æ ‡§Æ‡§π‡§ø‡§®‡•ç‡§Ø‡§æ‡§Ç‡§ö‡§æ ‡§µ‡§æ‡§∏‡§∞ ‡§§‡§™‡§æ‡§∏‡§£‡•Ä‡§∏‡§æ‡§†‡•Ä ‡§∏‡§æ‡§¶‡§∞ ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§§ ‡§Ü‡§≤‡§æ.\n",
      "eng_Latn: Planning authorities should provide alternative locations for small businesses which are or would be offensive in a residential area.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§®‡§ø‡§Ø‡•ã‡§ú‡§® ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞\\u093C‡•ç‡§Ø‡§æ‡§Ç‡§®‡•Ä ‡§õ‡•ã‡§ü‡•ç‡§Ø‡§æ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø‡§æ‡§Ç‡§∏‡§æ‡§†‡•Ä ‡§™‡§∞‡•ç‡§Ø‡§æ‡§Ø‡•Ä ‡§†‡§ø‡§ï‡§æ‡§£‡•á ‡§™‡•Å‡§∞‡§µ‡§≤‡•Ä ‡§™‡§æ‡§π‡§ø‡§ú‡•á‡§§ ‡§ú‡•Ä ‡§®‡§ø‡§µ‡§æ‡§∏‡•Ä ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡§æ‡§§ ‡§Ü‡§ï‡•ç‡§∑‡•á‡§™‡§æ‡§∞‡•ç‡§π ‡§Ü‡§π‡•á‡§§ ‡§ï‡§ø‡§Ç‡§µ‡§æ ‡§Ö‡§∏‡§§‡•Ä‡§≤.\n",
      "eng_Latn: As the machine develops the forms we use to record data from past projects will be amended.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§ú‡§∏‡§ú‡§∏‡•á ‡§Æ‡§∂‡•Ä‡§® ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§π‡•ã‡§à‡§≤ ‡§§‡§∏‡§§‡§∏‡•á ‡§Æ‡§æ‡§ó‡•Ä‡§≤ ‡§™‡•ç‡§∞‡§ï‡§≤‡•ç‡§™‡§æ‡§Ç‡§Æ‡§ß‡•Ä‡§≤ ‡§°‡•á‡§ü‡§æ ‡§∞‡•á‡§ï‡•â‡§∞‡•ç‡§° ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§Ü‡§™‡§£ ‡§µ‡§æ‡§™‡§∞‡§§ ‡§Ö‡§∏‡§≤‡•á‡§≤‡•á ‡§´‡•â‡§∞‡•ç‡§Æ ‡§∏‡•Å‡§ß‡§æ‡§∞‡§ø‡§§ ‡§ï‡•á‡§≤‡•á ‡§ú‡§æ‡§§‡•Ä‡§≤.\n",
      "eng_Latn: As mentioned, first impressions can be misleading.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§®‡§Æ‡•Ç‡§¶ ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§™‡•ç‡§∞‡§Æ‡§æ‡§£‡•á, ‡§™‡§π‡§ø‡§≤‡•Ä ‡§õ‡§æ‡§™ ‡§¶‡§ø‡§∂‡§æ‡§≠‡•Ç‡§≤ ‡§ï‡§∞‡§£‡§æ‡§∞‡•Ä ‡§Ö‡§∏‡•Ç ‡§∂‡§ï‡§§‡•á.\n",
      "eng_Latn: To get a clean assembly load the assembled equals table before the assembly is run.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§∏‡•ç‡§µ‡§ö‡•ç‡§õ ‡§Ö‡§∏‡•á‡§Ç‡§¨‡•ç‡§≤‡•Ä ‡§≤‡•ã‡§° ‡§Æ‡§ø‡§≥‡§µ‡§ø‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä, ‡§Ö‡§∏‡•á‡§Ç‡§¨‡•ç‡§≤‡•Ä ‡§ö‡§æ‡§≤‡§µ‡§£‡•ç‡§Ø‡§æ‡§™‡•Ç‡§∞‡•ç‡§µ‡•Ä ‡§Ö‡§∏‡•á‡§Ç‡§¨‡§≤ ‡§ï‡•á‡§≤‡•á‡§≤‡•á ‡§∏‡§Æ‡§æ‡§® ‡§ü‡•á‡§¨‡§≤.\n",
      "eng_Latn: Executors delay giving information about substantial deviations from agreed dates. Because of this action cannot be taken in time.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§ï‡•á‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§§‡§æ‡§∞‡§ñ‡§æ‡§Ç‡§™‡§æ‡§∏‡•Ç‡§® ‡§≤‡§ï‡•ç‡§∑‡§£‡•Ä‡§Ø ‡§µ‡§ø‡§ö‡§≤‡§®‡§æ‡§Ç‡§ö‡•Ä ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä ‡§¶‡•á‡§£‡•ç‡§Ø‡§æ‡§∏ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡§æ‡§∞‡•Ä ‡§µ‡§ø‡§≤‡§Ç‡§¨ ‡§ï‡§∞‡§§‡§æ‡§§. ‡§§‡•ç‡§Ø‡§æ‡§Æ‡•Å‡§≥‡•á ‡§π‡•Ä ‡§ï‡§æ‡§∞‡§µ‡§æ‡§à ‡§µ‡•á‡§≥‡•á‡§µ‡§∞ ‡§ï‡•á‡§≤‡•Ä ‡§ú‡§æ‡§ä ‡§∂‡§ï‡§§ ‡§®‡§æ‡§π‡•Ä.\n",
      "eng_Latn: These glycans are poorly transferred to proteins resulting in unoccupied glycosylation sequons.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§π‡•á ‡§ó‡•ç‡§≤‡§æ‡§Ø‡§ï‡•á‡§®‡•ç‡§∏ ‡§™‡•ç‡§∞‡§•‡§ø‡§®‡§æ‡§Ç‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§ñ‡§∞‡§æ‡§¨ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞‡•á ‡§π‡§∏‡•ç‡§§‡§æ‡§Ç‡§§‡§∞‡§ø‡§§ ‡§ï‡•á‡§≤‡•á ‡§ú‡§æ‡§§‡§æ‡§§, ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ‡•Ä ‡§∞‡§ø‡§ï‡•ç‡§§ ‡§ó‡•ç‡§≤‡§æ‡§Ø‡§ï‡•ã‡§∏‡§ø‡§≤‡•á‡§∂‡§® ‡§∏‡•Ä‡§ï‡•ç‡§µ‡§æ‡§Ç‡§∏ ‡§§‡§Ø‡§æ‡§∞ ‡§π‡•ã‡§§‡§æ‡§§.\n",
      "eng_Latn: X is an effective acute, oral treatment for migraine with a rapid onset of action\n",
      "mar_Deva: mar_Deva eng_Latn ‡§è‡§ï‡•ç‡§∏ ‡§π‡§æ ‡§Ö‡§∞‡•ç‡§ß‡§∂‡§ø‡§∂‡•Ä‡§∏‡§æ‡§†‡•Ä ‡§è‡§ï ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡•Ä, ‡§§‡•Ä‡§µ‡•ç‡§∞, ‡§§‡•ã‡§Ç‡§°‡•Ä ‡§â‡§™‡§ö‡§æ‡§∞ ‡§Ü‡§π‡•á, ‡§ú‡•ç‡§Ø‡§æ‡§ö‡•Ä ‡§ï‡•É‡§§‡•Ä ‡§ú‡§≤‡§¶ ‡§∏‡•Å‡§∞‡•Ç ‡§π‡•ã‡§§‡•á.\n",
      "eng_Latn: No newspaper is completely unbiased in my expert opinion.\n",
      "mar_Deva: mar_Deva eng_Latn ‡§Æ‡§æ‡§ù‡•ç‡§Ø‡§æ ‡§§‡§ú‡•ç‡§û‡§æ‡§Ç‡§ö‡•ç‡§Ø‡§æ ‡§Æ‡§§‡•á ‡§ï‡•ã‡§£‡§§‡•á‡§π‡•Ä ‡§µ‡•É‡§§‡•ç‡§§‡§™‡§§‡•ç‡§∞ ‡§™‡•Ç‡§∞‡•ç‡§£‡§™‡§£‡•á ‡§®‡§ø‡§É‡§™‡§ï‡•ç‡§∑‡§™‡§æ‡§§‡•Ä ‡§®‡§æ‡§π‡•Ä.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from IndicTransToolkit.processor import IndicProcessor\n",
    "# recommended to run this on a gpu with flash_attn installed\n",
    "# don't set attn_implemetation if you don't have flash_attn\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE = torch.device(\"cuda:3\")\n",
    "\n",
    "src_lang, tgt_lang = \"eng_Latn\", \"mar_Deva\"\n",
    "tokenizer_name =  \"ai4bharat/indictrans2-en-indic-dist-200M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name, \n",
    "    trust_remote_code=True, \n",
    "    torch_dtype=torch.float16, # performance might slightly vary for bfloat16\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ").to(DEVICE)\n",
    "\n",
    "ip = IndicProcessor(inference=True)\n",
    "\n",
    "input_sentences = src_sentences\n",
    "\n",
    "batch = ip.preprocess_batch(input_sentences, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "\n",
    "# Tokenize the sentences and generate input encodings\n",
    "inputs = tokenizer(\n",
    "    batch,\n",
    "    truncation=True,\n",
    "    padding=\"longest\",\n",
    "    return_tensors=\"pt\",\n",
    "    return_attention_mask=True,\n",
    ").to(DEVICE)\n",
    "\n",
    "# Generate translations using the model\n",
    "with torch.no_grad():\n",
    "    generated_tokens = model.generate(\n",
    "        **inputs,\n",
    "        use_cache=True,\n",
    "        min_length=0,\n",
    "        max_length=256,\n",
    "        num_beams=5,\n",
    "        num_return_sequences=1,\n",
    "    )\n",
    "\n",
    "# Decode the generated tokens into text\n",
    "generated_tokens = tokenizer.batch_decode(\n",
    "    generated_tokens,\n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=True,\n",
    ")\n",
    "\n",
    "# Postprocess the translations, including entity replacement\n",
    "translations = ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
    "\n",
    "for input_sentence, translation in zip(input_sentences[:10], translations[:10]):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "954aed86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§â‡§§‡•ç‡§∏‡§µ ‡§∏‡§æ‡§ú‡§∞‡§æ ‡§ï‡§∞‡§£‡§æ‡§∞\\u093C‡•ç‡§Ø‡§æ‡§®‡•á ‡§™‡•ç‡§∞‡§æ‡§∞‡•ç‡§•‡§®‡•á‡§ö‡§æ ‡§â‡§ö‡•ç‡§ö‡§æ‡§∞ ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§Æ‡•Å‡§≥‡•á ‡§ó‡§æ‡§Ø‡§ï‡§µ‡•É‡§Ç‡§¶‡§æ‡§®‡•á ‡§ú‡§™ ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§®‡•á ‡§Ü‡§µ‡§æ‡§ú ‡§µ‡§æ‡§¢‡§≤‡§æ.\n"
     ]
    }
   ],
   "source": [
    "def remove_prefix(translations, prefix):\n",
    "    ans = []\n",
    "    for t in translations:\n",
    "        t = t.strip()\n",
    "        if t.startswith(prefix):\n",
    "            t = t[len(prefix):]\n",
    "        ans.append(t)\n",
    "    return ans\n",
    "\n",
    "translations = remove_prefix(translations, \"mar_Deva eng_Latn \")\n",
    "print(translations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0ae0253",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"combined_led\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c13258aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Saved predictions to shalaka_combined_led_outputs.csv\n",
      "\n",
      "===== FINAL METRICS =====\n",
      "All references combined ‚Üí BLEU: 68.89, chrF++: 84.37, chrF2++: 82.12\n",
      "GT Marathi ‚Üí BLEU: 47.75\n",
      "Gemini    ‚Üí BLEU: 24.28\n",
      "CFILT     ‚Üí BLEU: 58.70\n",
      "\n",
      "üéØ BEST REFERENCE = CFILT (by highest BLEU)\n",
      "Metrics written to shalaka_punct_combined_led_indictrans2_eval_metrics.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "\n",
    "# -------------------- SAVE OUTPUTS --------------------\n",
    "results_df = pd.DataFrame({\n",
    "    \"src\": src_sentences,\n",
    "    \"prediction\": translations,\n",
    "    \"gt\": ref_gt,\n",
    "    \"gemini\": ref_gem,\n",
    "    \"cfilt\": ref_cfilt\n",
    "})\n",
    "\n",
    "results_df.to_csv(f\"shalaka_{mode}_outputs.csv\", index=False)\n",
    "print(f\"‚úî Saved predictions to shalaka_{mode}_outputs.csv\")\n",
    "\n",
    "# -------------------- METRICS --------------------\n",
    "bleu = load(\"sacrebleu\")\n",
    "chrf = load(\"chrf\")\n",
    "\n",
    "def compute_scores(preds, ref1, ref2, ref3):\n",
    "    \"\"\"\n",
    "    Compute BLEU and chrF++ scores using all three references for each sentence.\n",
    "    \"\"\"\n",
    "    references = [[r1, r2, r3] for r1, r2, r3 in zip(ref1, ref2, ref3)]  # sacrebleu format\n",
    "    bleu_score = bleu.compute(predictions=preds, references=references)[\"score\"]\n",
    "    chrf_score = chrf.compute(predictions=preds, references=references)[\"score\"]\n",
    "    chrf2_score = chrf.compute(predictions=preds, references=references, char_order=6, word_order=2,  beta=2)[\"score\"]\n",
    "    return bleu_score, chrf_score, chrf2_score\n",
    "\n",
    "bleu_score, chrf_score, chrf2_score = compute_scores(translations, ref_gt, ref_gem, ref_cfilt)\n",
    "\n",
    "# Determine best reference per metric (based on BLEU)\n",
    "all_scores = {\n",
    "    \"GT\":    bleu.compute(predictions=translations, references=[[r] for r in ref_gt])[\"score\"],\n",
    "    \"Gemini\": bleu.compute(predictions=translations, references=[[r] for r in ref_gem])[\"score\"],\n",
    "    \"CFILT\":  bleu.compute(predictions=translations, references=[[r] for r in ref_cfilt])[\"score\"]\n",
    "}\n",
    "\n",
    "best_ref = max(all_scores, key=all_scores.get)\n",
    "\n",
    "print(\"\\n===== FINAL METRICS =====\")\n",
    "print(f\"All references combined ‚Üí BLEU: {bleu_score:.2f}, chrF++: {chrf_score:.2f}, chrF2++: {chrf2_score:.2f}\")\n",
    "print(f\"GT Marathi ‚Üí BLEU: {all_scores['GT']:.2f}\")\n",
    "print(f\"Gemini    ‚Üí BLEU: {all_scores['Gemini']:.2f}\")\n",
    "print(f\"CFILT     ‚Üí BLEU: {all_scores['CFILT']:.2f}\")\n",
    "print(f\"\\nüéØ BEST REFERENCE = {best_ref} (by highest BLEU)\")\n",
    "\n",
    "# -------------------- SAVE METRICS --------------------\n",
    "with open(f\"shalaka_punct_{mode}_indictrans2_eval_metrics.txt\", \"w\") as f:\n",
    "    f.write(f\"All references combined ‚Üí BLEU {bleu_score:.2f}, chrF++ {chrf_score:.2f}, chrF2++: {chrf2_score:.2f}\\n\")\n",
    "    f.write(f\"GT    BLEU {all_scores['GT']:.2f}\\n\")\n",
    "    f.write(f\"Gem   BLEU {all_scores['Gemini']:.2f}\\n\")\n",
    "    f.write(f\"CFILT BLEU {all_scores['CFILT']:.2f}\\n\")\n",
    "    f.write(f\"\\nBEST REFERENCE = {best_ref}\\n\")\n",
    "\n",
    "print(f\"Metrics written to shalaka_punct_{mode}_indictrans2_eval_metrics.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c439f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93b895f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1ae9de9",
   "metadata": {},
   "source": [
    "## Combined Model - Shalaka LR=1e-5 & Epochs=5 Changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac5a5e5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_punct_model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[43mcombined_punct_model2\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_punct_model2' is not defined"
     ]
    }
   ],
   "source": [
    "model_name = combined_punct_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70da880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from IndicTransToolkit.processor import IndicProcessor\n",
    "# recommended to run this on a gpu with flash_attn installed\n",
    "# don't set attn_implemetation if you don't have flash_attn\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE = torch.device(\"cuda:3\")\n",
    "\n",
    "src_lang, tgt_lang = \"eng_Latn\", \"mar_Deva\"\n",
    "tokenizer_name =  \"ai4bharat/indictrans2-en-indic-dist-200M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name, \n",
    "    trust_remote_code=True, \n",
    "    torch_dtype=torch.float16, # performance might slightly vary for bfloat16\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ").to(DEVICE)\n",
    "\n",
    "ip = IndicProcessor(inference=True)\n",
    "\n",
    "input_sentences = src_sentences\n",
    "\n",
    "batch = ip.preprocess_batch(input_sentences, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "\n",
    "# Tokenize the sentences and generate input encodings\n",
    "inputs = tokenizer(\n",
    "    batch,\n",
    "    truncation=True,\n",
    "    padding=\"longest\",\n",
    "    return_tensors=\"pt\",\n",
    "    return_attention_mask=True,\n",
    ").to(DEVICE)\n",
    "\n",
    "# Generate translations using the model\n",
    "with torch.no_grad():\n",
    "    generated_tokens = model.generate(\n",
    "        **inputs,\n",
    "        use_cache=True,\n",
    "        min_length=0,\n",
    "        max_length=256,\n",
    "        num_beams=5,\n",
    "        num_return_sequences=1,\n",
    "    )\n",
    "\n",
    "# Decode the generated tokens into text\n",
    "generated_tokens = tokenizer.batch_decode(\n",
    "    generated_tokens,\n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=True,\n",
    ")\n",
    "\n",
    "# Postprocess the translations, including entity replacement\n",
    "translations = ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
    "\n",
    "for input_sentence, translation in zip(input_sentences[:10], translations[:10]):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344d9826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefix(translations, prefix):\n",
    "    ans = []\n",
    "    for t in translations:\n",
    "        t = t.strip()\n",
    "        if t.startswith(prefix):\n",
    "            t = t[len(prefix):]\n",
    "        ans.append(t)\n",
    "    return ans\n",
    "\n",
    "translations = remove_prefix(translations, \"mar_Deva eng_Latn \")\n",
    "print(translations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f5b4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"combined_le2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaa0676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "\n",
    "# -------------------- SAVE OUTPUTS --------------------\n",
    "results_df = pd.DataFrame({\n",
    "    \"src\": src_sentences,\n",
    "    \"prediction\": translations,\n",
    "    \"gt\": ref_gt,\n",
    "    \"gemini\": ref_gem,\n",
    "    \"cfilt\": ref_cfilt\n",
    "})\n",
    "\n",
    "results_df.to_csv(f\"shalaka_{mode}_outputs.csv\", index=False)\n",
    "print(f\"‚úî Saved predictions to shalaka_{mode}_outputs.csv\")\n",
    "\n",
    "# -------------------- METRICS --------------------\n",
    "bleu = load(\"sacrebleu\")\n",
    "chrf = load(\"chrf\")\n",
    "\n",
    "def compute_scores(preds, ref1, ref2, ref3):\n",
    "    \"\"\"\n",
    "    Compute BLEU and chrF++ scores using all three references for each sentence.\n",
    "    \"\"\"\n",
    "    references = [[r1, r2, r3] for r1, r2, r3 in zip(ref1, ref2, ref3)]  # sacrebleu format\n",
    "    bleu_score = bleu.compute(predictions=preds, references=references)[\"score\"]\n",
    "    chrf_score = chrf.compute(predictions=preds, references=references)[\"score\"]\n",
    "    chrf2_score = chrf.compute(predictions=preds, references=references, char_order=6, word_order=2,  beta=2)[\"score\"]\n",
    "    return bleu_score, chrf_score, chrf2_score\n",
    "\n",
    "bleu_score, chrf_score, chrf2_score = compute_scores(translations, ref_gt, ref_gem, ref_cfilt)\n",
    "\n",
    "# Determine best reference per metric (based on BLEU)\n",
    "all_scores = {\n",
    "    \"GT\":    bleu.compute(predictions=translations, references=[[r] for r in ref_gt])[\"score\"],\n",
    "    \"Gemini\": bleu.compute(predictions=translations, references=[[r] for r in ref_gem])[\"score\"],\n",
    "    \"CFILT\":  bleu.compute(predictions=translations, references=[[r] for r in ref_cfilt])[\"score\"]\n",
    "}\n",
    "\n",
    "best_ref = max(all_scores, key=all_scores.get)\n",
    "\n",
    "print(\"\\n===== FINAL METRICS =====\")\n",
    "print(f\"All references combined ‚Üí BLEU: {bleu_score:.2f}, chrF++: {chrf_score:.2f}, chrF2++: {chrf2_score:.2f}\")\n",
    "print(f\"GT Marathi ‚Üí BLEU: {all_scores['GT']:.2f}\")\n",
    "print(f\"Gemini    ‚Üí BLEU: {all_scores['Gemini']:.2f}\")\n",
    "print(f\"CFILT     ‚Üí BLEU: {all_scores['CFILT']:.2f}\")\n",
    "print(f\"\\nüéØ BEST REFERENCE = {best_ref} (by highest BLEU)\")\n",
    "\n",
    "# -------------------- SAVE METRICS --------------------\n",
    "with open(f\"shalaka_punct_{mode}_indictrans2_eval_metrics.txt\", \"w\") as f:\n",
    "    f.write(f\"All references combined ‚Üí BLEU {bleu_score:.2f}, chrF++ {chrf_score:.2f},  chrF2++: {chrf2_score:.2f}\\n\")\n",
    "    f.write(f\"GT    BLEU {all_scores['GT']:.2f}\\n\")\n",
    "    f.write(f\"Gem   BLEU {all_scores['Gemini']:.2f}\\n\")\n",
    "    f.write(f\"CFILT BLEU {all_scores['CFILT']:.2f}\\n\")\n",
    "    f.write(f\"\\nBEST REFERENCE = {best_ref}\\n\")\n",
    "\n",
    "print(f\"Metrics written to shalaka_punct_{mode}_indictrans2_eval_metrics.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f201a2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed56f96f",
   "metadata": {},
   "source": [
    "## Combined Model- Shalaka LR=1e-5 & Epochs=5 & Dataset Changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e444a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = combined_punct_model_data_changed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0843425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from IndicTransToolkit.processor import IndicProcessor\n",
    "# recommended to run this on a gpu with flash_attn installed\n",
    "# don't set attn_implemetation if you don't have flash_attn\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE = torch.device(\"cuda:3\")\n",
    "\n",
    "src_lang, tgt_lang = \"eng_Latn\", \"mar_Deva\"\n",
    "tokenizer_name =  \"ai4bharat/indictrans2-en-indic-dist-200M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name, \n",
    "    trust_remote_code=True, \n",
    "    torch_dtype=torch.float16, # performance might slightly vary for bfloat16\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ").to(DEVICE)\n",
    "\n",
    "ip = IndicProcessor(inference=True)\n",
    "\n",
    "input_sentences = src_sentences\n",
    "\n",
    "batch = ip.preprocess_batch(input_sentences, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "\n",
    "# Tokenize the sentences and generate input encodings\n",
    "inputs = tokenizer(\n",
    "    batch,\n",
    "    truncation=True,\n",
    "    padding=\"longest\",\n",
    "    return_tensors=\"pt\",\n",
    "    return_attention_mask=True,\n",
    ").to(DEVICE)\n",
    "\n",
    "# Generate translations using the model\n",
    "with torch.no_grad():\n",
    "    generated_tokens = model.generate(\n",
    "        **inputs,\n",
    "        use_cache=True,\n",
    "        min_length=0,\n",
    "        max_length=256,\n",
    "        num_beams=5,\n",
    "        num_return_sequences=1,\n",
    "    )\n",
    "\n",
    "# Decode the generated tokens into text\n",
    "generated_tokens = tokenizer.batch_decode(\n",
    "    generated_tokens,\n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=True,\n",
    ")\n",
    "\n",
    "# Postprocess the translations, including entity replacement\n",
    "translations = ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
    "\n",
    "for input_sentence, translation in zip(input_sentences[:10], translations[:10]):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae74a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefix(translations, prefix):\n",
    "    ans = []\n",
    "    for t in translations:\n",
    "        t = t.strip()\n",
    "        if t.startswith(prefix):\n",
    "            t = t[len(prefix):]\n",
    "        ans.append(t)\n",
    "    return ans\n",
    "\n",
    "translations = remove_prefix(translations, \"mar_Deva eng_Latn \")\n",
    "print(translations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb4f22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"combined_led2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a30634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "\n",
    "# -------------------- SAVE OUTPUTS --------------------\n",
    "results_df = pd.DataFrame({\n",
    "    \"src\": src_sentences,\n",
    "    \"prediction\": translations,\n",
    "    \"gt\": ref_gt,\n",
    "    \"gemini\": ref_gem,\n",
    "    \"cfilt\": ref_cfilt\n",
    "})\n",
    "\n",
    "results_df.to_csv(f\"shalaka_{mode}_outputs.csv\", index=False)\n",
    "print(f\"‚úî Saved predictions to shalaka_{mode}_outputs.csv\")\n",
    "\n",
    "# -------------------- METRICS --------------------\n",
    "bleu = load(\"sacrebleu\")\n",
    "chrf = load(\"chrf\")\n",
    "\n",
    "def compute_scores(preds, ref1, ref2, ref3):\n",
    "    \"\"\"\n",
    "    Compute BLEU and chrF++ scores using all three references for each sentence.\n",
    "    \"\"\"\n",
    "    references = [[r1, r2, r3] for r1, r2, r3 in zip(ref1, ref2, ref3)]  # sacrebleu format\n",
    "    bleu_score = bleu.compute(predictions=preds, references=references)[\"score\"]\n",
    "    chrf_score = chrf.compute(predictions=preds, references=references)[\"score\"]\n",
    "    chrf2_score = chrf.compute(predictions=preds, references=references, char_order=6, word_order=2,  beta=2)[\"score\"]\n",
    "    return bleu_score, chrf_score, chrf2_score\n",
    "\n",
    "bleu_score, chrf_score, chrf2_score = compute_scores(translations, ref_gt, ref_gem, ref_cfilt)\n",
    "\n",
    "# Determine best reference per metric (based on BLEU)\n",
    "all_scores = {\n",
    "    \"GT\":    bleu.compute(predictions=translations, references=[[r] for r in ref_gt])[\"score\"],\n",
    "    \"Gemini\": bleu.compute(predictions=translations, references=[[r] for r in ref_gem])[\"score\"],\n",
    "    \"CFILT\":  bleu.compute(predictions=translations, references=[[r] for r in ref_cfilt])[\"score\"]\n",
    "}\n",
    "\n",
    "best_ref = max(all_scores, key=all_scores.get)\n",
    "\n",
    "print(\"\\n===== FINAL METRICS =====\")\n",
    "print(f\"All references combined ‚Üí BLEU: {bleu_score:.2f}, chrF++: {chrf_score:.2f}, chrF2++ {chrf2_score:.2f}\")\n",
    "print(f\"GT Marathi ‚Üí BLEU: {all_scores['GT']:.2f}\")\n",
    "print(f\"Gemini    ‚Üí BLEU: {all_scores['Gemini']:.2f}\")\n",
    "print(f\"CFILT     ‚Üí BLEU: {all_scores['CFILT']:.2f}\")\n",
    "print(f\"\\nüéØ BEST REFERENCE = {best_ref} (by highest BLEU)\")\n",
    "\n",
    "# -------------------- SAVE METRICS --------------------\n",
    "with open(f\"shalaka_punct_{mode}_indictrans2_eval_metrics.txt\", \"w\") as f:\n",
    "    f.write(f\"All references combined ‚Üí BLEU {bleu_score:.2f}, chrF++ {chrf_score:.2f}, chrF2++ {chrf2_score:.2f}\\n\")\n",
    "    f.write(f\"GT    BLEU {all_scores['GT']:.2f}\\n\")\n",
    "    f.write(f\"Gem   BLEU {all_scores['Gemini']:.2f}\\n\")\n",
    "    f.write(f\"CFILT BLEU {all_scores['CFILT']:.2f}\\n\")\n",
    "    f.write(f\"\\nBEST REFERENCE = {best_ref}\\n\")\n",
    "\n",
    "print(f\"Metrics written to shalaka_punct_{mode}_indictrans2_eval_metrics.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dd9640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
